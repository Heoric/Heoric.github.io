<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>回溯算法</title>
    <url>/2023/09/15/%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>回溯，全排列，N皇后。</p>
<span id="more"></span>

<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">permute</span>(vector&lt;<span class="type">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        <span class="built_in">dfs</span>(nums, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; res;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(vector&lt;<span class="type">int</span>&gt; nums, <span class="type">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (x == nums.<span class="built_in">size</span>() - <span class="number">1</span>) &#123;</span><br><span class="line">            res.<span class="built_in">push_back</span>(nums);      <span class="comment">// 添加排列方案</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = x; i &lt; nums.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="built_in">swap</span>(nums[i], nums[x]);   <span class="comment">// 交换，将 nums[i] 固定在第 x 位</span></span><br><span class="line">            <span class="built_in">dfs</span>(nums, x + <span class="number">1</span>);         <span class="comment">// 开启固定第 x + 1 位元素</span></span><br><span class="line">            <span class="built_in">swap</span>(nums[i], nums[x]);   <span class="comment">// 恢复交换</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title>我的博客</title>
    <url>/2023/01/31/template/</url>
    <content><![CDATA[<p>我的第一篇博客</p>
<span id="more"></span>

<p>正片开始</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">关系模型</span><br><span class="line">关系代数</span><br><span class="line"></span><br><span class="line">parser</span><br><span class="line">	词法</span><br><span class="line">	语法</span><br><span class="line">	</span><br><span class="line">AST</span><br><span class="line"></span><br><span class="line">planner</span><br><span class="line">	启发式（Heuristics）</span><br><span class="line">	启发式+基于代价的JOIN（Heuristics + Cost-based Join Order Search）</span><br><span class="line">	分层优化器框架（Stratified Search）</span><br><span class="line">	统一优化器框架（Unified Search）</span><br><span class="line">	</span><br><span class="line">	system-r</span><br><span class="line">	v</span><br><span class="line">	</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>template</category>
      </categories>
      <tags>
        <tag>模版</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库SQL总结</title>
    <url>/2023/01/31/2-%E6%95%B0%E6%8D%AE%E5%BA%93/template/</url>
    <content><![CDATA[<p>数据库、操作系统和编译器是计算机软件的三大系统。其中数据库更接近业务层，几乎所有软件都会用到数据库，所以对数据库的熟练使用时每个开发人员必备的技能，而数据库对外最直接的接口就是 SQL。</p>
<p>今天我们来讲讲数据库SQL。</p>
<span id="more"></span>

<p>基本SQL</p>
<p>建表</p>
<p>中级SQL</p>
<p>高级SQL</p>
<p>join</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>c++11 新特性</title>
    <url>/2023/01/31/3-c++/c++11/</url>
    <content><![CDATA[<span id="more"></span>

]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>编译原理</title>
    <url>/2023/08/22/2-%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>什么是编译器 ？他的作用是什么？他的输入输出是什么？</p>
<p>编译器是一个程序，他将源程序翻译成等价的目标程序，输入数据是类似 C语言的高级语言，输出是类似汇编语言或者机器语言的低级语言。</p>
<p>编译器与解释器有什么区别 ？</p>
<p>对编译器来说，编译和运行时两个阶段。解释器则不需要将这两阶段分开；</p>
<p>编译器和解释器的根本区别在于是否生产目标代码。编译器会生成目标代码，然后运行，而解释器分析后直接运行生成结果；</p>
<span id="more"></span>

<p>编译器和解释器的存储组织方式不同，对编译器来说，在源程序被编译阶段，存储区要为源程序和目标程序开辟空间，存放需要使用的各种表，如符号表，在运行阶段需要存放目标代码和数据，编译阶段的信息不再需要。解释器在整个过程中源程序、符号表都需要存储在存储区中；</p>
<p>编译器比解释器效率高，因为编译器时一次翻译，多次运行。而解释器每次运行都需要逐行翻译。</p>
<p>编译器工作分为几个阶段 ？</p>
<p>一般分为 词法分析、语法分析、语义分析、中间代码生成、代码优化、目标代码生成这六个阶段。期间要有错误处理等。当然不是严格分为几个阶段。不同编译器不一样。</p>
<p>编译过程中的前端和后端如何划分，为什么要划分前后端 ？</p>
<p>前端主要依赖于源代码，与目标机器无关。后端主要依赖于目标机器，与源程序无关。前端包括词法分析，语法分析，语义分析和中间代码生成，还有某些优化工作。后端包括目标代码生成。</p>
<p>按照这种方式，可以实现不同机器使用同一源程序的编译器（前端相同，后端不同），也可以为同一期间生成几个语言的编译程序（前端不同，后端相同）。</p>
<h2 id="文法和语言"><a href="#文法和语言" class="headerlink" title="文法和语言"></a>文法和语言</h2><p>什么是语法，什么是语义 ？</p>
<p>语法是一组规则，用来定义什么样的符号序列是合法的。语义进一步判断合法的符号是否能构成正确的程序。比如类型检查就无法从语法上判断，但是可以在语义分析阶段判断。</p>
<p>文法的分类有哪些 ？</p>
<p>乔姆斯基（Chomsky）于1956年建立了形式语言的描述，把文法分成四种类型，即0型（短语文法）,1型（上下文有关文法）,2型（上下文无关文法）,3型（正规文法）。</p>
<p>上下文无关文法（context-free grammar）是什么？</p>
<p>上下文无关文法由四个元素组成，一个终结符号集合、一个非终结符号集合、一个产生式集合、一个非终结符号为开始符号。</p>
<p>如何进行语法分析，有哪些基本方法？</p>
<p>语法分析分为两大类，自顶向下分析和自底向上分析。</p>
<p>自顶向下分析思想：从文法的开始符号出发，反复使用各种产生式，逐步向下推导，试图推导出句子。存在的问题：在推导中如何选择规则？采用回溯法可行，但是代价太高，还可能陷入死循环。</p>
<p>自底向上分析法思想：从输入符号串开始，逐步进行归约，直到规约到文法的开始符号。存在的问题：每次应归约当前句型的句柄，但如何找句柄，以及句柄是否唯一？对一个句型的短语、直接短语和句柄的判断，常用的方法是：（1）查看语法树的叶子结点（终结符或非终结符），如果叶子结点的父结点还有其他子结点，就将该父结点的所有子结点作为一个字符串集合来判断；（2）对子结点的判断要从左向右处理；向上判断短语是相对哪个非终结符的短语时，要一直处理到祖先结点。</p>
<h2 id="词法分析"><a href="#词法分析" class="headerlink" title="词法分析"></a>词法分析</h2><p>词法分析的主要任务是什么，输入输出是什么？</p>
<p>词法分析从左向右扫描每行源代码，识别出单词和属性，把单词转换成统一的内部表示给语法分析。还需要删除注释，空格，换行等非必要信息。 输入源程序代码，输出单词符号（token）。</p>
<p>单词符号（token）分为哪些 ？</p>
<p>关键字、标识符、常数、运算符、界限符（分号，括号等）。 </p>
<h2 id="语法分析"><a href="#语法分析" class="headerlink" title="语法分析"></a>语法分析</h2><p>什么是自顶向下分析法 ？</p>
<p>自顶向下分析法也称面向目标的分析方法，也就是从文法的开始符号出发企图推导出与输入的单词串完全相匹配的句子，若输入串是给定文法的句子，则必能推出，反之必然出错。自顶向下分析包括确定分析和不确定分析。</p>
]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
      <tags>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title>深入C++虚函数</title>
    <url>/2023/01/31/3-c++/%E8%99%9A%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p>我一直认为 c++ 的精髓是 虚函数。</p>
<p>虚函数是运行时多状的基础。</p>
<p>今天就来扒一扒虚函数的内部机制。</p>
<span id="more"></span>

<h3 id="没有虚函数"><a href="#没有虚函数" class="headerlink" title="没有虚函数"></a>没有虚函数</h3><p>我们从 内存 来看 虚函数的 底层机制。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> base_1;</span><br><span class="line">    <span class="type">int</span> base_2;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Base b;</span><br><span class="line">    </span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sizeof</span>(b) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 8</span></span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">offsetof</span>(Base, base_1) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 0</span></span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">offsetof</span>(Base, base_2) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 4</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 结果很明显， 不需要多说什么。</span></span><br></pre></td></tr></table></figure>

<h3 id="只有一个虚函数"><a href="#只有一个虚函数" class="headerlink" title="只有一个虚函数"></a>只有一个虚函数</h3><p>接下来，我们看一下，带虚函数的对象的内存。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> base_1;</span><br><span class="line">    <span class="type">int</span> base_2;</span><br><span class="line">		<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">func</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Base b;</span><br><span class="line">    </span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sizeof</span>(b) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 16</span></span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">offsetof</span>(Base, base_1) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 8</span></span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">offsetof</span>(Base, base_2) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 12</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以看出来，对象前面多了八个字节。让我们来看看多了的是什么。</p>
<p>其实我们都知道，虚函数是在一个虚函数表里面。那么我们看看对象 b 的布局。</p>
<p>可以看到里面有个 指针，我们把里面的值打出来，看到是 一个函数指针，指向了 func()。</p>
<p>新定义一个变量 b1，查看 b1 的虚函数表，和内容，可以看到跟 b 是一摸一样的。说明一个类，只有一个虚函数表。</p>
<p>![image-20230605165441623](&#x2F;Users&#x2F;leoric&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230605165441623.png)</p>
<h3 id="多个虚函数"><a href="#多个虚函数" class="headerlink" title="多个虚函数"></a>多个虚函数</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> base_1;</span><br><span class="line">    <span class="type">int</span> base_2;</span><br><span class="line">		<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">func</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">  	<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">func1</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Base b;</span><br><span class="line">    </span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sizeof</span>(b) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 16</span></span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">offsetof</span>(Base, base_1) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 8</span></span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">offsetof</span>(Base, base_2) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 12</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>可以看到，对象对大小不变， 虚函数表里多了 func1。</p>
<p>![image-20230605170310030](&#x2F;Users&#x2F;leoric&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230605170310030.png)</p>
<h3 id="单继承且本身不存在虚函数"><a href="#单继承且本身不存在虚函数" class="headerlink" title="单继承且本身不存在虚函数"></a>单继承且本身不存在虚函数</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> base_1;</span><br><span class="line">    <span class="type">int</span> base_2;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">func</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">func1</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derive</span> : <span class="keyword">public</span> Base</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> derive_1;</span><br><span class="line">    <span class="type">int</span> derive_2;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Base b;</span><br><span class="line">    Base b1; </span><br><span class="line">    </span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sizeof</span>(b) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">offsetof</span>(Base, base_1) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">offsetof</span>(Base, base_2) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Derive d;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sizeof</span>(b) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">//16</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>直接看内存， 虚函数表的地址不一样，但是指向了相同的函数。</p>
<p>![image-20230605172826693](&#x2F;Users&#x2F;leoric&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230605172826693.png)</p>
<h3 id="本身不存在虚函数但存在基类虚函数覆盖"><a href="#本身不存在虚函数但存在基类虚函数覆盖" class="headerlink" title="本身不存在虚函数但存在基类虚函数覆盖"></a>本身不存在虚函数但存在基类虚函数覆盖</h3>]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>c++ 模版元编程</title>
    <url>/2023/05/26/3-c++/00-%E6%A8%A1%E7%89%88%E5%85%83%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<p>本系列文章从零开始介绍C++模版元编程，需要有C++基础。</p>
<span id="more"></span>

<h3 id="函数模版"><a href="#函数模版" class="headerlink" title="函数模版"></a>函数模版</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function">T <span class="title">add</span><span class="params">(T <span class="type">const</span> a, T <span class="type">const</span> b)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> a = <span class="built_in">add</span>(<span class="number">42</span>, <span class="number">21</span>);</span><br><span class="line"><span class="keyword">auto</span> d = <span class="built_in">add</span>&lt;<span class="type">double</span>&gt;(<span class="number">41.0</span>, <span class="number">21</span>); <span class="comment">// 无法自动推导类型的时候可以显示的指定类型</span></span><br></pre></td></tr></table></figure>



<h3 id="类模版"><a href="#类模版" class="headerlink" title="类模版"></a>类模版</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">wrapper</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">wrapper</span>(T <span class="type">const</span> v) : <span class="built_in">value</span>(v) &#123;&#125;</span><br><span class="line">  <span class="function">T <span class="type">const</span>&amp; <span class="title">get</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> value; &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  T value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">wrapper <span class="title">a</span><span class="params">(<span class="number">1</span>)</span></span>; <span class="comment">// 模版参数推导</span></span><br><span class="line"><span class="function">wrapper&lt;<span class="type">int</span>&gt; <span class="title">b</span><span class="params">(<span class="number">2</span>)</span></span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="成员函数模版"><a href="#成员函数模版" class="headerlink" title="成员函数模版"></a>成员函数模版</h3><h4 id="模版类的成员函数"><a href="#模版类的成员函数" class="headerlink" title="模版类的成员函数"></a>模版类的成员函数</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">comoosition</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function">T <span class="title">add</span><span class="params">(T <span class="type">const</span> a, T <span class="type">const</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">composition&lt;<span class="type">int</span>&gt; c;</span><br><span class="line">c.<span class="built_in">add</span>(<span class="number">12</span>,<span class="number">32</span>);</span><br></pre></td></tr></table></figure>

<h4 id="非模版类的成员函数模版"><a href="#非模版类的成员函数模版" class="headerlink" title="非模版类的成员函数模版"></a>非模版类的成员函数模版</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">compotion</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="function">T <span class="title">add</span><span class="params">(T <span class="type">const</span> a, T <span class="type">const</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">compostion c;</span><br><span class="line">c.<span class="built_in">add</span>&lt;<span class="type">int</span>&gt;(<span class="number">12</span>,<span class="number">13</span>);</span><br><span class="line">c.<span class="built_in">add</span>(<span class="number">1</span>,<span class="number">2</span>);</span><br></pre></td></tr></table></figure>

<h4 id="类模版的成员函数模版"><a href="#类模版的成员函数模版" class="headerlink" title="类模版的成员函数模版"></a>类模版的成员函数模版</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">wrapper</span> &#123;</span><br><span class="line">pbulic:</span><br><span class="line">  <span class="built_in">wrapper</span>(T <span class="type">const</span> v) : <span class="built_in">value</span>(v) &#123;&#125;</span><br><span class="line">  <span class="function">T <span class="type">const</span>&amp; <span class="title">get</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> value; &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> U&gt;</span><br><span class="line">  <span class="function">U <span class="title">as</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">static_cast</span>&lt;U&gt;(value);</span><br><span class="line">  &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  T value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 成员函数模板的模板形参必须与类模板的模板形参不同</span></span><br><span class="line"></span><br><span class="line"><span class="function">wrapper&lt;<span class="type">double</span>&gt; <span class="title">a</span><span class="params">(<span class="number">42.1</span>)</span></span>;</span><br><span class="line"><span class="keyword">auto</span> d = a.<span class="built_in">get</span>();</span><br><span class="line"><span class="keyword">auto</span> b = a.<span class="built_in">as</span>&lt;<span class="type">int</span>&gt;();</span><br></pre></td></tr></table></figure>



<h3 id="模版参数"><a href="#模版参数" class="headerlink" title="模版参数"></a>模版参数</h3><h4 id="类型模版参数"><a href="#类型模版参数" class="headerlink" title="类型模版参数"></a>类型模版参数</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; <span class="comment">// 不带默认参数</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">wrapper</span> &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T = <span class="type">int</span>&gt; <span class="comment">// 带默认参数</span></span><br><span class="line"><span class="keyword">class</span> wrapper &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span>... T&gt; <span class="comment">// 可变参数模版</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">wrapper</span> &#123;&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="非类型模版"><a href="#非类型模版" class="headerlink" title="非类型模版"></a>非类型模版</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">int</span> V&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">foo</span> &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">int</span> V = <span class="number">42</span>&gt;</span><br><span class="line"><span class="keyword">class</span> foo &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">int</span>... V&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">foo</span> &#123;&#125;;</span><br></pre></td></tr></table></figure>



<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="type">size_t</span> S&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">buffer</span> &#123;</span><br><span class="line">  T data_[S];</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">constexpr</span> T <span class="type">const</span> * <span class="title">data</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> data_; &#125;</span><br><span class="line">  <span class="keyword">constexpr</span> T&amp; <span class="keyword">operator</span>[](<span class="type">size_t</span> <span class="type">const</span> index) &#123;</span><br><span class="line">    <span class="keyword">return</span> data_[index];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">constexpr</span> T <span class="type">const</span>&amp; <span class="keyword">operator</span>[] (<span class="type">size_t</span> <span class="type">const</span> index) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> data_[index];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">buffer&lt;<span class="type">int</span>, <span class="number">10</span>&gt; b1; </span><br><span class="line">buffer&lt;<span class="type">int</span>, <span class="number">2</span>*<span class="number">5</span>&gt; b2;</span><br></pre></td></tr></table></figure>

<p>看一种更常见的类型</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">device</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">output</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">device</span>() &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="built_in">void</span> (*action) ()&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">smart_device</span> : device &#123;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">output</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    (*action) ();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">say_hello_in_english</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Hello, world!\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">auto</span> w1 = std::make_unique&lt;smart_device&lt;&amp;say_hello_in_english&gt;&gt;();</span><br><span class="line">w1-&gt;<span class="built_in">output</span>();</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="双重模版参数"><a href="#双重模版参数" class="headerlink" title="双重模版参数"></a>双重模版参数</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">simple_wrapper</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	T value; </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">fancy_wrapper</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">fancy_wrapper</span>(T <span class="type">const</span> v) :<span class="built_in">value</span>(v) &#123;&#125;</span><br><span class="line">  </span><br><span class="line">	<span class="function">T <span class="type">const</span>&amp; <span class="title">get</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> value; &#125;</span><br><span class="line">  </span><br><span class="line">	<span class="keyword">template</span> &lt;<span class="keyword">typename</span> U&gt; <span class="function">U <span class="title">as</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="built_in">static_cast</span>&lt;U&gt;(value); </span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">private</span>: </span><br><span class="line">  T value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U, <span class="keyword">template</span>&lt;<span class="keyword">typename</span>&gt; <span class="keyword">typename</span> W = fancy_wrapper&gt;</span><br><span class="line"><span class="keyword">class</span> wrapping_pair &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">wrapping_pair</span>(T <span class="type">const</span> a, U <span class="type">const</span> b) : <span class="built_in">item1</span>(a), <span class="built_in">item2</span>(b) &#123; &#125;</span><br><span class="line">	W&lt;T&gt; item1;</span><br><span class="line">  W&lt;U&gt; item2;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="默认模版参数"><a href="#默认模版参数" class="headerlink" title="默认模版参数"></a>默认模版参数</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T = <span class="type">int</span>&gt; </span><br><span class="line"><span class="keyword">class</span> foo &#123; <span class="comment">/*...*/</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T = <span class="type">int</span>, <span class="keyword">typename</span> U = <span class="type">double</span>&gt; </span><br><span class="line"><span class="keyword">class</span> bar &#123; <span class="comment">/*...*/</span> &#125;;</span><br></pre></td></tr></table></figure>



<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T = <span class="type">int</span>, <span class="keyword">typename</span> U&gt; </span><br><span class="line"><span class="keyword">class</span> bar &#123; &#125;; <span class="comment">// error, 类模版带默认参数的参数，后面不能跟不带默认参数的参数。</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T = <span class="type">int</span>, <span class="keyword">typename</span> U&gt; </span><br><span class="line"><span class="type">void</span> <span class="built_in">func</span>() &#123;&#125; <span class="comment">// OK</span></span><br></pre></td></tr></table></figure>



<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T = <span class="type">int</span>&gt; </span><br><span class="line"><span class="keyword">struct</span> foo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T = <span class="type">int</span>&gt; <span class="comment">// error redefinition // of default parameter</span></span><br><span class="line"><span class="keyword">struct</span> foo &#123;&#125;;</span><br></pre></td></tr></table></figure>





<h3 id="模版实例化"><a href="#模版实例化" class="headerlink" title="模版实例化"></a>模版实例化</h3><p>模版实例化可以是显式的也可以是隐式的。</p>
<h4 id="隐式实例化"><a href="#隐式实例化" class="headerlink" title="隐式实例化"></a>隐式实例化</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">foo</span> &#123;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">f</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"> 	foo&lt;<span class="type">int</span>&gt; *x; <span class="comment">// 不会实例化</span></span><br><span class="line">  foo&lt;<span class="type">int</span>&gt; p;  <span class="comment">// 会</span></span><br><span class="line">  foo&lt;<span class="type">int</span>&gt; p1; <span class="comment">// 会</span></span><br><span class="line">  foo&lt;<span class="type">double</span>&gt; *q; <span class="comment">// 不会</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">foo</span> &#123;</span><br><span class="line">  <span class="type">static</span> T data;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; T foo&lt;T&gt;::data = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  foo&lt;<span class="type">int</span>&gt; a;</span><br><span class="line">  foo&lt;<span class="type">double</span>&gt; b;</span><br><span class="line">  foo&lt;<span class="type">double</span>&gt; c;</span><br><span class="line">  std::cout &lt;&lt; a.data &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 0 </span></span><br><span class="line">  std::cout &lt;&lt; b.data &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 0 </span></span><br><span class="line">  std::cout &lt;&lt; c.data &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 0</span></span><br><span class="line">  </span><br><span class="line">  b.data = <span class="number">42</span>;</span><br><span class="line">  </span><br><span class="line">  std::cout &lt;&lt; a.data &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 0 </span></span><br><span class="line">  std::cout &lt;&lt; b.data &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 42 </span></span><br><span class="line">  std::cout &lt;&lt; c.data &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// 42</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="显示实例化"><a href="#显示实例化" class="headerlink" title="显示实例化"></a>显示实例化</h4><p>显示实例化分为显示实例化定义和显示实例化声明。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 类模版</span></span><br><span class="line"><span class="keyword">template</span> <span class="keyword">class</span>-key <span class="keyword">template</span>-name &lt;argument-list&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 函数模版</span></span><br><span class="line"><span class="keyword">template</span> <span class="keyword">return</span>-type <span class="built_in">name</span>&lt;argument-list&gt; (parameter-list);</span><br><span class="line"><span class="keyword">template</span> <span class="keyword">return</span>-type <span class="built_in">name</span>(parameter-list);</span><br></pre></td></tr></table></figure>



<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">namespace</span> ns &#123;</span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">wrapper</span> &#123;</span><br><span class="line">    T value;</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">template</span> <span class="keyword">struct</span> <span class="title class_">wrapper</span>&lt;<span class="type">int</span>&gt;; <span class="comment">// 显示实例化</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span> <span class="keyword">struct</span> <span class="title class_">ns</span>::wrapper&lt;<span class="type">double</span>&gt;; <span class="comment">// 显示实例化</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">namespace</span> ns &#123;</span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="function">T <span class="title">add</span><span class="params">(T <span class="type">const</span> a, T <span class="type">const</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">template</span> <span class="type">int</span> <span class="title">add</span><span class="params">(<span class="type">int</span>, <span class="type">int</span>)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span> <span class="type">double</span> <span class="title">ns::add</span><span class="params">(<span class="type">double</span>, <span class="type">double</span>)</span></span>;</span><br></pre></td></tr></table></figure>







<h3 id="模版特化"><a href="#模版特化" class="headerlink" title="模版特化"></a>模版特化</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">is_floatiog_point</span> &#123;</span><br><span class="line">  <span class="keyword">constexpr</span> <span class="type">static</span> <span class="type">bool</span> value = <span class="literal">false</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">is_floating_point</span>&lt;<span class="type">float</span>&gt; &#123;</span><br><span class="line">  <span class="keyword">constexpr</span> <span class="type">static</span> <span class="type">bool</span> value = <span class="literal">true</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">is_floating_point</span> &lt;<span class="type">double</span>&gt;&#123;</span><br><span class="line">  <span class="keyword">constexpr</span> <span class="type">static</span> <span class="type">bool</span> value = <span class="literal">true</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">is_floating_point</span> &lt;<span class="type">long</span> <span class="type">double</span>&gt; &#123;</span><br><span class="line">  <span class="keyword">constexpr</span> <span class="type">static</span> <span class="type">bool</span> value = <span class="literal">true</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h3 id="变量模版"><a href="#变量模版" class="headerlink" title="变量模版"></a>变量模版</h3><h3 id="别名模版"><a href="#别名模版" class="headerlink" title="别名模版"></a>别名模版</h3><h3 id="lambda-模版"><a href="#lambda-模版" class="headerlink" title="lambda 模版"></a>lambda 模版</h3>]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP协议深入理解</title>
    <url>/2023/01/31/1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/template/</url>
    <content><![CDATA[<span id="more"></span>







]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统之进程</title>
    <url>/2023/01/31/0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<span id="more"></span>


]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title>go 接口原理</title>
    <url>/2023/01/31/4-go/%E6%8E%A5%E5%8F%A3%E5%92%8C%E6%8C%87%E9%92%88/</url>
    <content><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>go context 原理</title>
    <url>/2023/01/31/4-go/go%20context/</url>
    <content><![CDATA[<p>原文 <a href="https://go.dev/blog/context">https://go.dev/blog/context</a></p>
<p><a href="https://go.dev/blog/pipelines">https://go.dev/blog/pipelines</a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>在 Go 服务器中，每个传入的请求都在其自己的 goroutine 中处理。 </p>
<p>请求处理程序通常会启动额外的 goroutine 来访问后台，比如数据库和 RPC 服务等。</p>
<p> 处理请求的 goroutines 集通常需要访问特定于请求的值，例如最终用户的身份、授权令牌和请求的截止日期。</p>
<p> 当请求被取消或超时时，所有处理该请求的 goroutines 都应该快速退出，以便系统可以回收它们正在使用的任何资源。</p>
<span id="more"></span>

<p>Google开发了一个<code>context</code>包，可以轻松地将请求范围的值、取消信号和截止日期跨 API 边界传递给处理请求所涉及的所有 goroutine。context包公开可用 。本文介绍了如何使用该包并提供了一个完整的工作示例。</p>
<h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A Context carries a deadline, cancellation signal, and request-scoped values</span></span><br><span class="line"><span class="comment">// across API boundaries. Its methods are safe for simultaneous use by multiple</span></span><br><span class="line"><span class="comment">// goroutines.</span></span><br><span class="line"><span class="keyword">type</span> Context <span class="keyword">interface</span> &#123;</span><br><span class="line">    <span class="comment">// Done returns a channel that is closed when this Context is canceled</span></span><br><span class="line">    <span class="comment">// or times out.</span></span><br><span class="line">    Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Err indicates why this context was canceled, after the Done channel</span></span><br><span class="line">    <span class="comment">// is closed.</span></span><br><span class="line">    Err() <span class="type">error</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Deadline returns the time when this Context will be canceled, if any.</span></span><br><span class="line">    Deadline() (deadline time.Time, ok <span class="type">bool</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Value returns the value associated with key or nil if none.</span></span><br><span class="line">    Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>Done</code>方法返回一个通道，该通道充当代表运行的函数的取消信号<code>Context</code>：当通道关闭时，函数应该放弃它们的工作并返回。<code>Err</code>方法返回一个错误，指示<code>Context</code>取消的原因。</p>
<p>Context 没有 Cancel 方法，原因与 Done 通道是仅接收的原因相同：接收取消信号的函数通常不是发送信号的函数。 特别是，当父操作为子操作启动 goroutine 时，这些子操作不应该能够取消父操作。 相反，WithCancel 函数（如下所述）提供了一种取消新 Context 值的方法。</p>
<p>一个 Context 对于多个 goroutine 同时使用是安全的。 代码可以将单个 Context 传递给任意数量的 goroutine，并取消该 Context 以向所有 goroutine 发出信号。</p>
<p>Deadline 方法允许函数确定它们是否应该开始工作； 如果剩下的时间太少，可能就不值得了。 代码也可以使用最后期限来设置 I&#x2F;O 操作的超时。</p>
<p>Value 允许上下文携带请求范围的数据。 该数据必须是安全的，以便多个 goroutine 同时使用。</p>
<h3 id="Derived-contexts"><a href="#Derived-contexts" class="headerlink" title="Derived contexts"></a>Derived contexts</h3><p>context 包提供了从现有值派生新 Context 值的函数。 这些值形成了一个树：当一个上下文被取消时，所有从它派生的上下文也被取消。</p>
<p>Background 是任何 Context 树的根； 它永远不会被取消：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Background returns an empty Context. It is never canceled, has no deadline,</span></span><br><span class="line"><span class="comment">// and has no values. Background is typically used in main, init, and tests,</span></span><br><span class="line"><span class="comment">// and as the top-level Context for incoming requests.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Background</span><span class="params">()</span></span> Context</span><br></pre></td></tr></table></figure>

<p>WithCancel 和 WithTimeout 返回派生的 Context 值，这些值可以比父 Context 更快地取消。 当请求处理程序返回时，通常会取消与传入请求关联的上下文。 WithCancel 对于在使用多个副本时取消冗余请求也很有用。 WithTimeout 对于设置对后端服务器的请求的截止日期很有用：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// WithCancel returns a copy of parent whose Done channel is closed as soon as</span></span><br><span class="line"><span class="comment">// parent.Done is closed or cancel is called.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCancel</span><span class="params">(parent Context)</span></span> (ctx Context, cancel CancelFunc)</span><br><span class="line"></span><br><span class="line"><span class="comment">// A CancelFunc cancels a Context.</span></span><br><span class="line"><span class="keyword">type</span> CancelFunc <span class="function"><span class="keyword">func</span><span class="params">()</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// WithTimeout returns a copy of parent whose Done channel is closed as soon as</span></span><br><span class="line"><span class="comment">// parent.Done is closed, cancel is called, or timeout elapses. The new</span></span><br><span class="line"><span class="comment">// Context&#x27;s Deadline is the sooner of now+timeout and the parent&#x27;s deadline, if</span></span><br><span class="line"><span class="comment">// any. If the timer is still running, the cancel function releases its</span></span><br><span class="line"><span class="comment">// resources.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithTimeout</span><span class="params">(parent Context, timeout time.Duration)</span></span> (Context, CancelFunc)</span><br></pre></td></tr></table></figure>

<p>WithValue 提供了一种将请求范围的值与 Context 相关联的方法：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// WithValue returns a copy of parent whose Value method returns val for key.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithValue</span><span class="params">(parent Context, key <span class="keyword">interface</span>&#123;&#125;, val <span class="keyword">interface</span>&#123;&#125;)</span></span> Context</span><br></pre></td></tr></table></figure>

<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>我们的示例是一个 HTTP 服务器，它通过将查询“golang”转发到 Google Web Search API 并呈现结果来处理像 &#x2F;search?q&#x3D;golang&amp;timeout&#x3D;1s 这样的 URL。 timeout 参数告诉服务器在该持续时间过去后取消请求。</p>
<p>代码分为三个包：</p>
<p>server 为 &#x2F;search 提供主要功能和处理程序。<br>userip 提供了从请求中提取用户 IP 地址并将其与 Context 相关联的功能。<br>google 提供了用于向 Google 发送查询的搜索功能。</p>
<h3 id="The-server-program"><a href="#The-server-program" class="headerlink" title="The server program"></a>The server program</h3><p>server 通过为 golang 提供前几个 Google 搜索结果来处理像 &#x2F;search?q&#x3D;golang 这样的请求。 它注册 handleSearch 来处理 &#x2F;search 端点。 处理程序创建一个名为 ctx 的初始上下文，并安排在处理程序返回时取消它。 如果请求中包含 timeout URL 参数，则 Context 在超时后自动取消：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handleSearch</span><span class="params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;</span><br><span class="line">    <span class="comment">// ctx is the Context for this handler. Calling cancel closes the</span></span><br><span class="line">    <span class="comment">// ctx.Done channel, which is the cancellation signal for requests</span></span><br><span class="line">    <span class="comment">// started by this handler.</span></span><br><span class="line">    <span class="keyword">var</span> (</span><br><span class="line">        ctx    context.Context</span><br><span class="line">        cancel context.CancelFunc</span><br><span class="line">    )</span><br><span class="line">    timeout, err := time.ParseDuration(req.FormValue(<span class="string">&quot;timeout&quot;</span>))</span><br><span class="line">    <span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="comment">// The request has a timeout, so create a context that is</span></span><br><span class="line">        <span class="comment">// canceled automatically when the timeout expires.</span></span><br><span class="line">        ctx, cancel = context.WithTimeout(context.Background(), timeout)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        ctx, cancel = context.WithCancel(context.Background())</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">defer</span> cancel() <span class="comment">// Cancel ctx as soon as handleSearch returns.</span></span><br></pre></td></tr></table></figure>

<p>处理程序从请求中提取查询，并通过调用 userip 包提取客户端的 IP 地址。 后端请求需要客户端的 IP 地址，因此 handleSearch 将其附加到 ctx：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Check the search query.</span></span><br><span class="line">query := req.FormValue(<span class="string">&quot;q&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> query == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">    http.Error(w, <span class="string">&quot;no query&quot;</span>, http.StatusBadRequest)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Store the user IP in ctx for use by code in other packages.</span></span><br><span class="line">userIP, err := userip.FromRequest(req)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    http.Error(w, err.Error(), http.StatusBadRequest)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">ctx = userip.NewContext(ctx, userIP)</span><br></pre></td></tr></table></figure>

<p>The handler calls <code>google.Search</code> with <code>ctx</code> and the <code>query</code>:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Run the Google search and print the results.</span></span><br><span class="line">start := time.Now()</span><br><span class="line">results, err := google.Search(ctx, query)</span><br><span class="line">elapsed := time.Since(start)</span><br></pre></td></tr></table></figure>

<p>If the search succeeds, the handler renders the results:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> err := resultsTemplate.Execute(w, <span class="keyword">struct</span> &#123;</span><br><span class="line">    Results          google.Results</span><br><span class="line">    Timeout, Elapsed time.Duration</span><br><span class="line">&#125;&#123;</span><br><span class="line">    Results: results,</span><br><span class="line">    Timeout: timeout,</span><br><span class="line">    Elapsed: elapsed,</span><br><span class="line">&#125;); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Print(err)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="Package-userip"><a href="#Package-userip" class="headerlink" title="Package userip"></a>Package userip</h3><p>userip 包提供了从请求中提取用户 IP 地址并将其与上下文相关联的功能。 上下文提供键值映射，其中键和值都是 interface{} 类型。 键类型必须支持相等，并且值必须安全地被多个 goroutine 同时使用。 像 userip 这样的包隐藏了这个映射的细节，并提供了对特定上下文值的强类型访问。</p>
<p>为了避免键冲突，userip 定义了一个未导出的类型键，并使用此类型的值作为上下文键：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// The key type is unexported to prevent collisions with context keys defined in</span></span><br><span class="line"><span class="comment">// other packages.</span></span><br><span class="line"><span class="keyword">type</span> key <span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// userIPkey is the context key for the user IP address.  Its value of zero is</span></span><br><span class="line"><span class="comment">// arbitrary.  If this package defined other context keys, they would have</span></span><br><span class="line"><span class="comment">// different integer values.</span></span><br><span class="line"><span class="keyword">const</span> userIPKey key = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>FromRequest 从 http.Request 中提取 userIP 值：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FromRequest</span><span class="params">(req *http.Request)</span></span> (net.IP, <span class="type">error</span>) &#123;</span><br><span class="line">    ip, _, err := net.SplitHostPort(req.RemoteAddr)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;userip: %q is not IP:port&quot;</span>, req.RemoteAddr)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>NewContext 返回一个带有提供的 userIP 值的新 Context：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewContext</span><span class="params">(ctx context.Context, userIP net.IP)</span></span> context.Context &#123;</span><br><span class="line">    <span class="keyword">return</span> context.WithValue(ctx, userIPKey, userIP)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>FromContext 从 Context 中提取用户 IP：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FromContext</span><span class="params">(ctx context.Context)</span></span> (net.IP, <span class="type">bool</span>) &#123;</span><br><span class="line">    <span class="comment">// ctx.Value returns nil if ctx has no value for the key;</span></span><br><span class="line">    <span class="comment">// the net.IP type assertion returns ok=false for nil.</span></span><br><span class="line">    userIP, ok := ctx.Value(userIPKey).(net.IP)</span><br><span class="line">    <span class="keyword">return</span> userIP, ok</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="Package-google"><a href="#Package-google" class="headerlink" title="Package google"></a>Package google</h3><p>google.Search 函数向 Google Web Search API 发出 HTTP 请求并解析 JSON 编码的结果。 它接受 Context 参数 ctx 并在请求运行时如果 ctx.Done 关闭则立即返回。</p>
<p>Google Web Search API 请求包括搜索查询和用户 IP 作为查询参数：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Search</span><span class="params">(ctx context.Context, query <span class="type">string</span>)</span></span> (Results, <span class="type">error</span>) &#123;</span><br><span class="line">    <span class="comment">// Prepare the Google Search API request.</span></span><br><span class="line">    req, err := http.NewRequest(<span class="string">&quot;GET&quot;</span>, <span class="string">&quot;https://ajax.googleapis.com/ajax/services/search/web?v=1.0&quot;</span>, <span class="literal">nil</span>)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    &#125;</span><br><span class="line">    q := req.URL.Query()</span><br><span class="line">    q.Set(<span class="string">&quot;q&quot;</span>, query)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If ctx is carrying the user IP address, forward it to the server.</span></span><br><span class="line">    <span class="comment">// Google APIs use the user IP to distinguish server-initiated requests</span></span><br><span class="line">    <span class="comment">// from end-user requests.</span></span><br><span class="line">    <span class="keyword">if</span> userIP, ok := userip.FromContext(ctx); ok &#123;</span><br><span class="line">        q.Set(<span class="string">&quot;userip&quot;</span>, userIP.String())</span><br><span class="line">    &#125;</span><br><span class="line">    req.URL.RawQuery = q.Encode()</span><br></pre></td></tr></table></figure>

<p>Search 使用辅助函数 httpDo 来发出 HTTP 请求，如果在处理请求或响应时 ctx.Done 关闭，则将其取消。 搜索传递一个闭包给 httpDo 处理 HTTP 响应：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> results Results</span><br><span class="line">err = httpDo(ctx, req, <span class="function"><span class="keyword">func</span><span class="params">(resp *http.Response, err <span class="type">error</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">defer</span> resp.Body.Close()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Parse the JSON search result.</span></span><br><span class="line">    <span class="comment">// https://developers.google.com/web-search/docs/#fonje</span></span><br><span class="line">    <span class="keyword">var</span> data <span class="keyword">struct</span> &#123;</span><br><span class="line">        ResponseData <span class="keyword">struct</span> &#123;</span><br><span class="line">            Results []<span class="keyword">struct</span> &#123;</span><br><span class="line">                TitleNoFormatting <span class="type">string</span></span><br><span class="line">                URL               <span class="type">string</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> err := json.NewDecoder(resp.Body).Decode(&amp;data); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> _, res := <span class="keyword">range</span> data.ResponseData.Results &#123;</span><br><span class="line">        results = <span class="built_in">append</span>(results, Result&#123;Title: res.TitleNoFormatting, URL: res.URL&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;)</span><br><span class="line"><span class="comment">// httpDo waits for the closure we provided to return, so it&#x27;s safe to</span></span><br><span class="line"><span class="comment">// read results here.</span></span><br><span class="line"><span class="keyword">return</span> results, err</span><br></pre></td></tr></table></figure>

<p>httpDo 函数运行 HTTP 请求并在新的 goroutine 中处理其响应。 如果 ctx.Done 在 goroutine 退出之前关闭，它将取消请求：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">httpDo</span><span class="params">(ctx context.Context, req *http.Request, f <span class="keyword">func</span>(*http.Response, <span class="type">error</span>)</span></span> <span class="type">error</span>) <span class="type">error</span> &#123;</span><br><span class="line">    <span class="comment">// Run the HTTP request in a goroutine and pass the response to f.</span></span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">error</span>, <span class="number">1</span>)</span><br><span class="line">    req = req.WithContext(ctx)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c &lt;- f(http.DefaultClient.Do(req)) &#125;()</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">        &lt;-c <span class="comment">// Wait for f to return.</span></span><br><span class="line">        <span class="keyword">return</span> ctx.Err()</span><br><span class="line">    <span class="keyword">case</span> err := &lt;-c:</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Adapting-code-for-Contexts"><a href="#Adapting-code-for-Contexts" class="headerlink" title="Adapting code for Contexts"></a>Adapting code for Contexts</h2><p>许多服务器框架提供包和类型来承载请求范围的值。 我们可以定义 Context 接口的新实现，以在使用现有框架的代码和需要 Context 参数的代码之间架起一座桥梁。</p>
<p>例如，Gorilla 的 <a href="http://www.gorillatoolkit.org/pkg/context">github.com&#x2F;gorilla&#x2F;context</a>  包允许处理程序通过提供从 HTTP 请求到键值对的映射来将数据与传入请求相关联。 在 gorilla.go 中，我们提供了一个 Context 实现，其 Value 方法返回与 Gorilla 包中特定 HTTP 请求关联的值。</p>
<p>其他包提供了类似于 Context 的取消支持。 例如，Tomb 提供了一个 Kill 方法，该方法通过关闭 Dying 通道来发出取消信号。 Tomb 还提供了等待这些 goroutine 退出的方法，类似于 sync.WaitGroup。 在 tomb.go 中，我们提供了一个 Context 实现，当它的父 Context 被取消或提供的 Tomb 被杀死时，该实现被取消。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>在 Google，我们要求 Go 程序员将 Context 参数作为第一个参数传递给传入和传出请求之间调用路径上的每个函数。 这使得许多不同团队开发的 Go 代码能够很好地互操作。 它提供了对超时和取消的简单控制，并确保安全凭证等关键值正确传输 Go 程序。</p>
<p>想要在 Context 上构建的服务器框架应该提供 Context 的实现，以便在它们的包和那些需要 Context 参数的包之间架起一座桥梁。 然后，他们的客户端库将接受来自调用代码的上下文。 通过为请求范围的数据和取消建立一个通用接口，Context 使包开发人员更容易共享代码以创建可扩展的服务。</p>
]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>go channel 用法及原理</title>
    <url>/2023/01/31/4-go/go%20channel/</url>
    <content><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="无缓冲"><a href="#无缓冲" class="headerlink" title="无缓冲"></a>无缓冲</h2><p>创建一个channel</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">chan1 := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br></pre></td></tr></table></figure>



<h2 id="有缓冲"><a href="#有缓冲" class="headerlink" title="有缓冲"></a>有缓冲</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">chan2 := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span> <span class="number">1</span>)</span><br></pre></td></tr></table></figure>



<span id="more"></span>

<h2 id="通道方向"><a href="#通道方向" class="headerlink" title="通道方向"></a>通道方向</h2><p>指定channel的方向</p>
<h2 id="通道选择器"><a href="#通道选择器" class="headerlink" title="通道选择器"></a>通道选择器</h2><p>select </p>
<h3 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h3><h3 id="非阻塞"><a href="#非阻塞" class="headerlink" title="非阻塞"></a>非阻塞</h3><p>default</p>
<h3 id="超时"><a href="#超时" class="headerlink" title="超时"></a>超时</h3><p>time</p>
<h2 id="通道关闭"><a href="#通道关闭" class="headerlink" title="通道关闭"></a>通道关闭</h2><p>close ，</p>
<p>可以接收关闭channel的数据，但是不能向关闭的channel发送数据</p>
<h2 id="通道遍历"><a href="#通道遍历" class="headerlink" title="通道遍历"></a>通道遍历</h2><p>for range 会阻塞</p>
<h2 id="Timer-和-ticker"><a href="#Timer-和-ticker" class="headerlink" title="Timer 和 ticker"></a>Timer 和 ticker</h2><p>timer 可以再到期之前结束</p>
<p>ticker 时隔一定时间执行一次。</p>
<h2 id="通道的实现"><a href="#通道的实现" class="headerlink" title="通道的实现"></a>通道的实现</h2>]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>go 闭包现象和原理</title>
    <url>/2023/01/31/4-go/go%20%E7%B3%BB%E5%88%97%E4%B9%8B%E9%97%AD%E5%8C%85/</url>
    <content><![CDATA[<h2 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h2><h3 id="概念："><a href="#概念：" class="headerlink" title="概念："></a>概念：</h3><span id="more"></span>

<h3 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h3><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3>]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>学习方法</title>
    <url>/2023/06/09/6-%E9%97%B2%E8%B0%88/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>平时突然感悟到的学习方法。</p>
<p>解题：极端，全是，全不是。</p>
<span id="more"></span>







]]></content>
      <categories>
        <category>方法</category>
      </categories>
      <tags>
        <tag>灵感</tag>
      </tags>
  </entry>
  <entry>
    <title>乐理初级</title>
    <url>/2023/08/19/9-%E9%9F%B3%E4%B9%90/%E4%B9%90%E7%90%86%E5%88%9D%E7%BA%A7/</url>
    <content><![CDATA[<h1 id="初级"><a href="#初级" class="headerlink" title="初级"></a>初级</h1><p>初级乐理知识。</p>
<span id="more"></span>

<h2 id="音阶"><a href="#音阶" class="headerlink" title="音阶"></a>音阶</h2><h3 id="相邻两个音之间的关系"><a href="#相邻两个音之间的关系" class="headerlink" title="相邻两个音之间的关系"></a>相邻两个音之间的关系</h3><p>全音关系</p>
<p>半音关系</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1 2 3	(半音关系) 4 5 6 7 (半音关系) 1 </span><br><span class="line"><span class="comment"># 其余都是全音关系</span></span><br></pre></td></tr></table></figure>

<p>吉他上相邻两个品格之间是半音关系，间隔一个品位的为全音关系。</p>
<h3 id="不相邻两个音之间的关系"><a href="#不相邻两个音之间的关系" class="headerlink" title="不相邻两个音之间的关系"></a>不相邻两个音之间的关系</h3><p>音程（度）</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1 2 3 4 5 6 7</span><br><span class="line"><span class="comment"># 1 - 5 , 5 度音程关系</span></span><br></pre></td></tr></table></figure>

<h4 id="三度音程关系"><a href="#三度音程关系" class="headerlink" title="三度音程关系"></a>三度音程关系</h4><p>大三度（不包含半音关系）</p>
<p>小三度（含有半音关系）</p>
<h2 id="和弦"><a href="#和弦" class="headerlink" title="和弦"></a>和弦</h2><h3 id="构成"><a href="#构成" class="headerlink" title="构成"></a>构成</h3><p>有三个或三个以上有一定音程关系的音的组合</p>
<p>三度音叠加构成和谐</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 三度音叠加构成和谐  1 3 5 构成一个和弦</span></span><br><span class="line">1 2 3 4 5 6 7 </span><br></pre></td></tr></table></figure>

<h3 id="名称"><a href="#名称" class="headerlink" title="名称"></a>名称</h3><p>大三和弦构成： 一个大三度加一个小三度  </p>
<p><strong>色彩特点</strong> 明亮坚定</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1 3 5</span><br></pre></td></tr></table></figure>

<p>小三和弦构成： 一个小三度加一个大三度</p>
<p><strong>色彩特点</strong> 忧伤紧张</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">2 4 6</span><br></pre></td></tr></table></figure>



<h2 id="节奏"><a href="#节奏" class="headerlink" title="节奏"></a>节奏</h2><h3 id="拍-（音符的单位）"><a href="#拍-（音符的单位）" class="headerlink" title="拍 （音符的单位）"></a>拍 （音符的单位）</h3><p>记录音的长短 (注意不同歌曲都有自己的拍速，每首歌的拍速是固定的)</p>
<p>一下一上为一拍</p>
<h3 id="音符-（单位-拍）"><a href="#音符-（单位-拍）" class="headerlink" title="音符 （单位 拍）"></a>音符 （单位 拍）</h3><p>全音符        4 拍 x</p>
<p>二分音符    2 拍 </p>
<p>四分音符   1 拍</p>
<p>八分音符  半拍</p>
<h2 id="动手"><a href="#动手" class="headerlink" title="动手"></a>动手</h2><p>四拍em和弦</p>
<p>两拍</p>
<p>一拍</p>
<p>半拍 (下上)</p>
<h1 id="初级进阶"><a href="#初级进阶" class="headerlink" title="初级进阶"></a>初级进阶</h1><h2 id="音名和唱名"><a href="#音名和唱名" class="headerlink" title="音名和唱名"></a>音名和唱名</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">简谱  1   2   3   4   5   6   7</span><br><span class="line">唱名  Do  Re  Mi  Fa  Sol La  Si   名字  为了全世界统一</span><br><span class="line">音名  C   D   E   F   G   A   B    位置  多种乐器统一</span><br><span class="line"></span><br><span class="line">音名的位置不变</span><br><span class="line">唱名的位置会变化</span><br></pre></td></tr></table></figure>

<h2 id="调"><a href="#调" class="headerlink" title="调"></a>调</h2><p>一串音阶在乐器上不同的位置</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1 2 3 4 5 6 7</span><br><span class="line">1 主音决定调 </span><br><span class="line">1 在 C 这个位置，表名是 C 调</span><br></pre></td></tr></table></figure>

<h3 id="大调和小调"><a href="#大调和小调" class="headerlink" title="大调和小调"></a>大调和小调</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1  2  3  4  5  6  7  1   大调音阶              以 1 为主音度音阶</span><br><span class="line"> 全  全 半 全 全  全  半</span><br><span class="line">6  7  1  2  3  4  5  6   小调音阶(自然小调音阶)  以 6 为主音的音阶</span><br><span class="line"> 全  半 全 全 半  全 全</span><br></pre></td></tr></table></figure>

<p>大调音阶 ：明亮 坚定  欢快</p>
<p>小调音阶 ：忧郁 悲伤 不安</p>
<h3 id="关系大小调"><a href="#关系大小调" class="headerlink" title="关系大小调"></a>关系大小调</h3><p>自然调式当中 音的排列相同 音的位置也相同 使用的调号也相同</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1 = C</span><br><span class="line">C D E F G A B  <span class="comment"># C 大调音阶</span></span><br><span class="line"></span><br><span class="line">A B C D E F G  <span class="comment"># A 小调音阶</span></span><br><span class="line"></span><br><span class="line">1 = G</span><br><span class="line">G A B C D E F  <span class="comment"># G 大调音阶</span></span><br><span class="line">1 2 3 4 5 6 7</span><br><span class="line">E F G A B C D  <span class="comment"># E 小调音阶</span></span><br><span class="line">6 7 1 2 3 4 5</span><br></pre></td></tr></table></figure>

<h2 id="和弦进阶"><a href="#和弦进阶" class="headerlink" title="和弦进阶"></a>和弦进阶</h2><h3 id="调内原位三和弦"><a href="#调内原位三和弦" class="headerlink" title="调内原位三和弦"></a>调内原位三和弦</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">C调</span><br><span class="line">音阶 1 2 3 4 5 6 7</span><br><span class="line">音名 C D E F G A B</span><br><span class="line">1 3 5 一级和弦 C</span><br><span class="line">2 4 6 二级和弦 Dm</span><br><span class="line">3 5 7 三级和弦 Em</span><br><span class="line">4 5 1 四级和弦 F</span><br><span class="line">5 7 2 五级和弦 G</span><br><span class="line">6 1 3 六级和弦 Am</span><br><span class="line">7 2 4 七级和弦 Bdim 减和弦，很少用</span><br><span class="line"><span class="comment"># 一个调内，七级和弦构成方式 ，所有调中和弦的大三度和小三度是固定的</span></span><br></pre></td></tr></table></figure>

<h2 id="转调"><a href="#转调" class="headerlink" title="转调"></a>转调</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># C 调</span></span><br><span class="line">级数：  1   2   3   4  5  6   7</span><br><span class="line">和弦：	 C   Dm  Em  F  G  Am  Bdim </span><br><span class="line"></span><br><span class="line"><span class="comment"># G 调</span></span><br><span class="line">级数：  1   2   3   4  5  6   7</span><br><span class="line">和弦：	 G   Am  Bm  C  D  Em  <span class="comment">#Fmdim </span></span><br><span class="line"><span class="comment"># C调转G调，转到对应的级数就可以， </span></span><br><span class="line"><span class="comment"># 可以快速记忆曲谱。只需要记住 调号和级数就可以</span></span><br></pre></td></tr></table></figure>

<h2 id="关系大小调和和弦的关系"><a href="#关系大小调和和弦的关系" class="headerlink" title="关系大小调和和弦的关系"></a>关系大小调和和弦的关系</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="节奏-1"><a href="#节奏-1" class="headerlink" title="节奏"></a>节奏</h2><p>拍号</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">6/8  一小节有六拍，以八分音符为一拍</span><br><span class="line"><span class="comment"># 强 弱 弱 次强 弱 弱</span></span><br><span class="line">4/4  一小节有四拍，以四分音符为一拍</span><br><span class="line"><span class="comment"># 强 弱 次强 弱</span></span><br><span class="line"><span class="comment"># 速度不同，轻重关系不同</span></span><br></pre></td></tr></table></figure>

<p>4&#x2F;4 拍的常用节奏型</p>
]]></content>
      <categories>
        <category>音乐</category>
      </categories>
      <tags>
        <tag>乐理</tag>
      </tags>
  </entry>
  <entry>
    <title>linux 基本分析工具</title>
    <url>/2023/01/31/8-linux/Linux%20%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<span id="more"></span>



]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title>理解分布式 cap 理论</title>
    <url>/2023/01/31/7-%E5%88%86%E5%B8%83%E5%BC%8F/cap%20/</url>
    <content><![CDATA[<h3 id="CAP理论概述"><a href="#CAP理论概述" class="headerlink" title="CAP理论概述"></a>CAP理论概述</h3><p>一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。</p>
<span id="more"></span>



<h3 id="Consistency-一致性"><a href="#Consistency-一致性" class="headerlink" title="Consistency 一致性"></a>Consistency 一致性</h3><p>系统结果一致</p>
<h3 id="Availability-可用性"><a href="#Availability-可用性" class="headerlink" title="Availability 可用性"></a>Availability 可用性</h3><p>系统可用</p>
<h3 id="Partition-Tolerance分区容错性"><a href="#Partition-Tolerance分区容错性" class="headerlink" title="Partition Tolerance分区容错性"></a>Partition Tolerance分区容错性</h3><p>出现分区问题，仍然可提供服务</p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式之抽象工厂模式</title>
    <url>/2023/01/31/5-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/01-%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82/</url>
    <content><![CDATA[<span id="more"></span>







]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>深入理解raft</title>
    <url>/2023/01/31/7-%E5%88%86%E5%B8%83%E5%BC%8F/raft/</url>
    <content><![CDATA[<span id="more"></span>



]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title>高效表达</title>
    <url>/2023/06/09/6-%E9%97%B2%E8%B0%88/%E9%AB%98%E6%A0%A1%E8%A1%A8%E8%BE%BE/</url>
    <content><![CDATA[<p>我们在和别人沟通的时候，经常会遇到这种情况，自己觉得表达清楚了，可是对方却不明白你在说什么。</p>
<p>比如跟同事分享自己的设计方案，明明准备的非常好，别人却不理解。跟领导汇报工作，明明做了很多，领导确认为你没做多少。下面我们就来聊聊如何高效表达。用最简单的话表达最有价值的信息。</p>
<span id="more"></span>

<h2 id="定主题"><a href="#定主题" class="headerlink" title="定主题"></a>定主题</h2><p>高效表达的第一步就是先说观点。</p>
<p>第一用一句话先表达你的观点。</p>
<p>第二直接表达，不要绕弯子。</p>
]]></content>
      <categories>
        <category>方法</category>
      </categories>
      <tags>
        <tag>表达</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式之设计原则</title>
    <url>/2023/01/31/5-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/00-%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h2 id="面向对象设计原则"><a href="#面向对象设计原则" class="headerlink" title="面向对象设计原则"></a>面向对象设计原则</h2><h3 id="依赖倒置原则（DIP）"><a href="#依赖倒置原则（DIP）" class="headerlink" title="依赖倒置原则（DIP）"></a>依赖倒置原则（DIP）</h3><ul>
<li><p>高层模块（稳定）不应该依赖底层模块（变化），二者都应该依赖于抽象（稳定）。</p>
</li>
<li><p>抽象（稳定）不应该依赖于实现细节（变化），实现细节应该依赖于抽象（稳定）。</p>
</li>
</ul>
<h3 id="开放封闭原则（OCP）"><a href="#开放封闭原则（OCP）" class="headerlink" title="开放封闭原则（OCP）"></a>开放封闭原则（OCP）</h3><ul>
<li><p>对拓展开放，对更改封闭。</p>
</li>
<li><p>类模块应该是可拓展的，但是不可修改。</p>
</li>
</ul>
<h3 id="单一职责原则（SRP）"><a href="#单一职责原则（SRP）" class="headerlink" title="单一职责原则（SRP）"></a>单一职责原则（SRP）</h3><ul>
<li>一个类应该仅有一个引起它变化的原因。</li>
<li>变化的方向隐含着类的责任。</li>
</ul>
<h3 id="Liskov-替换原则（LSP）"><a href="#Liskov-替换原则（LSP）" class="headerlink" title="Liskov 替换原则（LSP）"></a>Liskov 替换原则（LSP）</h3><ul>
<li>子类必须能够体会他们的基类（IS-A）。</li>
<li>继承表达类型抽象。</li>
</ul>
<h3 id="接口隔离原则（ISP）"><a href="#接口隔离原则（ISP）" class="headerlink" title="接口隔离原则（ISP）"></a>接口隔离原则（ISP）</h3><ul>
<li><p>不应该强迫客户程序依赖他们不用的方法</p>
</li>
<li><p>接口应该小而完备</p>
</li>
</ul>
<h3 id="优先使用对象组合，而不是类继承"><a href="#优先使用对象组合，而不是类继承" class="headerlink" title="优先使用对象组合，而不是类继承"></a>优先使用对象组合，而不是类继承</h3><ul>
<li>类继承通常为 “白箱复用”，对象组合通常为 “黑箱复用”。</li>
<li>继承在某种程度上破坏了封装性，子类父类耦合性高。</li>
</ul>
<h3 id="封装变化点"><a href="#封装变化点" class="headerlink" title="封装变化点"></a>封装变化点</h3><span id="more"></span>



<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>创建型</p>
<p>结构型</p>
<p>行为型</p>
<h3 id="针对接口编程，而不是针对实现编程"><a href="#针对接口编程，而不是针对实现编程" class="headerlink" title="针对接口编程，而不是针对实现编程"></a>针对接口编程，而不是针对实现编程</h3><h2 id="模版方法"><a href="#模版方法" class="headerlink" title="模版方法"></a>模版方法</h2><p>library 提供需需函数，application 实现library 的虚函数，librayr 提供程序的流程。</p>
<p>晚绑定 代替 早绑定。   早-&gt;晚。</p>
<h2 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h2><p>支持多种税收的计算，</p>
<p>枚举，if-else。 设计抽象类，和子类。</p>
<h2 id="观察者模式-x2F-event"><a href="#观察者模式-x2F-event" class="headerlink" title="观察者模式&#x2F; event"></a>观察者模式&#x2F; event</h2><p>文件分割器，进度条的显示。</p>
<h2 id="桥模式"><a href="#桥模式" class="headerlink" title="桥模式"></a>桥模式</h2>]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式之简单工厂模式</title>
    <url>/2023/01/31/5-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/02-%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82/</url>
    <content><![CDATA[<span id="more"></span>







]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>安装软件加速</title>
    <url>/2023/01/31/%E8%AE%BA%E6%96%87/0-brew/</url>
    <content><![CDATA[<p>安装软件加速</p>
<span id="more"></span>



<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">ALL_PROXY=socks5://127.0.0.1:1086 brew update</span><br><span class="line"></span><br><span class="line">brew upgrade go</span><br><span class="line"></span><br><span class="line">ALL_PROXY=socks5://127.0.0.1:1086 brew install xxx</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2021/02/13/5-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="面向对象设计原则"><a href="#面向对象设计原则" class="headerlink" title="面向对象设计原则"></a>面向对象设计原则</h2><h3 id="依赖倒置原则（DIP）"><a href="#依赖倒置原则（DIP）" class="headerlink" title="依赖倒置原则（DIP）"></a>依赖倒置原则（DIP）</h3><ul>
<li><p>高层模块（稳定）不应该依赖底层模块（变化），二者都应该依赖于抽象（稳定）。</p>
</li>
<li><p>抽象（稳定）不应该依赖于实现细节（变化），实现细节应该依赖于抽象（稳定）。</p>
</li>
</ul>
<h3 id="开放封闭原则（OCP）"><a href="#开放封闭原则（OCP）" class="headerlink" title="开放封闭原则（OCP）"></a>开放封闭原则（OCP）</h3><ul>
<li><p>对拓展开放，对更改封闭。</p>
</li>
<li><p>类模块应该是可拓展的，但是不可修改。</p>
</li>
</ul>
<h3 id="单一职责原则（SRP）"><a href="#单一职责原则（SRP）" class="headerlink" title="单一职责原则（SRP）"></a>单一职责原则（SRP）</h3><ul>
<li>一个类应该仅有一个引起它变化的原因。</li>
<li>变化的方向隐含着类的责任。</li>
</ul>
<h3 id="Liskov-替换原则（LSP）"><a href="#Liskov-替换原则（LSP）" class="headerlink" title="Liskov 替换原则（LSP）"></a>Liskov 替换原则（LSP）</h3><ul>
<li>子类必须能够体会他们的基类（IS-A）。</li>
<li>继承表达类型抽象。</li>
</ul>
<h3 id="接口隔离原则（ISP）"><a href="#接口隔离原则（ISP）" class="headerlink" title="接口隔离原则（ISP）"></a>接口隔离原则（ISP）</h3><ul>
<li><p>不应该强迫客户程序依赖他们不用的方法</p>
</li>
<li><p>接口应该小而完备</p>
</li>
</ul>
<h3 id="优先使用对象组合，而不是类继承"><a href="#优先使用对象组合，而不是类继承" class="headerlink" title="优先使用对象组合，而不是类继承"></a>优先使用对象组合，而不是类继承</h3><ul>
<li>类继承通常为 “白箱复用”，对象组合通常为 “黑箱复用”。</li>
<li>继承在某种程度上破坏了封装性，子类父类耦合性高。</li>
</ul>
<h3 id="封装变化点"><a href="#封装变化点" class="headerlink" title="封装变化点"></a>封装变化点</h3><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>创建型</p>
<p>结构型</p>
<p>行为型</p>
<h3 id="针对接口编程，而不是针对实现编程"><a href="#针对接口编程，而不是针对实现编程" class="headerlink" title="针对接口编程，而不是针对实现编程"></a>针对接口编程，而不是针对实现编程</h3><h2 id="模版方法"><a href="#模版方法" class="headerlink" title="模版方法"></a>模版方法</h2><p>library 提供需需函数，application 实现library 的虚函数，librayr 提供程序的流程。</p>
<p>晚绑定 代替 早绑定。   早-&gt;晚。</p>
<h2 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h2><p>支持多种税收的计算，</p>
<p>枚举，if-else。 设计抽象类，和子类。</p>
<h2 id="观察者模式-x2F-event"><a href="#观察者模式-x2F-event" class="headerlink" title="观察者模式&#x2F; event"></a>观察者模式&#x2F; event</h2><p>文件分割器，进度条的显示。</p>
<h2 id="桥模式"><a href="#桥模式" class="headerlink" title="桥模式"></a>桥模式</h2>]]></content>
  </entry>
  <entry>
    <title>CockRoackDB 概述</title>
    <url>/2023/01/31/2-%E6%95%B0%E6%8D%AE%E5%BA%93/1-cockroachdb/cockorachdb%20%E4%B9%8B%2001-%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<h1 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h1><p>CockroachDB 设计的两个目标：可拓展和一致性。开发者经常会有疑问我们是如何做到的。这篇文章详细解释CockroachDB的内部工作原理。对于使用者来说，不需要了解底层架构，所以此文是为了那些想要了解底层的用户。</p>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>CockroachDB 设计目标：</p>
<ul>
<li>使人们的生活更轻松，这意味着对于用户来说高度自动化，对于开发者来说更简单。</li>
<li>提供行业领先的一致性，即使在大规模部署当中也是，这意味着使用分布式事务，以及消除最终一致性问题和 过期读的问题。</li>
<li>创建一个始终在线的数据库，该数据库所有节点接受读和写，而不产生冲突。</li>
<li>允许在任何平台中部署，不需要绑定平台和供应商。</li>
<li>支持处理关系数据的工具，比如SQL。</li>
</ul>
<p>通过这些特性的融合，我们希望 CockroachDB 帮助您构建全球性、可扩展、弹性的部署和应用程序。</p>
<p>在阅读我们的架构文档之前了解一些术语会很有帮助。</p>
<span id="more"></span>

<h2 id="数据库术语"><a href="#数据库术语" class="headerlink" title="数据库术语"></a>数据库术语</h2><table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody><tr>
<td>Consistency</td>
<td>事务必须仅以允许的方式更改受影响数据的要求。 CockroachDB 在 ACID 语义和 CAP 定理的意义上都使用了“一致性”，尽管没有任何一个定义那么正式。</td>
</tr>
<tr>
<td>isolation</td>
<td>一个事务可能受同时运行的其他事务影响的程度。 CockroachDB 提供了 SERIALIZABLE 隔离级别，这是可能的最高级别，并保证每个提交的事务具有相同的结果，就好像每个事务一次运行一个一样。</td>
</tr>
<tr>
<td>Consensus</td>
<td>就事务是提交还是中止达成一致的过程。 CockroachDB 使用 Raft 共识协议。 在 CockroachDB 中，当一个范围接收到写入时，包含该范围副本的节点的法定人数会确认写入。 这意味着您的数据得到安全存储，并且大多数节点都同意数据库的当前状态，即使某些节点处于脱机状态。<br/><br/>当写入未达成共识时，前进进程停止以保持集群内的一致性。</td>
</tr>
<tr>
<td>Replication</td>
<td>创建和分发数据副本以及确保这些副本保持一致的过程。 CockroachDB 要求所有写入在被视为已提交之前传播到数据副本的法定人数。 这确保了数据的一致性。</td>
</tr>
<tr>
<td>transation</td>
<td>在数据库上执行的一组满足 ACID 语义要求的操作。 这是确保开发人员可以信任其数据库中的数据的一致系统的关键特性。 有关 CockroachDB 中事务如何工作的更多信息，请参阅事务层。</td>
</tr>
<tr>
<td>Multi-active availability</td>
<td>一种基于共识的高可用性概念，允许集群中的每个节点处理存储数据子集的读取和写入（基于每个范围）。 这与主动-被动复制（主动节点接收 100% 的请求流量）和主动-主动复制（所有节点都接受请求但通常不能保证读取是最新的和快速的）形成对比。</td>
</tr>
</tbody></table>
<h2 id="CockroachDB-架构术语"><a href="#CockroachDB-架构术语" class="headerlink" title="CockroachDB 架构术语"></a>CockroachDB 架构术语</h2><table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody><tr>
<td>cluster</td>
<td>一组相互连接的存储节点，它们协作组织事务、容错和数据重新平衡。</td>
</tr>
<tr>
<td>node</td>
<td>CockroachDB 的单个实例。 一个或多个节点形成一个集群。</td>
</tr>
<tr>
<td>range</td>
<td>CockroachDB 将所有用户数据（表、索引等）和几乎所有系统数据存储在键值对的排序映射中。 这个键空间被分成称为范围的连续块，这样每个键都可以在一个范围内找到。<br/><br/>从 SQL 的角度来看，表及其二级索引最初映射到单个范围，其中范围中的每个键值对代表表中的单个行（也称为主索引，因为表是按主键排序的） 或二级索引中的单行。 一旦范围的大小达到 512 MiB（默认值），它就会被分成两个范围。 随着表及其索引的不断增长，这些新范围的过程将继续进行。</td>
</tr>
<tr>
<td>Replica</td>
<td>存储在节点上的范围的副本。 默认情况下，每个范围在不同节点上有三个副本。</td>
</tr>
<tr>
<td>Leasholder</td>
<td>持有“范围租约”的副本。 此副本接收并协调该范围的所有读取和写入请求。<br/><br/>对于大多数类型的表和查询，租用者是唯一可以提供一致读取（返回“最新”数据的读取）的副本。</td>
</tr>
<tr>
<td>raft protocol</td>
<td>CockreactDB中采用的共识协议可确保您的数据安全存储在多个节点上，并且这些节点即使其中一些暂时断开连接，也可以同意当前状态。</td>
</tr>
<tr>
<td>Raft leader</td>
<td>对于每个范围，是写作请求的“领导者”的副本。 领导者使用 raft 协议来确保大多数复本（领导者和足够的追随者）根据其 raft 日志达成一致，然后再进行写作。 raft 领导人几乎总是与 leaseholder 是相同的复本。</td>
</tr>
<tr>
<td>Raft log</td>
<td>按时间订购的日志写入其复制品已达成协议的范围。 该日志与每个副本一起存在，并且是一致复制的真实范围的来源。</td>
</tr>
</tbody></table>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>CockroachDB 在机器上启动使用下面两条命令。</p>
<ul>
<li>cockroach  start 启动集群中所有节点使用 –jion 标记 ，因此该过程知道它可以与之通信的所有其他机器。</li>
<li>cockroach init执行初始化集群。</li>
</ul>
<p>一旦初始化了CockacredDB群集，开发人员就会通过兼容 postgresql 的SQL API与CockreactDB相互作用。 得益于群集中所有节点的对称行为，您可以将SQL请求发送到任何节点； 这使蟑螂易于与负载平衡器集成。</p>
<p>接收SQL远程过程调用（RPC）后，节点将它们转换为 kv 操作 在分布式事务的存储中。</p>
<p>当这些RPC开始用数据填充群集时，CockroachdB开始算法将您的数据分配在群集的节点之间，将数据分解为我们称为 ragne 的512个MIB块。 默认情况下，每个range 至少复制至至少3个节点，以确保生存能力。 这样可以确保如果有任何节点下降，您仍然拥有可用于以下数据的数据的副本：</p>
<ul>
<li>继续提供读写。</li>
<li>持续负责数据到其他节点。</li>
</ul>
<p>如果一个节点接收到读或写请求无法直接处理，它会找到可以处理该请求的节点，并与该节点通信。这意味着您不需要知道在群集中存储了数据的特定部分；CockroachDB 为您跟踪它，并启用每个节点的对称读&#x2F;写行为。</p>
<p>对数据范围内对数据进行的任何更改都取决于共识算法，以确保大多数范围的复制品同意进行更改。 这就是蟑螂实现行业领先的隔离的方式，可以使其能够为您的应用提供一致的读取和写入，而不管您与哪种节点进行了交流。</p>
<p>最终，使用有效的存储引擎将数据写入并从磁盘上读取，该引擎能够跟踪数据的时间戳。 这是一个好处，可以让我们支持AS OF SYSTEM TIME 的SQL标准，从而让您在一段时间内找到历史数据。</p>
<h2 id="五层"><a href="#五层" class="headerlink" title="五层"></a>五层</h2><table>
<thead>
<tr>
<th>Layer</th>
<th>Order</th>
<th>Purpose</th>
</tr>
</thead>
<tbody><tr>
<td>SQL</td>
<td>1</td>
<td>转换 sql 到 kv 操作</td>
</tr>
<tr>
<td>Transitional</td>
<td>2</td>
<td>允许原子修改 多个kv 操作</td>
</tr>
<tr>
<td>Distribution</td>
<td>3</td>
<td>复制 kv range</td>
</tr>
<tr>
<td>Replication</td>
<td>4</td>
<td>一致和同步复制KV范围在许多节点上范围。 该层还可以使用共识算法进行一致的读取</td>
</tr>
<tr>
<td>Storage</td>
<td>5</td>
<td>读写 kv 在磁盘</td>
</tr>
</tbody></table>
<h1 id="SQL-层"><a href="#SQL-层" class="headerlink" title="SQL 层"></a>SQL 层</h1><p>sql 层给 开发者提供 SQL API 并且将 sql 语句转换为 读写请求到 key-velue store。并且通过事务层。</p>
<p>包含以下子层：</p>
<ul>
<li>sql api，用户的接口</li>
<li>Parser， 将sql 语句转换为 AST树</li>
<li>Cost-based optimizer，将 AST树转换为被优化的逻辑计划</li>
<li>Physical planner 将逻辑计划转换为物理计划，给集群中一个或者多个节点执行</li>
<li>SQL execution engine，执行物理计划通过创建 读写请求给底层的 key-value store</li>
</ul>
<h2 id="概览-1"><a href="#概览-1" class="headerlink" title="概览"></a>概览</h2><p>一旦CockroachDB被部署成功，开发者们需要一个连接串连接到集群，他们可以开始工作使用 SQL。</p>
<p>因为CockroachDB集群中每个节点上对等的，开发者可以从任何一个节点发送请求。接受请求的节点称为”gateway node”，执行请求并且响应客户端。</p>
<p>对集群的请求以 SQL 语句的形式到达，但数据最终以键值 (KV) 对的形式写入和读取存储层。 为了处理这个问题，SQL 层将 SQL 语句转换为 KV 操作计划，然后将其传递给事务层。</p>
<h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><h3 id="关系结构"><a href="#关系结构" class="headerlink" title="关系结构"></a>关系结构</h3><p>开发人员将存储在 CockroachDB 中的数据视为由行和列组成的关系结构。 行和列的集合被进一步组织成表格。 然后将表的集合组织到数据库中。 CockroachDB 集群可以包含许多数据库。</p>
<p>CockroachDB 提供了典型的关系特征，如约束（例如外键）。 这些特性意味着应用程序开发人员可以相信数据库将确保应用程序数据的结构一致； 数据验证不需要单独构建到应用程序逻辑中。</p>
<h3 id="SQL-API"><a href="#SQL-API" class="headerlink" title="SQL API"></a>SQL API</h3><p>CockroachDB 实现了大部分 ANSI SQL 标准以显示其关系结构。</p>
<p>重要的是，通过 SQL API，开发人员可以像通过任何 SQL 数据库（使用 BEGIN、COMMIT 等）一样访问 ACID 语义事务。</p>
<h3 id="PostgreSQL-wire-protocol"><a href="#PostgreSQL-wire-protocol" class="headerlink" title="PostgreSQL wire protocol"></a>PostgreSQL wire protocol</h3><p>SQL 查询通过 PostgreSQL 协议访问集群。 </p>
<h3 id="SQL-parser-planner-executor"><a href="#SQL-parser-planner-executor" class="headerlink" title="SQL parser, planner, executor"></a>SQL parser, planner, executor</h3><p>当 CockroachDB 集群中的节点接收到来自客户端的 SQL 请求时，它会解析语句并创建优化的逻辑查询计划，该计划会进一步转换为物理查询计划。 最后，执行物理计划。</p>
<h4 id="Parsing"><a href="#Parsing" class="headerlink" title="Parsing"></a>Parsing</h4><p>SQL 查询根据我们的 yacc 文件（描述我们支持的语法）进行解析，每个查询的 SQL 版本都被转换为抽象语法树 (AST)。</p>
<h4 id="Logical-planning"><a href="#Logical-planning" class="headerlink" title="Logical planning"></a>Logical planning</h4><p>在逻辑计划阶段，AST 树被转换为一个查询计划通过以下步骤。</p>
<ol>
<li>AST 被转换为高级逻辑查询计划。 在此转换过程中，CockroachDB 还执行语义分析，其中包括以下操作：</li>
</ol>
<ul>
<li>检查查询是否是 SQL 语言中的有效语句。</li>
<li>将名称（例如表或变量的名称）解析为其值。</li>
<li>消除不需要的中间计算，例如，将 0.6 + 0.4 替换为 1.0。 这也称为常量折叠。</li>
<li>最终确定用于中间结果的数据类型，例如，当查询包含一个或多个子查询时。</li>
</ul>
<ol start="2">
<li>使用一系列始终有效的转换简化了逻辑计划。 例如，a BETWEEN b AND c 可以转换为 a &gt;&#x3D; b AND a &lt;&#x3D; c。</li>
<li>使用搜索算法优化逻辑计划，该算法评估执行查询的许多可能方式并选择成本最低的执行计划。</li>
</ol>
<p>上述最后一步的结果是优化的逻辑计划。 要查看基于成本的优化器生成的逻辑计划，请使用 EXPLAIN (OPT) 语句。</p>
<h4 id="Physical-planning"><a href="#Physical-planning" class="headerlink" title="Physical planning"></a>Physical planning</h4><p>物理计划阶段根据 range 的位置信息决定那个节点参与查询的执行。这就是CockroachDB 决定分布式执行在靠近存储位置的地方。</p>
<p>更具体地说，物理计划阶段将 逻辑计划期间生成 的 逻辑计划 转换为物理 SQL 运算符的有向无环图 (DAG)。 可以通过运行 EXPLAIN(DISTSQL) 语句查看这些运算符。</p>
<p>关于是否在多个节点上分发查询的决定是由一种启发式方法做出的，该方法估计需要通过网络发送的数据量。 只需要少量行的查询在网关节点上执行。 其他查询分布在多个节点上。</p>
<p>例如，当一个查询被分发时，物理计划阶段将扫描操作从逻辑计划拆分为多个物理 TableReader 操作符，每个节点一个包含扫描读取的范围。 然后将剩余的逻辑操作（可能执行过滤器、连接和聚合）安排在与 TableReader 相同的节点上。 这导致执行的计算尽可能接近物理数据。</p>
<h4 id="Query-execution"><a href="#Query-execution" class="headerlink" title="Query execution"></a>Query execution</h4><p>物理计划的组成部分被发送到一个或多个节点执行。 在每个节点上，CockroachDB 生成一个逻辑处理器来计算查询的一部分。 节点内部或跨节点的逻辑处理器通过逻辑数据流相互通信。 查询的组合结果被发送回接收查询的第一个节点，以进一步发送到 SQL 客户端。</p>
<p>每个处理器对查询操作的标量值使用编码形式。 这是一种二进制形式，不同于 SQL 中使用的形式。 因此，SQL 查询中列出的值必须进行编码，并且在逻辑处理器之间通信以及从磁盘读取的数据必须在将其发送回 SQL 客户端之前进行解码。</p>
<h4 id="Vectorized-query-execution"><a href="#Vectorized-query-execution" class="headerlink" title="Vectorized query execution"></a>Vectorized query execution</h4><p>如果启用了向量化执行，则将物理计划发送到节点以由向量化执行引擎处理。</p>
<p>向量化引擎收到物理计划后，从磁盘中批量读取表数据，并将数据从行格式转换为列格式。 这些批次的列数据存储在内存中，因此引擎可以在执行过程中快速访问它们。</p>
<p>矢量化引擎使用专门的预编译函数，可以快速迭代特定类型的列数据数组。 当引擎处理每列数据时，函数的列输出存储在内存中。</p>
<p>在处理完输入缓冲区中的所有列数据后，引擎将列输出转换回行格式，然后将处理后的行返回给 SQL 接口。 当一批表数据处理完毕后，引擎会读取下一批表数据进行处理，直到查询执行完毕。</p>
<h3 id="Encoding"><a href="#Encoding" class="headerlink" title="Encoding"></a>Encoding</h3><p>尽管 SQL 查询是用可解析的字符串编写的，但 CockroachDB 的较低层主要以字节为单位处理。 这意味着在 SQL 层，在查询执行中，CockroachDB 必须将行数据从它们的 SQL 表示形式转换为字节，并将从较低层返回的字节转换为可以传递回客户端的 SQL 数据。</p>
<p>同样重要的是——对于索引列——这种字节编码保持与它所代表的数据类型相同的排序顺序。 这是因为 CockroachDB 最终将数据存储在排序的键值映射中的方式； 以与其所代表的数据相同的顺序存储字节使我们能够有效地扫描 KV 数据。</p>
<p>然而，对于非索引列（例如，非 PRIMARY KEY 列），CockroachDB 改为使用占用较少空间但不保留排序的编码（称为“值编码”）。</p>
<h3 id="DistSQL"><a href="#DistSQL" class="headerlink" title="DistSQL"></a>DistSQL</h3><p>因为 CockroachDB 是一个分布式数据库，所以我们为一些查询开发了一个分布式 SQL（DistSQL）优化工具，它可以显着加快涉及多个范围的查询。 尽管 DistSQL 的体系结构值得拥有它自己的文档，但这个粗略的解释可以提供一些关于它是如何工作的洞察力。</p>
<p>在非分布式查询中，协调节点接收与其查询匹配的所有行，然后对整个数据集执行任何计算。</p>
<p>但是，对于与 DistSQL 兼容的查询，每个节点都会对其包含的行进行计算，然后将结果（而不是整个行）发送到协调节点。 协调节点然后聚合来自每个节点的结果，最后向客户端返回单个响应。</p>
<p>这大大减少了带到协调节点的数据量，并利用了经过充分验证的并行计算概念，最终减少了完成复杂查询所需的时间。 此外，这会在已经存储数据的节点上处理数据，这让 CockroachDB 可以处理大于单个节点存储的行集。</p>
<p>为了以分布式方式运行 SQL 语句，我们引入了几个概念：</p>
<ul>
<li>逻辑计划：类似于上面描述的 AST&#x2F;planNode 树，它表示通过计算阶段的抽象（非分布式）数据流。</li>
<li>物理计划：物理计划在概念上是逻辑计划节点到运行 cockroach 的物理机器的映射。 逻辑计划节点根据集群拓扑进行复制和专门化。 与上面的 planNodes 一样，物理计划的这些组件是在集群上调度和运行的。</li>
</ul>
<h2 id="Schema-changes"><a href="#Schema-changes" class="headerlink" title="Schema changes"></a>Schema changes</h2><p>CockroachDB 使用允许表在模式更改期间保持在线（即能够提供读取和写入服务）的协议来执行模式更改，例如添加列或二级索引。 该协议允许集群中的不同节点在不同时间异步转换到新的表模式。</p>
<p>模式更改协议将每个模式更改分解为一系列增量更改，以达到预期的效果。</p>
<p>例如，添加二级索引需要在开始版本和结束版本之间有两个中间架构版本，以确保索引在整个集群中的写入时更新，然后才可用于读取。 为了确保数据库在整个模式更改过程中保持一致状态，我们强制执行不变量，即在集群中始终使用最多两个连续版本的该模式。</p>
<h1 id="事务层"><a href="#事务层" class="headerlink" title="事务层"></a>事务层</h1><p>事务层实现对事务 ACID 的支持通过协调当前的操作。</p>
<h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><p>CockroachDB 认为一致性是数据库最重要的特征。没有他，开发者不能构建可靠的工具，企业将遭受潜在的微妙的难以发现的异常。</p>
<p>为了提供一致性，CockroachDB实现了完整的 ACID事务语法在事务层。然而，最重要的是，所有的语句都是作为事务来处理的，包括单条语句，这有时被称为“autocommit mode”，因为它的行为就像每条语句后面都有一个 COMMIT。</p>
<p>因为 CockroachDB 支持跨整个集群的事务（包括跨范围和跨表事务），所以它使用称为 Parallel Commits 的分布式原子提交协议来实现正确性。</p>
<h3 id="Writes-and-reads-phase-1"><a href="#Writes-and-reads-phase-1" class="headerlink" title="Writes and reads (phase 1)"></a>Writes and reads (phase 1)</h3><h4 id="Writing"><a href="#Writing" class="headerlink" title="Writing"></a>Writing</h4><p>当事务层执行写操作的时候，他不直接将值写到磁盘中，他会创建以下几种事情帮助协调分布式事务：</p>
<ul>
<li><p><strong>Locks</strong> 所有事务的写，表示临时的、未提交的状态。 CockroachDB 有几种不同类型的锁：</p>
<ul>
<li><p><strong>Unreplicated Locks</strong> are stored in an in-memory, per-node lock table by the <a href="https://www.cockroachlabs.com/docs/stable/architecture/transaction-layer.html#concurrency-control">concurrency control</a> machinery. These locks are not replicated via <a href="https://www.cockroachlabs.com/docs/v21.2/architecture/replication-layer#raft">Raft</a>.</p>
</li>
<li><p><strong>Replicated Locks</strong> (also known as <a href="https://www.cockroachlabs.com/docs/stable/architecture/transaction-layer.html#write-intents">write intents</a>) are replicated via <a href="https://www.cockroachlabs.com/docs/v21.2/architecture/replication-layer#raft">Raft</a>, and act as a combination of a provisional value and an exclusive lock. They are essentially the same as standard <a href="https://www.cockroachlabs.com/docs/v21.2/architecture/storage-layer#mvcc">multi-version concurrency control (MVCC)</a> values but also contain a pointer to the <a href="https://www.cockroachlabs.com/docs/stable/architecture/transaction-layer.html#transaction-records">transaction record</a> stored on the cluster.</p>
</li>
</ul>
</li>
<li><p>A <strong>transaction record</strong> stored in the range where the first write occurs, which includes the transaction’s current state (which is either <code>PENDING</code>, <code>STAGING</code>, <code>COMMITTED</code>, or <code>ABORTED</code>).</p>
</li>
</ul>
<h4 id="Reading"><a href="#Reading" class="headerlink" title="Reading"></a>Reading</h4><p>如果事务没有被终止，事务层执行读操作。如果一个读操作遇到了标准的 MVCC 值，一切都很好。但是如果遇到了 写意向，操作必须解决事务冲突。</p>
<p>CockroachDB 提供两种类型的读：</p>
<ul>
<li>强一致性读：这是默认的也是最常用的读。这些读通过 leaseholder 并且可以看到读事务开始之前的所有写。他们总是返回正确最新的数据。</li>
<li>stale reads：这是有用的在你想要获取更快的读，而不是更新的数据的时候。他们可以用只读事务使用 <code>AS OF SYSTEM TIME</code> 语句。他们不需要通过 leaseholder ，因为他们可以确保一致性读通过读取不高于 closed timestamp 时间戳的本地副本。详细看 foller Rdads。<font color='red'> 为什么在非 leaseholder 上读，说明 leaseholder 可以看到最新的写，非leaseholder看不到 ？</font></li>
</ul>
<h3 id="Commits-phase-2"><a href="#Commits-phase-2" class="headerlink" title="Commits (phase 2)"></a>Commits (phase 2)</h3><p>CockroachDB 检查运行时的事务的记录，如果是 ABORTED。将重试事务。<font color='red'> 为什么会是 aborted ？</font></p>
<p>大多数情况下，他设置事务记录状态为 STAGING。检查 pending 状态事务的写意向事务已经成功（被集群复制）。</p>
<p><font color='red'>  如何检查是否被复制 ？</font></p>
<p>如果事务通过了检查，CockroacDB 返回客户端成功，进入 cleanup 阶段。到这时候，事务已经被提交。</p>
<p>关于更多的提交协议，看 并行提交。</p>
<h3 id="Cleanup-asynchronous-phase-3"><a href="#Cleanup-asynchronous-phase-3" class="headerlink" title="Cleanup (asynchronous phase 3)"></a>Cleanup (asynchronous phase 3)</h3><p>事务被提交后，他应当被标记，所有的写意向应该被解析。为了达到这个目的。 Coordinating 节点记录了所有写过的 keys。</p>
<p><font color='red'> 记录所有写过的 keys 干嘛用 ？清理的时候用</font></p>
<ul>
<li>将事务状态从 STAGING 改为 COMMITED。</li>
<li>解析事务的写意向到 MVCC。通过移除事务记录的指针。</li>
<li>删除写意向。</li>
</ul>
<p>这是一个简单的优化，如果操作遇到了写意向，他们总是检查事务状态，任何操作可以解析和移除写意向通过检查事务记录的状态。</p>
<h2 id="技术细节和组件"><a href="#技术细节和组件" class="headerlink" title="技术细节和组件"></a>技术细节和组件</h2><h3 id="时间和混合逻辑时钟"><a href="#时间和混合逻辑时钟" class="headerlink" title="时间和混合逻辑时钟"></a>时间和混合逻辑时钟</h3><p>在分布式系统中，排序和因果关系是一个复杂的问题。虽然可以完全依赖 Raft 共识来保持可序列化性，但读取数据效率低下。为了优化读性能，CockroachDB 实现了混合逻辑时钟，由一个物理组件（总是接近本地时间） 和一个逻辑组件（用于区分相同物理组件的事件）。这意味着 HTC 时间总是大于等于 wall time。</p>
<p><font color='red'> HLC 如何提高读性能 ？</font></p>
<p>在事务方面，网关节点总是给事务选择一个 HLC 时间戳。无论何时，当提及事务时间戳的时候，他一定是一个 HLC 时间，这个时间戳也会用来跟踪 MVCC 的值。提供事务一致性的保障。</p>
<p>当节点向其他节点发送请求时，它们包括由其本地 HLC 生成的时间戳（包括物理和逻辑组件）。 当节点接收到请求时，它们会将发送者随事件提供的时间戳通知其本地 HLC。 这对于保证节点上读取&#x2F;写入的所有数据的时间戳小于下一个 HLC 时间很有用。</p>
<p>然后，这让主要负责范围的节点（即，leaseholder）通过确保读取数据的事务处于大于它正在读取的 MVCC 值的 HLC 时间（即，读取总是发生在“之后 “写）。</p>
<h4 id="Max-clock-offset-enforcement"><a href="#Max-clock-offset-enforcement" class="headerlink" title="Max clock offset enforcement"></a>Max clock offset enforcement</h4><p>CockroachDB 需要中等级别的时钟同步以保持数据一致性。 出于这个原因，当一个节点检测到它的时钟与集群中至少一半的其他节点不同步到允许的最大偏移量（默认 500ms）的 80% 时，它会立即崩溃。</p>
<p>尽管无论时钟偏移如何都可以保持可串行化的一致性，但在配置的时钟偏移范围之外的偏移可能会导致因果相关事务之间的单键线性化违规。 因此，通过在每个节点上运行 NTP 或其他时钟同步软件来防止时钟漂移太远非常重要。</p>
<p><font color='red'>物理时钟不一致会导致什么问题  ? </font></p>
<h3 id="时间戳缓存-Timestamp-cache"><a href="#时间戳缓存-Timestamp-cache" class="headerlink" title="时间戳缓存 (Timestamp cache)"></a>时间戳缓存 (Timestamp cache)</h3><p>作为提供可串行化的一部分，每当一个操作读取一个值时，我们将操作的时间戳存储在时间戳缓存中，它显示正在读取的值的高水位标记。</p>
<p>时间戳缓存是一种数据结构，用于存储有关 leaseholders 执行的读取的信息。 这用于确保一旦某个事务 t1 读取一行，另一个出现并尝试写入该行的事务 t2 将在 t1 之后排序，从而确保事务的串行顺序，即可串行化。</p>
<p><font color='red'> 时间戳缓存在哪个节点存储 ？使用的时候怎么查找 ？</font></p>
<p>每当发生写入时，都会根据时间戳缓存检查其时间戳。 如果时间戳小于时间戳缓存的最新值，我们会尝试将其事务的时间戳推到稍后的时间。 推送时间戳可能会导致事务在事务的第二阶段重新启动（请参阅读取刷新）。</p>
<h3 id="Closed-timestamps"><a href="#Closed-timestamps" class="headerlink" title="Closed timestamps"></a>Closed timestamps</h3><p>每个 CockroachDB range 都跟踪一个称为其关闭时间戳的属性，这意味着永远不会在该时间戳或低于该时间戳时引入新的写入。 关闭的时间戳在 leaseholder 上连续提前，并且比当前时间滞后某个目标时间间隔。 随着关闭的时间戳提前，通知会发送给每个 follower。 如果某个 range 接受小于或等于其关闭时间戳的写，则写入将被迫更改其时间戳，这可能会导致事务重试错误（请参阅读取刷新）。</p>
<p><font color='red'> 所以到底能不能接受 小于 closed timestamps 的写 ？如果可以，什么情况下可以？ </font></p>
<p>换句话说，closed timestamp 是该 range 的 leaseholder 向其 follower 副本的承诺，即它不会接受低于该时间戳的写入。 一般来说，leaseholder 会在过去几秒钟内连续关闭时间戳。 ？？？</p>
<p><font color='red'> colsed timestamp 是在什么情况下生成？什么时候更新？  什么时候会删除 ？</font></p>
<p>Closed timestamps 子系统通过将 closed timestamps 捎带到 Raft 命令上来将信息从 leaseholders 有者传播到 followers，使复制流与timestamp closing 同步。 这意味着，一旦 followers 副本将所有 Raft 命令应用到由 leaseholder 指定的 Raft log 中的位置，它就可以开始提供时间戳等于或低于关闭时间戳的读取。</p>
<p>一旦 followers 副本应用了上述 Raft 命令，它就拥有了为时间戳小于或等于关闭时间戳的读取提供服务所需的所有数据。</p>
<p>请注意，即使承租人发生变化，关闭的时间戳也是有效的，因为它们会在租约转移中保留。 一旦发生租约转移，新的租约人将不会违反旧租约人作出的封闭时间戳承诺。</p>
<p>封闭的时间戳提供了用于为低延迟历史（陈旧）读取（也称为跟随者读取）提供支持的保证。 跟随者读取在多区域部署中特别有用。</p>
<p>有关关闭时间戳和 Follower Reads 实现的更多信息，请参阅我们的博客文章 An Epic Read on Follower Reads。</p>
<h3 id="client-Txn-and-TxnCoordSender"><a href="#client-Txn-and-TxnCoordSender" class="headerlink" title="client.Txn and TxnCoordSender"></a>client.Txn and TxnCoordSender</h3><p>正如我们在 SQL 层的架构概述中提到的，CockroachDB 将所有 SQL 语句转换为键值（KV）操作，这就是数据最终存储和访问的方式。</p>
<p>SQL 层生成的所有 KV 操作都使用 client.Txn，它是 CockroachDB KV 层的事务接口——但是，正如我们上面讨论的，所有语句都被视为事务，因此所有语句都使用该接口。</p>
<p>然而，client.Txn 实际上只是 TxnCoordSender 的一个包装器，它在我们的代码库中起着至关重要的作用：</p>
<ul>
<li>处理事务的状态。 事务启动后，TxnCoordSender 开始向该事务的事务记录异步发送心跳消息，这表明它应该保持活动状态。 如果 TxnCoordSender 的心跳停止，则事务记录将移至 ABORTED 状态。</li>
<li>在事务进行中跟踪每个 被写的 key 和 key range 。</li>
<li>清理累计的写意向当事务终止或者提交的时候，所有的请求都作为事务的一部分通过相同的 TxnCoordSender 统计所有的 写意向，从而优化 cleanup 阶段。</li>
</ul>
<p>在设置了这个簿记之后，请求被传递到分布层中的 DistSender。</p>
<h3 id="Transaction-records"><a href="#Transaction-records" class="headerlink" title="Transaction records"></a>Transaction records</h3><p>为了跟踪事务执行的状态，我们将一个称为事务记录的值写入我们的键值存储。 一个事务的所有写意图都指向这个记录，这让任何事务都可以检查它遇到的任何写意图的状态。 这种规范记录对于支持分布式环境中的并发性至关重要。</p>
<p>事务记录总是写入与事务中的第一个 key 相同的 range ，这由 TxnCoordSender 知道。 但是，在出现以下任一情况之前，不会创建交易记录本身：</p>
<ul>
<li>写操作提交</li>
<li>The <code>TxnCoordSender</code> heartbeats the transaction</li>
<li>An operation forces the transaction to abort 强制终止事务</li>
</ul>
<p>鉴于这种机制，事务记录使用以下状态：</p>
<ul>
<li><code>PENDING</code>: Indicates that the write intent’s transaction is still in progress. 表示写入意图的事务仍在进行中。</li>
<li><code>COMMITTED</code>: Once a transaction has completed, this status indicates that write intents can be treated as committed values.  一旦事务完成，此状态表明写入意图可以被视为已提交的值。</li>
<li>STAGING：用于启用并行提交功能。 根据此记录引用的写入意图的状态，事务可能处于提交状态，也可能不处于提交状态。<font color='red'>  什么情况下提交 ？什么情况下未提交？ </font></li>
<li><code>ABORTED</code>: Indicates that the transaction was aborted and its values should be discarded.</li>
<li>记录不存在：如果一个事务遇到一个事务记录不存在的写意图，它使用写意图的时间戳来确定如何进行。 如果写入意图的时间戳在事务活跃度阈值内，则写入意图的事务被视为处于待处理状态，否则视为事务已中止。</li>
</ul>
<p>已提交事务的事务记录将一直保留，直到其所有写入意图都转换为 MVCC 值。</p>
<h3 id="Write-intents"><a href="#Write-intents" class="headerlink" title="Write intents"></a>Write intents</h3><p>CockroachDB 中的值不会直接写入存储层； 相反，值以称为“写入意图”的临时状态写入。 这些本质上是 MVCC 记录，其中添加了一个附加值，用于标识该值所属的事务记录。 它们可以被认为是复制锁和复制临时值的组合。</p>
<p>每当操作遇到写入意图（而不是 MVCC 值）时，它都会查找事务记录的状态以了解它应该如何处理写入意图值。 如果事务记录丢失，则操作检查写入意图的时间戳并评估它是否被视为过期。</p>
<p>CockroachDB 使用每个节点的内存锁表来管理并发控制。 此表包含正在进行的事务获取的锁的集合，并在评估期间发现写入意图时包含有关写入意图的信息。 有关详细信息，请参阅下面有关并发控制的部分。</p>
<h4 id="Resolving-write-intents"><a href="#Resolving-write-intents" class="headerlink" title="Resolving write intents"></a>Resolving write intents</h4><p>当一个操作遇到了写意向，他尝试解析，解析的结果依赖写意向上的事务记录：</p>
<p>COMMITTED：该操作读取写意图并通过删除写意图指向事务记录的指针将其转换为 MVCC 值。</p>
<p>ABORTED：写入意图被忽略并删除。</p>
<p>PENDING：这表明存在必须解决的事务冲突。</p>
<p>STAGING：这表明操作需要检查 是否 staging 状态的事务还在运行中，通过检查 事务 coordinator 是否仍然在心跳事务记录，如果 coordinator 仍然在心跳事务记录，操作需要等待。 关于更多，参考并行提交。</p>
<h3 id="Concurrency-control"><a href="#Concurrency-control" class="headerlink" title="Concurrency control"></a>Concurrency control</h3><p>并发管理器对传入请求进行排序，并在发出那些打算执行冲突操作的请求的事务之间提供隔离。 此活动也称为并发控制。</p>
<p>并发管理器结合了 lath manager  和 lock table 的操作来完成这项工作：</p>
<ul>
<li>latch manager 对传入请求进行排序并在这些请求之间提供隔离。</li>
<li>锁表提供请求的锁定和排序（与锁管理器一致）。 它是一个每个节点的内存数据结构，其中包含由进行中事务获取的锁的集合。 为了确保与现有的写入意图系统（也称为复制的排他锁）的兼容性，它会在评估请求的过程中发现这些外部锁时根据需要提取有关这些外部锁的信息。</li>
</ul>
<p>并发管理器支持使用 SELECT FOR UPDATE 语句通过 SQL 进行悲观锁定。 此语句可用于增加吞吐量并减少竞争操作的尾部延迟。</p>
<p>有关 concurrency manager 如何与 latch manager  和 lock table 一起工作的更多详细信息，请参阅以下部分：</p>
<h4 id="Concurrency-manager"><a href="#Concurrency-manager" class="headerlink" title="Concurrency manager"></a>Concurrency manager</h4><p>并发管理器是一种结构，它对传入的请求进行排序，并在发出那些打算执行冲突操作的请求的事务之间提供隔离。 在排序过程中，发现冲突并通过被动排队和主动推送的组合来解决任何发现的问题。 一旦对请求进行排序，就可以自由评估，而不必担心由于管理器提供的隔离而与其他进行中的请求发生冲突。 这种隔离在请求的生命周期内得到保证，但在请求完成后终止。</p>
<h1 id="分布层"><a href="#分布层" class="headerlink" title="分布层"></a>分布层</h1><p>分布层为集群中的数据提供一个统一的视图。</p>
<h2 id="概览-2"><a href="#概览-2" class="headerlink" title="概览"></a>概览</h2><p>为了使用户可以从任何一个节点访问集群中的数据，CockroackDB 将数据以 kv 对的形式存储在一个整体有序的map中。这个 key 空间描述集群中的所有数据和数据的位置，数据被划分到了 ranges 中，所有的key 都可以被找到在 range中。</p>
<p>CockroachDB 实现排序的map以便：</p>
<ul>
<li><strong>Simple lookups</strong>：因为我们确定了哪些节点负责数据的某些部分，所以查询能够快速定位到哪里可以找到他们想要的数据。</li>
<li><strong>Efficient scans</strong>：通过定义数据的顺序，在扫描过程中很容易找到特定范围内的数据。</li>
</ul>
<h3 id="排序map-整体结构"><a href="#排序map-整体结构" class="headerlink" title="排序map 整体结构"></a>排序map 整体结构</h3><p>整体排序的 map 由两个基本元素组成：</p>
<ul>
<li>System data，包括集群中源数据的位置。（在学多其他集群范围和本地数据中）。</li>
<li>User data，存储集群中表数据。</li>
</ul>
<h4 id="Meta-ranges"><a href="#Meta-ranges" class="headerlink" title="Meta ranges"></a>Meta ranges</h4><p>集群中所有 range 的位置存储在键空间开头的两级索引中，称为meta ragnes，其中第一级 (meta1) 寻址第二级，第二级 (meta2) 寻址数据 集群。</p>
<p>这个两级索引加上用户数据可以可视化为一棵树，根在 meta1，第二级在 meta2，树的叶子由保存用户数据的范围组成。</p>
<p>重要的是，每个节点都有关于在哪里定位 meta1 范围的信息（称为其范围描述符，详情如下），并且该范围永远不会被分割。</p>
<p>默认情况下，这种元范围结构允许我们处理多达 4EiB 的用户数据：我们可以处理 2^(18 + 18) &#x3D; 2^36 个范围； 每个范围寻址 2^26 B，我们总共寻址 2^(36+26) B &#x3D; 2^62 B &#x3D; 4EiB。 但是，使用更大的范围大小，可以进一步扩展此容量。</p>
<p>元范围主要被视为正常范围，并且像集群的 KV 数据的其他元素一样被访问和复制。</p>
<p>每个节点缓存它之前访问过的 meta2 范围的值，从而优化将来对该数据的访问。 每当一个节点发现它的 meta2 缓存对于特定键无效时，缓存会通过对 meta2 范围执行定期读取来更新。</p>
<h4 id="Table-data"><a href="#Table-data" class="headerlink" title="Table data"></a>Table data</h4><p>在节点的元范围之后是集群存储的 KV 数据。</p>
<p>每个表及其二级索引最初都映射到一个范围，其中范围中的每个键值对代表表中的单个行（也称为主索引，因为该表是按主键排序的）或二级索引。一旦范围的大小达到 512 MiB，它就会分成两个范围。这个过程继续作为一个表，它的索引继续增长。一旦表被拆分为多个范围，表和二级索引很可能将存储在不同的范围中。但是，范围仍然可以包含表和二级索引的数据。</p>
<p>默认的 512 MiB 范围大小对我们来说是一个最佳点，它既小到可以在节点之间快速移动，又大到可以存储一组有意义的连续数据，这些数据的键更有可能被一起访问。然后，这些范围会在您的集群周围重新排列，以确保可生存性。</p>
<p>这些表范围被复制（在恰当命名的复制层中），并且每个副本的地址存储在 meta2 范围中。</p>
<h3 id="Using-the-monolithic-sorted-map"><a href="#Using-the-monolithic-sorted-map" class="headerlink" title="Using the monolithic sorted map"></a>Using the monolithic sorted map</h3><p>如元范围部分所述，集群中所有范围的位置存储在两级索引中：</p>
<ul>
<li>第一级 (meta1) 处理第二级。</li>
<li>第二级（meta2）处理用户数据。</li>
</ul>
<p>这也可以可视化为一棵树，根在 meta1，第二层在 meta2，树的叶子由保存用户数据的范围组成。</p>
<p>当一个节点收到一个请求时，它会以自下而上的方式查找包含请求中键的范围的位置，从这棵树的叶子开始。 此过程的工作方式如下：</p>
<ol>
<li>对于每个键，节点会在第二级范围元数据 (meta2) 中查找包含指定键的范围的位置。 该信息被缓存以提高性能； 如果在缓存中找到范围的位置，则立即返回。</li>
<li>如果在缓存中找不到范围的位置，则节点查找 meta2 的实际值所在的范围的位置。 此信息也被缓存； 如果在缓存中找到 meta2 范围的位置，则节点向 meta2 范围发送 RPC 以获取请求要操作的键的位置，并返回该信息。</li>
<li>最后，如果在缓存中找不到 meta2 范围的位置，则节点查找第一级范围元数据（meta1）的实际值所在的范围的位置。 这种查找总是成功的，因为 meta1 的位置使用 gossip 协议分布在集群中的所有节点之间。 然后节点使用来自 meta1 的信息来查找 meta2 的位置，并从 meta2 中查找包含请求中键的范围的位置。</li>
</ol>
<p>请注意，上述过程是递归的； 每次执行查找时，它要么 (1) 从缓存中获取位置，要么 (2) 对树中下一级“向上”的值执行另一次查找。 由于缓存了范围元数据，因此通常可以执行查找，而无需将 RPC 发送到另一个节点。</p>
<p>既然节点有了来自请求的键所在的范围的位置，它就会将请求中的 KV 操作发送到 BatchRequest 中的范围（使用 DistSender 机器）。</p>
<h2 id="技术细节和组件-1"><a href="#技术细节和组件-1" class="headerlink" title="技术细节和组件"></a>技术细节和组件</h2><h3 id="gRPC"><a href="#gRPC" class="headerlink" title="gRPC"></a>gRPC</h3><p>gRPC 是用于相互通信的软件节点。 因为分发层是与其他节点通信的第一层，所以 CockroachDB 在这里实现了 gRPC。</p>
<p>gRPC 要求将输入和输出格式化为协议缓冲区（protobufs）。 为了利用 gRPC，CockroachDB 实现了 api.proto 中定义的基于协议缓冲区的 API。</p>
<h3 id="BatchRequest"><a href="#BatchRequest" class="headerlink" title="BatchRequest"></a>BatchRequest</h3><p>所有 KV 操作请求都捆绑到一个 protobuf 中，称为 BatchRequest。 此批次的目的地在 BatchRequest 标头中标识，以及指向请求的事务记录的指针。 （另一方面，当一个节点在回复一个 BatchRequest 时，它使用了一个 protobuf————BatchResponse。）</p>
<p>这个 BatchRequest 也用于使用 gRPC 在节点之间发送请求，它接受和发送协议缓冲区。</p>
<h3 id="DistSender"><a href="#DistSender" class="headerlink" title="DistSender"></a>DistSender</h3><h1 id="复制层"><a href="#复制层" class="headerlink" title="复制层"></a>复制层</h1><p>CockroachDB 的复制层拷贝数据在节点之间，并且通过一致性算法来确保拷贝数据的一致性。</p>
<h2 id="概览-3"><a href="#概览-3" class="headerlink" title="概览"></a>概览</h2><p>高可用需要数据库可以容忍节点下线而不打断服务，保证应用可用。这意味着需要复制数据在节点之间来确保数据仍然可以访问。</p>
<p>在节点离线的时候确保一致性是数据库的挑战。为了解决这个问题，CockroachDB 使用的一致性算法需要多数的副本同意修改才能提交修改。因为3 是一个最小的数字达到多数派，CockroachDB 最少需要 3 个节点。</p>
<h1 id="存储层"><a href="#存储层" class="headerlink" title="存储层"></a>存储层</h1><p>CockroachDB的存储层读写数据从磁盘上。</p>
<p><a href="https://www.cockroachlabs.com/blog/pebble-rocksdb-kv-store/">https://www.cockroachlabs.com/blog/pebble-rocksdb-kv-store/</a></p>
<h2 id="概览-4"><a href="#概览-4" class="headerlink" title="概览"></a>概览</h2><p>每个CockroachDB节点至少包含一个 store，在节点启动的时候指定，这是cockroach进程读写磁盘数据的位置。</p>
<p>数据以 key-value 的形式存储在存储引擎，被认为是 黑盒API。</p>
<p>CockroachDB使用 pebble 存储引擎，pebble 是受 RocksDB 启发，但是有不同：</p>
<ul>
<li>使用go语言并且实现 RocksDB 的一个子集。</li>
<li>包含有利于 CockroachDB 的优化。</li>
</ul>
<p>在内部，每个 store 包含两个存储引擎的实例：</p>
<ul>
<li>一个用来存储临时的分布式SQL数据。</li>
<li>一个存储节点所有的其他数据。</li>
</ul>
<p>此外，还有一个块缓存在一个节点的所有 store之间共享，这些 stores 又有 range 副本的集合。一个 range 的多个副本永远不会被放在一个 stroe 甚至是一个 节点。</p>
<h2 id="组件-1"><a href="#组件-1" class="headerlink" title="组件"></a>组件</h2><h3 id="pebble"><a href="#pebble" class="headerlink" title="pebble"></a>pebble</h3><p>pebble 和 CockroachDB很好的集成有许多原因：</p>
<ul>
<li>他是一个 kv 存储，使得很容易引射成key -value。</li>
<li>提供原子写 batnches 和 snapshots，是事务的一个子集。</li>
<li>自研。</li>
<li>包含 rocksdb 中没有的优化，灵感来自 CockraochDb 如何使用 存储引擎。<a href="https://www.cockroachlabs.com/blog/bulk-data-import/">https://www.cockroachlabs.com/blog/bulk-data-import/</a></li>
</ul>
<p>底层 Pebble 引擎通过前缀压缩来保证 key 的高效存储。</p>
<h4 id="LSM-tree"><a href="#LSM-tree" class="headerlink" title="LSM tree"></a>LSM tree</h4><p>pebble 使用lsm tree 来管理数据存储。LSM tree 是一个层次树。在树的每一层，有对应的在磁盘上的文件来存储数据。这些文件叫做 SST 文件（sorted string table）。</p>
<h5 id="SSTs"><a href="#SSTs" class="headerlink" title="SSTs"></a>SSTs</h5><p>SST 是 key- value对 排序列表的磁盘表示。 </p>
<p>SST文件上不可变的，他们不会被修改，即使在 compaction 进程中。</p>
<h5 id="LSM-levels"><a href="#LSM-levels" class="headerlink" title="LSM levels"></a>LSM levels</h5><p>LSM tree 被组织为 L0 到 L6 层。L0上最顶层，L6是最底层。新数据是被添加到 L0层，然后随时间被 merged 到底层。</p>
<p>LSM tree 的每一层都有 SSTs 的集合，每个 SST 是不可变的并且是唯一的，序号是单调递增的。</p>
<p>每个一层的 SST 的 key 不会重叠：例如 如果一个 SST 包含key [A-F] ，下一个文件包含 [F-R]。但是 L0是特殊的，L0是唯一一层可以包含重叠的 keys 。由于以下原因，这种例外是必要的：</p>
<ul>
<li>为了使 基于LSM tree 的存储引擎，比如 pebble 支持大量数据的摄取，比如当使用 IMPORT 语句的时候。</li>
<li>为了使 memtales 更容易和高效的 flushes。</li>
</ul>
<h5 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h5><p>merging SSTs 文件并且从 L0移动到 L6到过程叫做 compaction，存储引擎compact 数据越快越好。这个过程的结果使得底层的包含更大的 SSTs文件，并且包含较少的最近更新的 keys。</p>
<p>compaction 过程是必要的为了使 LSM 更加高效； 从 L0到 L6，每一层应该包含下一层大约十分之一的数据。比如，L1大约有L2十分之一的数据。理想情况下，尽可能多的数据将存储在 LSM 较低级别引用的较大 SST 中。如果 compaction 过程落后，可能导致 inverted LSM。</p>
<p>SST 文件在压缩过程中永远不会被修改。 相反，新的 SST 被写入，旧的 SST 被删除。 这种设计利用了顺序磁盘访问比随机磁盘访问快得多的事实。</p>
<p>压缩的过程是这样的：如果需要合并两个 SST 文件 A 和 B，则将它们的内容（键值对）读入内存。 内容在内存中进行排序和合并，然后打开一个新文件 C 并将其写入磁盘，其中包含新的、更大的键值对排序列表。 此步骤在概念上类似于归并排序。 最后，旧文件 A 和 B 被删除。</p>
<h5 id="inverted-LSMs"><a href="#inverted-LSMs" class="headerlink" title="inverted LSMs"></a>inverted LSMs</h5><p>如果压缩过程落后于添加的数据量，并且树的更高层存储的数据多于下面的层级，则 LSM 形状可能会反转。</p>
<p>反向 LSM 会降低读取性能。</p>
<p>反向LSM 的读放大很高，在倒置 LSM 状态下，读取需要从更高级别开始，并通过大量 SST“向下看”以读取key的正确（最新）值。 当存储引擎需要从多个 SST 文件中读取以服务于单个逻辑读取时，这种状态称为读取放大。</p>
<p>如果大量的 IMPORT 使集群过载（由于 CPU 和&#x2F;或 IOPS 不足）并且存储引擎必须咨询 L0 中的许多小型 SST 以确定正在使用的键的最新值，则读取放大可能会特别糟糕。（例如，使用 SELECT）。</p>
<p>写放大比读放大更复杂，但可以广义地定义为：“我在压缩期间重写了多少物理文件？” 例如，如果存储引擎在 L5 中进行大量压缩，它将一遍又一遍地重写 L5 中的 SST 文件。 这是一个折衷，因为如果引擎没有足够频繁地执行压缩，L0 的大小会变得太大，并且会导致反向 LSM，这也会产生不良影响。</p>
<p>读取放大和写入放大是 LSM 性能的关键指标。 两者都不是天生的“好”或“坏”，但它们不能过度出现，并且为了获得最佳性能，它们必须保持平衡。 这种平衡涉及权衡。</p>
<p>倒置的 LSM 也有过多的压实债务。 在这种状态下，存储引擎有大量的压缩积压要做，以使反转的 LSM 恢复到正常的非反转状态。</p>
<p>有关如何监控集群的 LSM 运行状况的说明，请参阅 LSM 运行状况。 要监控集群的 LSM L0 运行状况，请参阅 LSM L0 运行状况。</p>
<h5 id="Memtable和wal"><a href="#Memtable和wal" class="headerlink" title="Memtable和wal"></a>Memtable和wal</h5><p>为了便于管理 LSM 树结构，存储引擎维护 LSM 的内存表示，称为 memtable； 内存表中的数据会定期刷新到磁盘上的 SST 文件中。</p>
<p>磁盘上另一个名为 write-ahead log（以下称为 WAL）的文件与每个 memtable 相关联，以确保在断电或其他故障的情况下的持久性。 WAL 是复制层向存储引擎发布的最新更新存储在磁盘上的位置。 每个 WAL 与一个 memtable 是一一对应的； 它们保持同步，并且作为存储引擎正常操作的一部分，来自 WAL 和 memtable 的更新会定期写入 SST。</p>
<p> 新值在写入memtable的同时写入 WAL。 它们最终会从 memtable 写入磁盘上的 SST 文件以进行长期存储。</p>
<h5 id="LSM-设计的权衡"><a href="#LSM-设计的权衡" class="headerlink" title="LSM 设计的权衡"></a>LSM 设计的权衡</h5><p>LSM 树设计优化了写入性能而不是读取性能。 通过将排序的键值数据保存在 SST 中，可以避免写入时的随机磁盘寻道。 它试图通过从 LSM 树中尽可能低的位置、从更少、更大的文件中进行读取来降低读取（随机搜索）的成本。 这就是存储引擎执行压缩的原因。 存储引擎还尽可能使用块缓存来进一步加快读取速度。</p>
<p>LSM 设计中的权衡是为了利用现代磁盘的工作方式，因为即使它们由于缓存提供了对磁盘上随机位置的更快读取，但它们在写入随机位置时的性能仍然相对较差。</p>
<h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><p>CockroachDB 严重依赖多版本并发控制（MVCC）来处理并发请求并保证一致性。 大部分工作是通过使用混合逻辑时钟 (HLC) 时间戳来区分数据版本、跟踪提交时间戳和识别值的垃圾收集到期来完成的。 然后，所有这些 MVCC 数据都存储在 Pebble 中。</p>
<p>尽管在存储层中实现，但 MVCC 值被广泛用于在事务层中强制执行一致性。 例如，CockroachDB 维护一个时间戳缓存，它存储最后一次读取密钥的时间戳。 如果写入操作发生的时间戳低于读取时间戳缓存中的最大值，则表示存在潜在异常，事务必须在稍后的时间戳重新启动。</p>
<h4 id="Time-travel"><a href="#Time-travel" class="headerlink" title="Time-travel"></a>Time-travel</h4><p>如 SQL:2011 标准中所述，CockroachDB 支持时间旅行查询（由 MVCC 启用）。</p>
<p>为此，所有模式信息背后也有一个类似 MVCC 的模型。 这使您可以执行 SELECT…AS OF SYSTEM TIME，CockroachDB 使用当时的模式信息来制定查询。</p>
<p>使用这些工具，您可以从数据库中获得一致的数据在垃圾回收之前。</p>
<h3 id="Garbage-collection"><a href="#Garbage-collection" class="headerlink" title="Garbage collection"></a>Garbage collection</h3><p>CockroachDB 定期垃圾收集 MVCC 值以减少存储在磁盘上的数据大小。 为此，当有一个较新的 MVCC 值具有比垃圾回收期更早的时间戳时，我们会压缩旧的 MVCC 值。 通过配置 gc.ttlseconds 复制区域变量，可以在集群、数据库或表级别设置垃圾收集周期。 </p>
<h4 id="Protected-timestamps"><a href="#Protected-timestamps" class="headerlink" title="Protected timestamps"></a>Protected timestamps</h4><p>垃圾收集只能在不受保护的时间戳覆盖的 MVCC 值上运行。 受保护的时间戳子系统的存在是为了确保依赖历史数据的操作的安全性，例如：</p>
<ul>
<li><a href="https://www.cockroachlabs.com/docs/v21.2/import">Imports</a>, including <a href="https://www.cockroachlabs.com/docs/v21.2/import-into"><code>IMPORT INTO</code></a></li>
<li><a href="https://www.cockroachlabs.com/docs/v21.2/backup">Backups</a></li>
<li><a href="https://www.cockroachlabs.com/docs/v21.2/change-data-capture-overview">Changefeeds</a></li>
<li><a href="https://www.cockroachlabs.com/docs/v21.2/online-schema-changes">Online schema changes</a></li>
</ul>
<p>受保护的时间戳可确保历史数据的安全性，同时还可以实现更短的 GC TTL。 较短的 GC TTL 意味着保留较少的先前 MVCC 值。 这有助于降低全天频繁更新行的工作负载的查询执行成本，因为 SQL 层必须扫描以前的 MVCC 值才能找到行的当前值。</p>
<h5 id="How-protected-timestamps-work"><a href="#How-protected-timestamps-work" class="headerlink" title="How protected timestamps work"></a>How protected timestamps work</h5><p>保护时间戳通过在内部系统表中创建记录来工作。当一个长时间运行的 job ，比如备份想要保护某个时间戳的数据不被 GC 时，他会创建改数据和时间戳关联的 记录。</p>
<p>成功创建保护记录后，时间戳小于或等于受保护时间戳的指定数据的 MVCC 值将不会被垃圾收集。 当创建保护记录的作业完成其工作时，它会删除该记录，从而允许垃圾收集器在以前受保护的值上运行。</p>
<h2 id="Transaction-contention-争用"><a href="#Transaction-contention-争用" class="headerlink" title="Transaction contention(争用)"></a>Transaction contention(争用)</h2><p>对相同索引键值进行操作的事务（特别是对给定索引键在相同列族上进行操作的事务）被严格序列化以遵守事务隔离语义。 为了保持这种隔离，编写事务“锁定”行以防止与并发事务的危险交互。 但是，如果多个事务试图同时访问相同的“锁定”数据，锁定可能会导致处理延迟。 这称为事务（或锁）争用。</p>
<p>当满足以下三个条件时，就会发生事务争用：</p>
<ul>
<li>有多个并发事务或语句（由同时连接到单个 CockroachDB 集群的多个客户端发送）。</li>
<li>它们对具有相同索引键值（主键或二级索引）的表行进行操作。</li>
<li>至少一个事务修改数据。</li>
</ul>
<p>经历争用的事务通常会延迟完成或重新启动。 事务重启的可能性需要客户端实现事务重试。</p>
<h3 id="Find-transaction-contention"><a href="#Find-transaction-contention" class="headerlink" title="Find transaction contention"></a>Find transaction contention</h3><p>查找事务中发生争用的事务和语句。 CockroachDB 有几个工具可以帮助您追踪此类事务和语句：</p>
<ul>
<li>在 DB Console 中，访问事务和语句页面并按争用对事务和语句进行排序。</li>
<li>查询数据库的 crdb_internal.cluster_contended_indexes 和 crdb_internal.cluster_contended_tables 表，以查找发生争用的索引和表。</li>
</ul>
<h3 id="Reduce-transaction-contention"><a href="#Reduce-transaction-contention" class="headerlink" title="Reduce transaction contention"></a>Reduce transaction contention</h3><p>为了减少事务争用：</p>
<ul>
<li>让事务更小，让每个事务做的工作更少。 特别是，避免每个事务进行多次客户端-服务器交换。 例如，使用公用表表达式将多个 SELECT 和 INSERT、UPDATE、DELETE 和 UPSERT 子句组合到一个 SQL 语句中。</li>
<li>一次性发送事务中的所有语句，以便 CockroachDB 自动为您重试事务。</li>
<li>在事务执行读取然后更新它刚刚读取的行的情况下使用 SELECT FOR UPDATE 语句。 该语句通过控制对表的一行或多行的并发访问来对事务进行排序。 它通过锁定选择查询返回的行来工作，这样试图访问这些行的其他事务被迫等待锁定这些行的事务完成。 这些其他事务被有效地放入队列中，该队列根据它们何时尝试读取锁定行的值进行排序。</li>
<li>替换行中的值时，使用 UPSERT 并为插入行中的所有列指定值。 与 SELECT、INSERT 和 UPDATE 的组合相比，这通常在争用情况下具有最佳性能。</li>
</ul>
<h1 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h1><h2 id="Transactions"><a href="#Transactions" class="headerlink" title="Transactions"></a>Transactions</h2><p>CockroachDB 支持将多个 SQL 语句捆绑到单个全有或全无事务中。 每个事务保证 ACID 语义跨越任意表和行，即使数据是分布式的。 如果事务成功，则所有突变都将与虚拟同时一起应用。 如果事务的任何部分失败，则整个事务将中止，并且数据库保持不变。 CockroachDB 保证当一个事务处于挂起状态时，它与其他具有可序列化隔离的并发事务隔离。</p>
<p>有关 CockroachDB 事务语义的详细讨论，请参阅 <a href="https://www.cockroachlabs.com/blog/how-cockroachdb-distributes-atomic-transactions/">https://www.cockroachlabs.com/blog/how-cockroachdb-distributes-atomic-transactions/</a> 和  <a href="https://www.cockroachlabs.com/blog/serializable-lockless-distributed-isolation-cockroachdb/">https://www.cockroachlabs.com/blog/serializable-lockless-distributed-isolation-cockroachdb/</a> 这篇博文中描述的事务模型的解释有些过时了。 有关更多详细信息，请参阅事务重试部分。</p>
<h3 id="SQL-statements"><a href="#SQL-statements" class="headerlink" title="SQL statements"></a>SQL statements</h3><table>
<thead>
<tr>
<th>Statement</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://www.cockroachlabs.com/docs/v22.1/begin-transaction"><code>BEGIN</code></a></td>
<td>Initiate a transaction, as well as control its <a href="https://www.cockroachlabs.com/docs/v22.1/transactions#transaction-priorities">priority</a>.</td>
</tr>
<tr>
<td><a href="https://www.cockroachlabs.com/docs/v22.1/set-transaction"><code>SET TRANSACTION</code></a></td>
<td>Control a transaction’s <a href="https://www.cockroachlabs.com/docs/v22.1/transactions#transaction-priorities">priority</a>.</td>
</tr>
<tr>
<td><a href="https://www.cockroachlabs.com/docs/v22.1/commit-transaction"><code>COMMIT</code></a></td>
<td>Commit a regular transaction, or clear the connection after committing a transaction using the <a href="https://www.cockroachlabs.com/docs/v22.1/advanced-client-side-transaction-retries">advanced retry protocol</a>.</td>
</tr>
<tr>
<td><a href="https://www.cockroachlabs.com/docs/v22.1/rollback-transaction"><code>ROLLBACK</code></a></td>
<td>Abort a transaction and roll the database back to its state before the transaction began.</td>
</tr>
<tr>
<td><a href="https://www.cockroachlabs.com/docs/v22.1/show-vars"><code>SHOW</code></a></td>
<td>Display the current transaction settings.</td>
</tr>
<tr>
<td><a href="https://www.cockroachlabs.com/docs/v22.1/savepoint"><code>SAVEPOINT</code></a></td>
<td>Used for <a href="https://www.cockroachlabs.com/docs/v22.1/transactions#nested-transactions">nested transactions</a>; also used to implement <a href="https://www.cockroachlabs.com/docs/v22.1/advanced-client-side-transaction-retries">advanced client-side transaction retries</a>.</td>
</tr>
<tr>
<td><a href="https://www.cockroachlabs.com/docs/v22.1/release-savepoint"><code>RELEASE SAVEPOINT</code></a></td>
<td>Commit a <a href="https://www.cockroachlabs.com/docs/v22.1/transactions#nested-transactions">nested transaction</a>; also used for <a href="https://www.cockroachlabs.com/docs/v22.1/advanced-client-side-transaction-retries">retryable transactions</a>.</td>
</tr>
<tr>
<td><a href="https://www.cockroachlabs.com/docs/v22.1/rollback-transaction"><code>ROLLBACK TO SAVEPOINT</code></a></td>
<td>Roll back a <a href="https://www.cockroachlabs.com/docs/v22.1/transactions#nested-transactions">nested transaction</a>; also used to handle <a href="https://www.cockroachlabs.com/docs/v22.1/advanced-client-side-transaction-retries">retryable transaction errors</a>.</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title>从零写数据库系列-scanner</title>
    <url>/2023/02/01/2-%E6%95%B0%E6%8D%AE%E5%BA%93/3-%E6%89%8B%E5%86%99%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BB%8E%E9%9B%B6%E5%86%99%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B02-scanner/</url>
    <content><![CDATA[<span id="more"></span>



]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title>从零写数据库系列-parser</title>
    <url>/2023/02/01/2-%E6%95%B0%E6%8D%AE%E5%BA%93/3-%E6%89%8B%E5%86%99%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BB%8E%E9%9B%B6%E5%86%99%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B03-parser/</url>
    <content><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title>从零写数据库系列-背景知识</title>
    <url>/2023/02/01/2-%E6%95%B0%E6%8D%AE%E5%BA%93/3-%E6%89%8B%E5%86%99%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BB%8E%E9%9B%B6%E5%86%99%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B01-%E8%83%8C%E6%99%AF/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>1970 年，IBM的研究员Edgar Frank Codd (TED) 发表了《A Relational Model of Data for Large Shared Data Banks》，这篇论文首次提出了关系模型。</p>
<p>1972年，TED 又提出了关系大事和关系演算的概念。</p>
<p>1974年，IBM的Ray Boyce和Don Chamberlin提出了SQL（Structured Query Language）语言。</p>
<p>有了关系模型和关系代数的理论基础，又有了SQL 这种语言来表达。那么我们可以开始设计数据库系统了。</p>
<p>在关系模型提出后，出现过两个著名的产品，System R 和 Ingres。Ingres使用的是一种叫做 QUEL 的语言，System R使用的就是早期的 SQL。由于 SQL 成为了 ANSI 的标准，所以QUEL 成为了历史。</p>
<span id="more"></span>

<p>有了这些历史背景，现在可以谈谈SQL的执行流程了。</p>
<h2 id="Parser"><a href="#Parser" class="headerlink" title="Parser"></a>Parser</h2><p>词法(lexing)，语法(syntax)。</p>
<h2 id="Analyzer"><a href="#Analyzer" class="headerlink" title="Analyzer"></a>Analyzer</h2><p>语意(Semantic)。绑定，类型检查。</p>
<h2 id="Planner"><a href="#Planner" class="headerlink" title="Planner"></a>Planner</h2><p>System R优化器第一次提出了自底向上的动态规划搜索策略，影响了后续的很多系统。另一个创新点在于提出来基于cost-based的优化方法，如何根据sargable条件计算selective，增加了interesting order属性来对访问方法（Access Path）进行影响。</p>
<p>Volcano&#x2F;Cascades</p>
<p>Cascades 的实现，orca，cockroachdb。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *scope)</span></span> endAggFunc(cols opt.ColSet) (g *groupby) &#123;</span><br><span class="line">	<span class="keyword">if</span> !s.inAgg &#123;</span><br><span class="line">		<span class="built_in">panic</span>(errors.AssertionFailedf(<span class="string">&quot;mismatched calls to start/end aggFunc&quot;</span>))</span><br><span class="line">	&#125;</span><br><span class="line">	s.inAgg = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> curr := s; curr != <span class="literal">nil</span>; curr = curr.parent &#123;</span><br><span class="line">		<span class="keyword">if</span> cols.Len() == <span class="number">0</span> || cols.Intersects(curr.colSet()) &#123;</span><br><span class="line">			curr.verifyAggregateContext()</span><br><span class="line">			<span class="keyword">if</span> curr.groupby == <span class="literal">nil</span> &#123;</span><br><span class="line">				curr.initGrouping()</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> curr.groupby</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">panic</span>(errors.AssertionFailedf(<span class="string">&quot;aggregate function is not allowed in this context&quot;</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title>git 忽略文件</title>
    <url>/2023/09/17/10-%E5%B7%A5%E5%85%B7/git/0-brew/</url>
    <content><![CDATA[<p>git 用法记录</p>
<span id="more"></span>



<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">.gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。</span><br><span class="line">正确的做法是在每个<span class="built_in">clone</span>下来的仓库中手动设置不要检查特定文件的更改情况。</span><br><span class="line">git update-index --assume-unchanged FILE </span><br><span class="line">在FILE处输入要忽略的文件。</span><br><span class="line">如果要还原的话，使用命令：</span><br><span class="line">git update-index --no-assume-unchanged FILE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pkg/.../manual/manual.go</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>The Many Faces of Consistency</title>
    <url>/2023/10/26/2-%E6%95%B0%E6%8D%AE%E5%BA%93/4-%E8%AE%BA%E6%96%87/The%20Many%20Faces%20of%20Consistency/</url>
    <content><![CDATA[<p><em>The notion of consistency is used across di</em>ff<em>erent computer science disciplines from distributed systems to database systems to computer architecture. It turns out that consistency can mean quite di</em>ff<em>erent things across these disciplines, depending on who uses it and in what context it appears. We identify two broad types of consistency,</em> state consistency <em>and</em> operation consistency*, which di<em>ff</em>er fundamentally in meaning and scope. We explain how these types map to the many examples of consistency in each discipline.*</p>
<p>一致性的概念用于不同的计算机科学学科，从分布式系统到数据库系统再到计算机体系结构。 事实证明，一致性在这些学科中可能意味着完全不同的事情，具体取决于谁使用它以及它出现在什么背景下。 我们确定了两大类一致性：状态一致性和操作一致性，它们在含义和范围上有根本的不同。 我们解释这些类型如何映射到每个学科中的许多一致性示例。</p>
<span id="more"></span>

<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>Consistency is an important consideration in computer systems that <em>share</em> and <em>replicate</em> data. Whereas early computing systems had private data exclusively, shared data has become increasingly common as computers have evolved from calculating machines to tools of information exchange. Shared data occurs in many types of systems, from distributed systems to database systems to multiprocessor systems. For example, in distributed systems, users across the network share files (e.g., source code), network names (e.g., DNS entries), data blobs (e.g., images in a key-value store), or system metadata (e.g., configuration information). In database systems, users share tables containing account information, product descriptions, flight bookings, and seat assignments. Within a computer, processor cores share cache lines and physical memory.</p>
<p>一致性是共享和复制数据的计算机系统中的一个重要考虑因素。 早期的计算系统只拥有私有数据，而随着计算机从计算机器发展为信息交换工具，共享数据变得越来越普遍。 共享数据出现在许多类型的系统中，从分布式系统到数据库系统再到多处理器系统。 例如，在分布式系统中，网络上的用户共享文件（例如源代码）、网络名称（例如 DNS 条目）、数据 blob（例如键值存储中的图像）或系统元数据（例如配置） 信息）。 在数据库系统中，用户共享包含帐户信息、产品描述、航班预订和座位分配的表。 在计算机内，处理器核心共享高速缓存行和物理内存。</p>
<p>In addition to sharing, computer systems increasingly replicate data within and across components. In distributed systems, each site may hold a local replica of files, network names, blobs, or system metadata— these replicas, called caches, increase performance of the system. Database systems also replicate rows or tables for speed or to tolerate disasters. Within a computer, parts of memory are replicated at various points in the cache hierarchy (l1, l2, l3 caches), again for speed. We use the term replica broadly to mean any copies of the data maintained by the system.</p>
<p>除了共享之外，计算机系统还越来越多地在组件内部和组件之间复制数据。 在分布式系统中，每个站点都可以保存文件、网络名称、blob 或系统元数据的本地副本 - 这些副本（称为缓存）可以提高系统的性能。 数据库系统还复制行或表以提高速度或容忍灾难。 在计算机内，部分内存会在缓存层次结构（l1、l2、l3 缓存）中的各个点进行复制，同样是为了提高速度。 我们广泛使用术语“副本”来表示系统维护的数据的任何副本。</p>
<p>In all these systems, data sharing and replication raise a fundamental question: what should happen if a client modifies some data items and simultaneously, or within a short time, another client reads or modifies the same items, possibly at a different replica?</p>
<p>在所有这些系统中，数据共享和复制提出了一个基本问题：如果一个客户端修改了某些数据项，并且同时或在短时间内，另一个客户端可能在不同的副本上读取或修改了相同的项目，那么会发生什么情况？</p>
<p>This question does not have a single answer that is right in every context. A consistency property governs the possible outcomes by limiting how data can change or what clients can observe in each case. For example, with DNS, a change to a domain may not be visible for hours; the only guarantee is that updates will be seen eventually—an example of a property called eventual consistency [23]. But with flight seat assignments, updates must be immediate and mutually exclusive, to ensure that no two passengers receive the same seat—an example of a strong type of consistency provided by serializability [5]. Other consistency properties include causal consis- tency [13], read-my-writes [21], bounded staleness [1], continuous consistency [1, 25], release consistency [10], fork consistency [16], epsilon serializability [18], and more.</p>
<p>这个问题没有一个在所有情况下都正确的答案。 一致性属性通过限制数据的更改方式或客户端在每种情况下可以观察到的内容来控制可能的结果。 例如，对于 DNS，对域的更改可能在数小时内不可见； 唯一的保证是最终会看到更新——一个称为最终一致性的属性的例子[23]。 但对于航班座位分配，更新必须是立即且互斥的，以确保没有两名乘客获得相同的座位——这是可串行性提供的强一致性的一个例子 [5]。 其他一致性属性包括因果一致性 [13]、读我的写 [21]、有界陈旧性 [1]、连续一致性 [1, 25]、发布一致性 [10]、分叉一致性 [16]、epsilon 可串行性 [ 18]等等。</p>
<p>Consistency is important because developers must understand the answer to the above fundamental question. This is especially true when the clients interacting with the system are not humans but other computer programs that must be coded to deal with all possible outcomes.</p>
<p>一致性很重要，因为开发人员必须理解上述基本问题的答案。 当与系统交互的客户端不是人类而是必须编码以处理所有可能结果的其他计算机程序时尤其如此。</p>
<p>In this article, we examine many examples of how consistency is used across three computer science disci- plines: distributed systems, database systems, and computer architecture. We find that the use of consistency varies significantly across these disciplines. To bring some clarity, we identify two fundamentally different types of consistency: state consistency and operation consistency. State consistency concerns the state of the system and establishes constraints on the allowable relationships between different data items or different replicas of the same items. For instance, state consistency might require that two replicas store the same value when updates are not outstanding. Operation consistency concerns operations on the system and establishes constraints on what results they may return. For instance, operation consistency might require that a read of a file reflects the contents of the most recent write on that file. State consistency tends to be simpler and application dependent, while operation consistency tends to be more complex and application agnostic. Both types of consistency are important and, in our opinion, our communities should more clearly disentangle them.</p>
<p>在本文中，我们研究了如何在三个计算机科学学科（分布式系统、数据库系统和计算机体系结构）中使用一致性的许多示例。 我们发现，在这些学科中，一致性的使用存在显着差异。 为了清楚起见，我们确定了两种根本不同类型的一致性：状态一致性和操作一致性。 状态一致性涉及系统的状态，并对不同数据项或相同项的不同副本之间允许的关系建立约束。 例如，状态一致性可能要求两个副本在更新未完成时存储相同的值。 操作一致性涉及系统上的操作，并对它们可能返回的结果建立约束。 例如，操作一致性可能要求文件的读取反映该文件最近写入的内容。 状态一致性往往更简单且依赖于应用程序，而操作一致性往往更复杂且与应用程序无关。 这两种类型的一致性都很重要，我们认为，我们的社区应该更清楚地理清它们。</p>
<p>While this article discusses different forms of consistency, it focuses on the <em>semantics</em> of consistency rather than the <em>mechanisms</em> of consistency. Semantics refer to what consistency properties the system provides, while mechanisms refer to how the system enforces those properties. Semantics and mechanisms are closely related but it is important to understand the former without needing to understand the latter.</p>
<p>虽然本文讨论了不同形式的一致性，但它重点关注一致性的语义而不是一致性的机制。 语义是指系统提供哪些一致性属性，而机制是指系统如何强制执行这些属性。 语义和机制密切相关，但重要的是理解前者而不需要理解后者。</p>
<p>The rest of this article is organized as follows. We first explain the abstract system model and terminology used throughout the article in Section 2. We present the two types of consistency and their various embodiments in Section 3. We indicate how these consistency types occur across different disciplines in Section 4.</p>
<p>本文的其余部分组织如下。 我们首先在第 2 节中解释整篇文章中使用的抽象系统模型和术语。我们在第 3 节中介绍了两种类型的一致性及其各种实施例。我们在第 4 节中指出了这些一致性类型如何在不同学科中发生。</p>
<h2 id="2-Abstract-model"><a href="#2-Abstract-model" class="headerlink" title="2 Abstract model"></a>2 Abstract model</h2><p>We consider a setting with multiple <em>clients</em> that submit <em>operations</em> to be executed by the system. Clients could be human users, computer programs, or other systems that do not concern us. Operations might include simple read and write, read-modify-write, start and commit a transaction, and range queries. Operations typically act on data items, which could be blocks, files, key-value pairs, DNS entries, rows of tables, memory locations, and so on.</p>
<p>我们考虑具有多个客户端的设置，这些客户端提交要由系统执行的操作。 客户端可以是人类用户、计算机程序或与我们无关的其他系统。 操作可能包括简单的读取和写入、读取-修改-写入、启动和提交事务以及范围查询。 操作通常作用于数据项，这些数据项可以是块、文件、键值对、DNS 条目、表行、内存位置等。</p>
<p>The system has a <em>state</em>, which includes the current values of the data items. In some cases, we are interested in the consistency of client caches and other replicas. In these cases, the caches and other replicas are considered to be part of the system and the system state includes their contents.</p>
<p>系统具有状态，其中包括数据项的当前值。 在某些情况下，我们对客户端缓存和其他副本的一致性感兴趣。 在这些情况下，缓存和其他副本被视为系统的一部分，并且系统状态包括它们的内容。</p>
<p>An operation execution is not instantaneous; rather, it <em>starts</em> when a client submits the operation, and it <em>finishes</em> when the client obtains its response from the system. If the operation execution returns no response, then it finishes when the system is no longer actively processing it.</p>
<p>操作执行不是即时的； 相反，它在客户端提交操作时开始，在客户端从系统获得响应时结束。 如果操作执行没有返回响应，则当系统不再主动处理它时，操作就会完成。</p>
<p>Operations are distinct from operation executions. Operations are static and a system has relatively few of them, such as read and write. Operation executions, on the other hand, are dynamic and numerous. A client can execute the same operation many times, but each operation execution is unique. While technically we should separate operations from operation executions, we often blur the distinction when it is clear from the context (e.g., we might say that the read operation finishes, rather than the execution of the read operation finishes).</p>
<p>操作与操作执行不同。 操作是静态的，系统中的操作相对较少，例如读和写。 另一方面，操作执行是动态的且数量众多。 一个客户端可以多次执行相同的操作，但每次操作的执行都是唯一的。 虽然从技术上讲，我们应该将操作与操作执行分开，但当上下文清楚时，我们经常会模糊区别（例如，我们可能会说读操作完成，而不是读操作的执行完成）。</p>
<h2 id="3-Two-types-of-consistency"><a href="#3-Two-types-of-consistency" class="headerlink" title="3 Two types of consistency"></a>3 Two types of consistency</h2><p>We are interested in what happens when shared and replicated data is accessed concurrently or nearly con- currently by many clients. Generally speaking, consistency places constraints on the allowable outcomes of operations, according to the needs of the application. We now define two broad types of consistency. One places constraints on the state, the other on the results of operations.</p>
<p>我们感兴趣的是当许多客户端同时或几乎同时访问共享和复制的数据时会发生什么。 一般来说，一致性根据应用程序的需要对操作的允许结果施加限制。 我们现在定义两种广泛的一致性类型。 一是对 状态施加限制，二是对操作结果施加限制。</p>
<h3 id="3-1-State-consistency"><a href="#3-1-State-consistency" class="headerlink" title="3.1 State consistency"></a>3.1 State consistency</h3><p>State consistency pertains to the state of the system; it consists of properties that users expect the state to satisfy despite concurrent access and the existence of multiple replicas. State consistency is also applicable when data can be corrupted by errors (crashes, bit flips, bugs, etc), but this is not the focus of this article.</p>
<p>状态一致性与系统的状态有关； 它由用户期望状态满足的属性组成，尽管存在并发访问和存在多个副本。 当数据可能因错误（崩溃、位翻转、错误等）而损坏时，状态一致性也适用，但这不是本文的重点。</p>
<p>State consistency can be of many subcategories, based on how the properties of state are expressed. We explain these subcategories next.</p>
<p>根据状态属性的表达方式，状态一致性可以分为许多子类别。 接下来我们将解释这些子类别。</p>
<h4 id="3-1-1-Invariants-不变量"><a href="#3-1-1-Invariants-不变量" class="headerlink" title="3.1.1 Invariants 不变量"></a>3.1.1 Invariants 不变量</h4><p>The simplest subcategory of state consistency is one defined by an invariant—a predicate on the state that must evaluate to true. For instance, in a concurrent program, a singly linked list must not contain cycles. In a multiprocessor system, if the local caches of two processors keep a value for some address, it must be the same value. In a social network, if user x is a friend of user y then y is a friend of x. In a photo sharing application, if a photo album includes an image then the image’s owner is the album.</p>
<p>状态一致性最简单的子类别是由不变量定义的，即状态上必须评估为 true 的谓词。 例如，在并发程序中，单链表不能包含循环。 在多处理器系统中，如果两个处理器的本地缓存保存某个地址的值，则该值必须是相同的值。 在社交网络中，如果用户 x 是用户 y 的朋友，则 y 也是 x 的朋友。 在照片共享应用程序中，如果相册包含图像，则该图像的所有者就是相册。</p>
<p>In database systems, two important examples are uniqueness constraints and referential integrity. A <em>unique- ness constraint</em> on a column of a table requires that each value appearing in that column must occur in at most one row. This property is crucial for the primary keys of tables.</p>
<p>在数据库系统中，两个重要的例子是唯一性约束和引用完整性。 表的列的唯一性约束要求该列中出现的每个值必须最多出现在一行中。 该属性对于表的主键至关重要。</p>
<p><em>Referential integrity</em> concerns a table that refers to keys of another table. Databases may store relations between tables by including keys of a table within columns in another table. Referential integrity requires that the included keys are indeed keys in the first table. For instance, in a bank database, suppose that an accounts table includes a column for the account owner, which is a user id; meanwhile, the user id is the primary key in a users table, which has detailed information for each user. A referential integrity constraint requires that user ids in the accounts table must indeed exist in the users table.</p>
<p>参照完整性涉及引用另一个表的键的表。 数据库可以通过将一个表的键包含在另一个表的列中来存储表之间的关系。 参照完整性要求包含的键确实是第一个表中的键。 例如，在银行数据库中，假设帐户表包含帐户所有者的列，即用户 ID； 同时，用户id是用户表中的主键，该表包含每个用户的详细信息。 参照完整性约束要求帐户表中的用户 ID 必须确实存在于用户表中。</p>
<p>Another example of state consistency based on invariants is <em>mutual consistency</em>, used in distributed systems that are replicated using techniques such as primary-backup [2]. Mutual consistency requires that replicas have the same state when there are no outstanding updates. During updates, replicas may diverge temporarily since the updates are not applied simultaneously at all replicas.</p>
<p>基于不变量的状态一致性的另一个例子是相互一致性，用于使用主备份等技术进行复制的分布式系统[2]。 相互一致性要求副本在没有未完成的更新时具有相同的状态。 在更新期间，副本可能会暂时出现分歧，因为更新不会同时应用于所有副本。</p>
<h4 id="3-1-2-Error-bounds-误差范围"><a href="#3-1-2-Error-bounds-误差范围" class="headerlink" title="3.1.2 Error bounds 误差范围"></a>3.1.2 Error bounds 误差范围</h4><p>If the state contains numerical data, the consistency property could indicate a maximum deviation or error from the expected. For instance, the values at two replicas may diverge by at most ε. In an internet-of-things system, the reported value of a sensor, such as a thermometer, must be within ε from the actual value being measured. This example relates the state of the system to the state of the world. Error bounds were first proposed within the database community [1] and the basic idea was later revived in the distributed systems community [25].</p>
<p>如果状态包含数值数据，则一致性属性可能表示与预期的最大偏差或错误。 例如，两个副本上的值最多可能会差异ε。 在图Internet系统中，传感器的报告值（例如温度计）必须在ε内，从实际的值中。 这个示例将系统状态与世界状态联系起来。 误差界最初是在数据库社区中提出的[1]，后来在分布式系统社区中恢复了基本思想[25]。</p>
<h4 id="3-1-3-Limits-on-proportion-of-violations-违规比例限制"><a href="#3-1-3-Limits-on-proportion-of-violations-违规比例限制" class="headerlink" title="3.1.3 Limits on proportion of violations 违规比例限制"></a>3.1.3 Limits on proportion of violations 违规比例限制</h4><p>If there are many properties or invariants, it may be unrealistic to expect all of them to hold, but rather just a high percentage. For instance, the system may require that at most one user’s invariants are violated in a pool of a million users; this could make sense if the system can compensate a small fraction of users for inconsistencies in their data.</p>
<p>如果存在许多属性或不变量，则期望它们全部成立而只是高百分比成立可能是不现实的。 例如，系统可能要求在一百万个用户的池中最多违反一个用户的不变量； 如果系统可以补偿一小部分用户的数据不一致，那么这可能是有意义的。</p>
<h4 id="3-1-4-Importance-重要性"><a href="#3-1-4-Importance-重要性" class="headerlink" title="3.1.4 Importance 重要性"></a>3.1.4 Importance 重要性</h4><p>Properties or invariants may be critical, important, advisable, desirable, or optional, where users expect only the critical properties to hold at all times. Developers can use more expensive and effective mechanisms for the more important invariants. For instance, when a user changes her password at a web site, the system might require all replicas of the user account to have the same password before acknowledging the change to the user. This property is implemented by contacting all replicas and waiting for replies, which can be an overly expensive mechanism for less important properties.</p>
<p>属性或不变量可能是关键的、重要的、可取的、理想的或可选的，其中用户期望始终只保留关键属性。 开发人员可以针对更重要的不变量使用更昂贵和更有效的机制。 例如，当用户在网站上更改密码时，系统可能要求该用户帐户的所有副本都具有相同的密码，然后再向用户确认更改。 该属性是通过联系所有副本并等待回复来实现的，对于不太重要的属性来说，这可能是一种过于昂贵的机制。</p>
<h4 id="3-1-5-Eventual-invariants-最终不变量"><a href="#3-1-5-Eventual-invariants-最终不变量" class="headerlink" title="3.1.5 Eventual invariants 最终不变量"></a>3.1.5 Eventual invariants 最终不变量</h4><p>An invariant may need to hold only after some time has passed. For example, under eventual consistency, replicas need not be the same at all times, as long as they <em>eventually</em> become the same when updates stop occurring. This eventual property is appropriate because replicas may be updated in the background or using some anti-entropy mechanism, where it takes an indeterminate amount of time for a replica to receive and process an update. Eventual consistency was coined by the distributed systems community [23], though the database community previously proposed the idea of reconciling replicas that diverge during partitions [9].</p>
<p>不变量可能只需要在经过一段时间后才保持不变。 例如，在最终一致性下，副本不需要始终相同，只要当更新停止发生时它们最终变得相同即可。 此最终属性是合适的，因为副本可以在后台或使用某种反熵机制进行更新，其中副本接收和处理更新需要不确定的时间。 最终一致性是由分布式系统社区[23]创造的，尽管数据库社区之前提出了协调分区期间分歧的副本的想法[9]。</p>
<p>State consistency is limited to properties on state, but in many cases clients care less about the state and more about the results that they obtain from the system. In other words, what matters is the behavior that clients observe from interacting with the system. These cases call for a different form of consistency, which we discuss next.</p>
<p>状态一致性仅限于状态的属性，但在许多情况下，客户端不太关心状态，而更关心他们从系统获得的结果。 换句话说，重要的是客户通过与系统交互观察到的行为。 这些情况需要不同形式的一致性，我们接下来讨论。</p>
<h3 id="3-2-Operation-consistency"><a href="#3-2-Operation-consistency" class="headerlink" title="3.2 Operation consistency"></a>3.2 Operation consistency</h3><p>Operation consistency pertains to the operation executions by clients; it consists of properties that indicate whether operations return acceptable results. These properties can tie together many operation executions, as shown in the examples below.</p>
<p>操作一致性涉及客户端执行的操作； 它由指示操作是否返回可接受的结果的属性组成。 这些属性可以将许多操作执行联系在一起，如下面的示例所示。</p>
<p>Operation consistency has subcategories, with different ways to define the consistency property. We explain these subcategories next.</p>
<p>操作一致性有不同的子类别，有不同的方法来定义一致性属性。 接下来我们将解释这些子类别。</p>
<h4 id="3-2-1-Sequential-equivalence-顺序等价"><a href="#3-2-1-Sequential-equivalence-顺序等价" class="headerlink" title="3.2.1 Sequential equivalence 顺序等价"></a>3.2.1 Sequential equivalence 顺序等价</h4><p>This subcategory defines the permitted operation results of a concurrent execution in terms of the permitted oper- ation results in a sequential execution—one in which operations are executed one at a time, without concurrency. More specifically, there must be a way to take the execution of all operations submitted by any subset of clients, and then <em>reduce</em> them to a sequential execution that is correct. The exact nature of the reduction depends on the specific consistency property. Technically, the notion of a correct sequential execution is system dependent, so it needs to be specified as well, but it is often obvious and therefore omitted.</p>
<p>该子类别根据顺序执行（一次执行一个操作，无并发）中允许的操作结果来定义并发执行的允许操作结果。 更具体地说，必须有一种方法来执行任何客户端子集提交的所有操作，然后将它们简化为正确的顺序执行。 减少的确切性质取决于特定的一致性属性。 从技术上讲，正确顺序执行的概念取决于系统，因此也需要指定它，但它通常是显而易见的，因此被省略。</p>
<p>We now give some examples of sequential equivalence. 现在我们给出一些顺序等价的例子。</p>
<p><em>Linearizability [12]</em> is a strong form of consistency. Intuitively, the constraint is that each operation must appear to occur at an instantaneous point between its start and finish times, where execution at these instanta- neous points form a valid sequential execution. More precisely, we define a partial order &lt; from the concurrent execution, as follows: <em>op</em>1 &lt; <em>op</em>2 iff <em>op</em>1 finishes before <em>op</em>2 starts. There must exist a legal total order <em>T</em> of all operations with their results, such that (1) <em>T</em> is consistent with &lt;, meaning that if <em>op</em>1 &lt; <em>op</em>2 then <em>op</em>1 appears before <em>op</em>2 in <em>T</em>, and (2) <em>T</em> defines a correct sequential execution. Linearizability has been traditionally used to define the correct behavior of concurrent data structures; more recently, it has also been used in distributed systems.</p>
<p>线性化[12]是一致性的一种强形式。 直观上，约束是每个操作必须出现在其开始时间和结束时间之间的瞬时点，其中在这些瞬时点的执行形成有效的顺序执行。 更准确地说，我们从并发执行中定义一个偏序 &lt; ，如下所示： op1 &lt; op2 iff op1 在 op2 开始之前完成。 所有操作及其结果必须存在合法的全序 T，使得 (1) T 与 &lt; 一致，这意味着如果 op1 &lt; op2 则 op1 在 T 中出现在 op2 之前，并且 (2) T 定义了正确的顺序执行 。 线性化传统上被用来定义并发数据结构的正确行为。 最近，它也被用于分布式系统。</p>
<p><em>Sequential consistency [14]</em> is also a strong form of consistency, albeit weaker than linearizability. Intuitively, it requires that operations execute as if they were totally ordered in a way that respects the order in which each client issues operations. More precisely, we define a partial order &lt; as follows: <em>op</em>1 &lt; <em>op</em>2 iff both operations are executed by the same client and <em>op</em>1 finishes before <em>op</em>2 starts. There must exist a total order <em>T</em> such that (1) <em>T</em> is consistent with &lt;, and (2) <em>T</em> defines a correct sequential execution. These conditions are similar to linearizability, except that &lt; reflects just the local order of operations at each client. Sequential consistency is used to define a strongly consistent memory model of a computer, but it could also be used in the context of concurrent data structures.</p>
<p>顺序一致性[14]也是一致性的一种强形式，尽管比线性化弱。 直观上，它要求操作执行时就好像它们是完全有序的，并且尊重每个客户端发出操作的顺序。 更准确地说，我们定义一个偏序 &lt; 如下： op1 &lt; op2 当且仅当两个操作都由同一客户端执行并且 op1 在 op2 开始之前完成。 必须存在一个全序 T，使得 (1) T 与 &lt; 一致，并且 (2) T 定义了正确的顺序执行。 这些条件类似于线性化能力，除了 &lt; 只反映每个客户端的本地操作顺序。 顺序一致性用于定义计算机的强一致性内存模型，但它也可以用在并发数据结构的上下文中。</p>
<p>The next examples pertain to systems that support <em>transactions</em>. Intuitively, a transaction is a bundle of one or more operations that must be executed as a whole. More precisely, there are special operations to start, commit, and abort transactions; and operations on data items are associated with a transaction. The system provides an isolation property, which ensures that transactions do not significantly interfere with one another. There are many isolation properties: serializability, strong session serializability, order-preserving serializability, snapshot isolation, read committed, repeatable reads, etc. All of these are forms of operation consistency, and several of them are of the sequential equivalence subcategory. Here are some examples, all of which are used in the context of database systems.</p>
<p>下一个示例涉及支持事务的系统。 直观上，事务是一组必须作为一个整体执行的一个或多个操作。 更准确地说，有一些特殊的操作来启动、提交和中止事务； 对数据项的操作与事务相关联。 该系统提供了一种隔离属性，可确保事务不会严重干扰彼此。 隔离属性有很多：可序列化、强会话可序列化、保序可序列化、快照隔离、已提交读、可重复读等。所有这些都是操作一致性的形式，其中一些属于顺序等效子类别。 以下是一些示例，所有这些示例都在数据库系统的上下文中使用。</p>
<p><em>Serializability [5]</em> intuitively guarantees that each transaction appears to execute in series. More precisely, serializability imposes a constraint on the operations in a system: the schedule corresponding to those operations must be equivalent to a serial schedule of transactions. The serial schedule is called a serialization of the schedule.</p>
<p>可串行性[5]直观地保证每个事务看起来都是串行执行的。 更准确地说，可串行性对系统中的操作施加了约束：与这些操作相对应的调度必须等于事务的串行调度。 串行调度称为调度的串行化。</p>
<p><em>Strong session serializability [8]</em> addresses an issue with serializability. Serializability allows transactions of the same client to be reordered, which can be undesirable at times. Strong session serializability imposes additional constraints on top of serializability. More precisely, each transaction is associated with a session, and the constraint is that serializability must hold (as defined above) and the serialization must respect the order of transactions within every session: if transaction <em>T</em>1 occurs before <em>T</em>2 in the same session, then <em>T</em>2 is not serialized before <em>T</em>1.</p>
<p>强大的会话可串行性[8]解决了可串行性的问题。 可串行性允许对同一客户端的事务进行重新排序，这有时是不可取的。 强大的会话可串行性在可串行性之上施加了额外的约束。 更准确地说，每个事务都与一个会话关联，并且约束是可串行性必须保持（如上面所定义），并且序列化必须遵守每个会话中事务的顺序：如果事务 T1 在同一会话中发生在 T2 之前，则 T2 在 T1 之前未序列化。</p>
<p><em>Order-preserving serializability [24]</em>, also called strict serializability [6, 17] or strong serializability [7], requires that the serialization order respect the real-time ordering of transactions. More precisely, the constraint is that serializability must hold and the serialization must satisfy the requirement that, if transaction <em>T</em>1 commits before <em>T</em>2 starts, then <em>T</em>2 is not serialized before <em>T</em>1.</p>
<p>保序序列化[24]，也称为严格序列化[6, 17]或强序列化[7]，要求序列化顺序尊重事务的实时排序。 更准确地说，约束是可串行性必须成立，并且串行化必须满足以下要求：如果事务 T1 在 T2 开始之前提交，则 T2 不会在 T1 之前序列化。</p>
<h4 id="3-2-2-Reference-equivalence-参考等效"><a href="#3-2-2-Reference-equivalence-参考等效" class="headerlink" title="3.2.2 Reference equivalence 参考等效"></a>3.2.2 Reference equivalence 参考等效</h4><p>Reference equivalence is a generalization of sequential equivalence. It defines the permitted operation results by requiring the concurrent execution to be equivalent to a given reference, where the notion of equivalence and the reference depend on the consistency property. We now give some examples for systems with transactions. These examples occur often in the context of database systems.</p>
<p>参考等价是顺序等价的推广。 它通过要求并发执行等效于给定的引用来定义允许的操作结果，其中等效的概念和引用取决于一致性属性。 我们现在给出一些具有事务的系统的示例。 这些例子经常出现在数据库系统的环境中。</p>
<p><em>Snapshot isolation [4]</em> requires that transactions behave identically to a certain reference implementation, that is, transactions must have the same outcome as in the reference implementation, and operations must return the same results. The reference implementation is as follows. When a transaction starts, it gets assigned a monotonic start timestamp. When the transaction reads data, it reads from a snapshot of the system as of the start timestamp. When a transaction <em>T</em>1 wishes to commit, the system obtains a monotonic commit timestamp and verifies whether there is some other transaction <em>T</em>2 such that (1) <em>T</em>2 updates some item that <em>T</em>1 also updates, and (2) <em>T</em>2 has committed with a commit timestamp between <em>T</em>1’s start and commit timestamp. If so, then <em>T</em>1 is aborted; otherwise, <em>T</em>1 is committed and all its updates are applied instantaneously as of the time of <em>T</em>1’s commit timestamp.</p>
<p>快照隔离[4]要求事务的行为与某个参考实现相同，即事务必须具有与参考实现相同的结果，并且操作必须返回相同的结果。 参考实现如下。 当事务开始时，它会被分配一个单调的开始时间戳。 当事务读取数据时，它从截至开始时间戳的系统快照中读取。 当事务 T1 希望提交时，系统获取单调提交时间戳并验证是否存在其他事务 T2，以便 (1) T2 更新 T1 也更新的某些项目，以及 (2) T2 已提交，且提交时间戳介于 T1 的开始和提交时间戳。 如果是，则 T1 中止； 否则，T1 将被提交，并且自 T1 的提交时间戳记起立即应用其所有更新。</p>
<p>Interestingly, the next two properties are examples of reference equivalence where the reference is itself defined by another consistency property. This other property is in the serial equivalence subcategory in the first example, and it is in the reference equivalence subcategory in the second example.</p>
<p>有趣的是，接下来的两个属性是引用等效的示例，其中引用本身是由另一个一致性属性定义的。 该其他属性在第一个示例中位于序列等效子类别中，在第二个示例中位于参考等效子类别中。</p>
<p><em>One-copy serializability [5]</em> pertains to a replicated database system. The replicated system must behave like a reference system, which is a system that is not replicated and provides serializability.</p>
<p>单副本可串行化[5]适用于复制数据库系统。 复制系统的行为必须类似于参考系统，参考系统是一个不复制并提供可串行性的系统。</p>
<p><em>One-copy snapshot isolation [15]</em> also pertains to a replicated system. The requirement is that it must behave like a system that is not replicated and that provides snapshot isolation.</p>
<p>单副本快照隔离[15]也适用于复制系统。 要求是它的行为必须像一个不复制且提供快照隔离的系统。</p>
<h4 id="3-2-3-Read-write-centric-以读写为中心"><a href="#3-2-3-Read-write-centric-以读写为中心" class="headerlink" title="3.2.3 Read-write centric 以读写为中心"></a>3.2.3 Read-write centric 以读写为中心</h4><p>The above subcategories of operation consistency apply to systems with arbitrary operations. The read-write centric subcategory applies to systems with two very specific operations: read and write. These systems are important because they include many types of storage systems, such as block storage systems, key value storage systems, and processors accessing memory. By focusing on the two operations, this subcategory permits prop- erties that directly evoke the semantics of the operations. In particular, a write operation returns no information other than an acknowledgment or error status, which has no consistency implications. Thus, the consistency properties focus on the results of reads. Common to these properties is the notion of a read <em>seeing</em> the values of a set of writes, as we now explain. Each read is affected by some writes in the system; if every write covers the entire data item, then writes overwrite each other and the read returns the value written by one of them. But if the writes update just part of a data item, the read returns a combination of the written values in some appropriate order. In either case, the crucial consideration is the set of writes that <em>could</em> have potentially affected the read, irrespective of whether the writes are partial or not; we say that the read <em>sees</em> those writes. This notion is used to define several known consistency properties, as we now exemplify.</p>
<p>上述操作一致性的子类别适用于具有任意操作的系统。 以读写为中心的子类别适用于具有两个非常具体的操作的系统：读和写。 这些系统很重要，因为它们包括许多类型的存储系统，例如块存储系统、键值存储系统和访问内存的处理器。 通过关注这两个操作，该子类别允许直接唤起操作语义的属性。 特别是，写操作除了确认或错误状态之外不返回任何信息，这没有一致性影响。 因此，一致性属性集中于读取的结果。 正如我们现在所解释的，这些属性的共同点是读取看到一组写入的值的概念。 每次读都会受到系统中一些写的影响； 如果每次写入都覆盖整个数据项，则写入会相互覆盖，并且读取会返回其中之一写入的值。 但是，如果写入仅更新数据项的一部分，则读取将按某种适当的顺序返回写入值的组合。 无论哪种情况，关键的考虑因素是可能影响读取的一组写入，无论写入是否部分； 我们说读可以看到那些写。 正如我们现在举例的那样，这个概念用于定义几个已知的一致性属性。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 层级查询</title>
    <url>/2023/02/01/2-%E6%95%B0%E6%8D%AE%E5%BA%93/2-oracle/oracle%E7%B3%BB%E5%88%97%E4%B9%8B%2002-%E5%B1%82%E7%BA%A7%E6%9F%A5%E8%AF%A2/</url>
    <content><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="1-Hierarchical-Queries"><a href="#1-Hierarchical-Queries" class="headerlink" title="1. Hierarchical Queries"></a>1. Hierarchical Queries</h2><p>如果嫌描述啰嗦，直接 看 例子<a href="#info"> prior 例子</a></p>
<h3 id="1-语法"><a href="#1-语法" class="headerlink" title="1. 语法"></a>1. <strong>语法</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">connect</span> <span class="keyword">by</span> [nocycle] <span class="keyword">condition</span> [<span class="keyword">start</span> <span class="keyword">with</span> <span class="keyword">condition</span>]</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">with</span> <span class="keyword">condition</span> <span class="keyword">connect</span> <span class="keyword">by</span> [nocycle] <span class="keyword">condition</span></span><br></pre></td></tr></table></figure>

<span id="more"></span>

<p><code>condition</code> </p>
<p><code>start with</code> 指定层次查询的 root row</p>
<p><code>connect by</code> 指定层次查询中 parent rows 和 child rows 的关系</p>
<ul>
<li>NOCYCLE 参数指示 Oracle 数据库从查询中返回行，即使数据中存在 CONNECT BY 循环。 将此参数与 CONNECT_BY_ISCYCLE 伪列一起使用以查看哪些行包含循环。 有关详细信息，请参阅 CONNECT_BY_ISCYCLE 伪列。</li>
<li>在分层查询中，条件中的一个表达式必须使用 PRIOR 运算符限定以引用父行。 例如，</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">... PRIOR expr <span class="operator">=</span> expr</span><br><span class="line"><span class="keyword">or</span></span><br><span class="line">... expr <span class="operator">=</span> PRIOR expr</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>如果 CONNECT BY 条件是复合条件，则只有一个条件需要 PRIOR 运算符，尽管您可以有多个 PRIOR 条件。 例如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CONNECT</span> <span class="keyword">BY</span> last_name <span class="operator">!=</span> <span class="string">&#x27;King&#x27;</span> <span class="keyword">AND</span> PRIOR employee_id <span class="operator">=</span> manager_id ...</span><br><span class="line"><span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR employee_id <span class="operator">=</span> manager_id <span class="keyword">and</span> </span><br><span class="line">           PRIOR account_mgr_id <span class="operator">=</span> customer_id ...</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>PRIOR 是一元运算符，与一元 + 和 - 算术运算符具有相同的优先级。 它为分层查询中当前行的父行计算紧随其后的表达式。</p>
<p>PRIOR 最常用于使用相等运算符比较列值时。 （PRIOR 关键字可以在运算符的任一侧。） PRIOR 使 Oracle 使用列中父行的值。 在 CONNECT BY 子句中理论上可以使用除等号 (&#x3D;) 以外的运算符。 但是，这些其他运算符创建的条件可能会导致通过可能的组合的无限循环。 在这种情况下，Oracle 在运行时检测到循环并返回错误。</p>
<p>CONNECT BY 条件和 PRIOR 表达式都可以采用不相关子查询的形式。 但是，CURRVAL 和 NEXTVAL 不是有效的 PRIOR 表达式，因此 PRIOR 表达式不能引用序列。</p>
<p>您可以通过使用 CONNECT_BY_ROOT 运算符来进一步细化层次查询，以限定选择列表中的列。 此运算符不仅返回直接父行，而且返回层次结构中的所有祖先行，从而扩展了层次查询的 CONNECT BY [PRIOR] 条件的功能。</p>
<h3 id="2-执行过程"><a href="#2-执行过程" class="headerlink" title="2. 执行过程"></a>2. 执行过程</h3><p>Oracle 按如下方式处理分层查询：</p>
<ul>
<li>如果存在连接，则首先评估连接，无论连接是在 FROM 子句中指定还是使用 WHERE 子句谓词。</li>
<li>评估 CONNECT BY 条件。</li>
<li>评估任何剩余的 WHERE 子句谓词。</li>
</ul>
<p>然后，Oracle 使用来自这些评估的信息通过以下步骤形成层次结构：</p>
<ol>
<li>Oracle 选择层次结构的根行——那些满足 START WITH 条件的行。</li>
<li>Oracle 选择每个根行的子行。每个子行必须满足关于其中一个根行的 CONNECT BY 条件的条件。</li>
<li>Oracle 选择连续几代的子行。 Oracle 首先选择步骤 2 中返回的行的子代，然后选择这些子代的子代，以此类推。 Oracle 总是通过评估与当前父行相关的 CONNECT BY 条件来选择子行。</li>
<li>如果查询包含没有连接的 WHERE 子句，则 Oracle 从层次结构中删除所有不满足 WHERE 子句条件的行。 Oracle 对每一行单独评估此条件，而不是删除不满足条件的行的所有子行。</li>
<li>Oracle 按图 9-1 所示的顺序返回行。在图中，孩子出现在父母的下方。有关分层树的说明，请参见图 3-1。</li>
</ol>
<p><img src="https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlrf/img/sqlrf002.gif" alt="Description of Figure 9-1 follows"></p>
<p>为了找到父行的子行，Oracle 计算父行的 CONNECT BY 条件的 PRIOR 表达式和表中每一行的另一个表达式。 条件为真的行是父项的子项。 CONNECT BY 条件可以包含其他条件以进一步过滤查询选择的行。</p>
<p>如果 CONNECT BY 条件导致层次结构中出现循环，则 Oracle 返回错误。 如果一行既是另一行的父（或祖父母或直接祖先）又是子（或孙子或直接后代），则发生循环。</p>
<blockquote>
<p>注意：在分层查询中，不要指定 ORDER BY 或 GROUP BY，因为它们会覆盖 CONNECT BY 结果的分层顺序。 如果要对同一父级的兄弟行进行排序，请使用 ORDER SIBLINGS BY 子句。 请参见 order_by_clause。</p>
</blockquote>
<h3 id="3-Hierarchical-例子"><a href="#3-Hierarchical-例子" class="headerlink" title="3. Hierarchical  例子"></a>3. Hierarchical  例子</h3><h4 id="3-1CONNECT-BY-Example"><a href="#3-1CONNECT-BY-Example" class="headerlink" title="3.1CONNECT BY Example"></a>3.1<strong>CONNECT BY Example</strong></h4><p>以下分层查询使用 CONNECT BY 子句来定义员工和经理之间的关系：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> employee_id, last_name, manager_id</span><br><span class="line">   <span class="keyword">FROM</span> employees</span><br><span class="line">   <span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR employee_id <span class="operator">=</span> manager_id;</span><br><span class="line"></span><br><span class="line">EMPLOYEE_ID LAST_NAME                 MANAGER_ID</span><br><span class="line"><span class="comment">----------- ------------------------- ----------</span></span><br><span class="line">        <span class="number">101</span> Kochhar                          <span class="number">100</span></span><br><span class="line">        <span class="number">108</span> Greenberg                        <span class="number">101</span></span><br><span class="line">        <span class="number">109</span> Faviet                           <span class="number">108</span></span><br><span class="line">        <span class="number">110</span> Chen                             <span class="number">108</span></span><br><span class="line">        <span class="number">111</span> Sciarra                          <span class="number">108</span></span><br><span class="line">        <span class="number">112</span> Urman                            <span class="number">108</span></span><br><span class="line">        <span class="number">113</span> Popp                             <span class="number">108</span></span><br><span class="line">        <span class="number">200</span> Whalen                           <span class="number">101</span></span><br><span class="line">        <span class="number">203</span> Mavris                           <span class="number">101</span></span><br><span class="line">        <span class="number">204</span> Baer                             <span class="number">101</span></span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<h4 id="3-2-LEVEL-Example"><a href="#3-2-LEVEL-Example" class="headerlink" title="3.2 LEVEL Example"></a>3.2 <strong>LEVEL Example</strong></h4><p>下一个示例与前面的示例类似，但使用 LEVEL 伪列来显示父行和子行：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> employee_id, last_name, manager_id, LEVEL</span><br><span class="line">   <span class="keyword">FROM</span> employees</span><br><span class="line">   <span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR employee_id <span class="operator">=</span> manager_id;</span><br><span class="line"></span><br><span class="line">EMPLOYEE_ID LAST_NAME                 MANAGER_ID      LEVEL</span><br><span class="line"><span class="comment">----------- ------------------------- ---------- ----------</span></span><br><span class="line">        <span class="number">101</span> Kochhar                          <span class="number">100</span>          <span class="number">1</span></span><br><span class="line">        <span class="number">108</span> Greenberg                        <span class="number">101</span>          <span class="number">2</span></span><br><span class="line">        <span class="number">109</span> Faviet                           <span class="number">108</span>          <span class="number">3</span></span><br><span class="line">        <span class="number">110</span> Chen                             <span class="number">108</span>          <span class="number">3</span></span><br><span class="line">        <span class="number">111</span> Sciarra                          <span class="number">108</span>          <span class="number">3</span></span><br><span class="line">        <span class="number">112</span> Urman                            <span class="number">108</span>          <span class="number">3</span></span><br><span class="line">        <span class="number">113</span> Popp                             <span class="number">108</span>          <span class="number">3</span></span><br><span class="line">        <span class="number">200</span> Whalen                           <span class="number">101</span>          <span class="number">2</span></span><br><span class="line">        <span class="number">203</span> Mavris                           <span class="number">101</span>          <span class="number">2</span></span><br><span class="line">        <span class="number">204</span> Baer                             <span class="number">101</span>          <span class="number">2</span></span><br><span class="line">        <span class="number">205</span> Higgins                          <span class="number">101</span>          <span class="number">2</span></span><br><span class="line">        <span class="number">206</span> Gietz                            <span class="number">205</span>          <span class="number">3</span></span><br><span class="line">        <span class="number">102</span> De Haan                          <span class="number">100</span>          <span class="number">1</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h4 id="3-3-START-WITH-Examples"><a href="#3-3-START-WITH-Examples" class="headerlink" title="3.3 START WITH Examples"></a>3.3 <strong>START WITH Examples</strong></h4><p>下一个示例添加一个 START WITH 子句来指定层次结构的根行，并使用 SIBLINGS 关键字添加一个 ORDER BY 子句来保持层次结构内的顺序：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> last_name, employee_id, manager_id, LEVEL</span><br><span class="line">      <span class="keyword">FROM</span> employees</span><br><span class="line">      <span class="keyword">START</span> <span class="keyword">WITH</span> employee_id <span class="operator">=</span> <span class="number">100</span></span><br><span class="line">      <span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR employee_id <span class="operator">=</span> manager_id</span><br><span class="line">      <span class="keyword">ORDER</span> SIBLINGS <span class="keyword">BY</span> last_name;</span><br><span class="line"></span><br><span class="line">LAST_NAME                 EMPLOYEE_ID MANAGER_ID      LEVEL</span><br><span class="line"><span class="comment">------------------------- ----------- ---------- ----------</span></span><br><span class="line">King                              <span class="number">100</span>                     <span class="number">1</span></span><br><span class="line">Cambrault                         <span class="number">148</span>        <span class="number">100</span>          <span class="number">2</span></span><br><span class="line">Bates                             <span class="number">172</span>        <span class="number">148</span>          <span class="number">3</span></span><br><span class="line">Bloom                             <span class="number">169</span>        <span class="number">148</span>          <span class="number">3</span></span><br><span class="line">Fox                               <span class="number">170</span>        <span class="number">148</span>          <span class="number">3</span></span><br><span class="line">Kumar                             <span class="number">173</span>        <span class="number">148</span>          <span class="number">3</span></span><br><span class="line">Ozer                              <span class="number">168</span>        <span class="number">148</span>          <span class="number">3</span></span><br><span class="line">Smith                             <span class="number">171</span>        <span class="number">148</span>          <span class="number">3</span></span><br><span class="line">De Haan                           <span class="number">102</span>        <span class="number">100</span>          <span class="number">2</span></span><br><span class="line">Hunold                            <span class="number">103</span>        <span class="number">102</span>          <span class="number">3</span></span><br><span class="line">Austin                            <span class="number">105</span>        <span class="number">103</span>          <span class="number">4</span></span><br><span class="line">Ernst                             <span class="number">104</span>        <span class="number">103</span>          <span class="number">4</span></span><br><span class="line">Lorentz                           <span class="number">107</span>        <span class="number">103</span>          <span class="number">4</span></span><br><span class="line">Pataballa                         <span class="number">106</span>        <span class="number">103</span>          <span class="number">4</span></span><br><span class="line">Errazuriz                         <span class="number">147</span>        <span class="number">100</span>          <span class="number">2</span></span><br><span class="line">Ande                              <span class="number">166</span>        <span class="number">147</span>          <span class="number">3</span></span><br><span class="line">Banda                             <span class="number">167</span>        <span class="number">147</span>          <span class="number">3</span></span><br><span class="line">...</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在 hr.employees 表中，员工 Steven King 是公司的负责人，没有经理。 他的员工中有 John Russell，他是部门 80 的经理。如果您更新 employees 表以将 Russell 设置为 King 的经理，您会在数据中创建一个循环：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> employees <span class="keyword">SET</span> manager_id <span class="operator">=</span> <span class="number">145</span></span><br><span class="line">   <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> last_name &quot;Employee&quot;, </span><br><span class="line">   LEVEL, SYS_CONNECT_BY_PATH(last_name, <span class="string">&#x27;/&#x27;</span>) &quot;Path&quot;</span><br><span class="line">   <span class="keyword">FROM</span> employees</span><br><span class="line">   <span class="keyword">WHERE</span> level <span class="operator">&lt;=</span> <span class="number">3</span> <span class="keyword">AND</span> department_id <span class="operator">=</span> <span class="number">80</span></span><br><span class="line">   <span class="keyword">START</span> <span class="keyword">WITH</span> last_name <span class="operator">=</span> <span class="string">&#x27;King&#x27;</span></span><br><span class="line">   <span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR employee_id <span class="operator">=</span> manager_id <span class="keyword">AND</span> LEVEL <span class="operator">&lt;=</span> <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">ERROR:</span><br><span class="line">ORA<span class="number">-01436</span>: <span class="keyword">CONNECT</span> <span class="keyword">BY</span> loop <span class="keyword">in</span> <span class="keyword">user</span> data</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>CONNECT BY 条件中的 NOCYCLE 参数使 Oracle 尽管有循环仍返回行。 CONNECT_BY_ISCYCLE 伪列显示哪些行包含循环：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> last_name &quot;Employee&quot;, CONNECT_BY_ISCYCLE &quot;Cycle&quot;,</span><br><span class="line">   LEVEL, SYS_CONNECT_BY_PATH(last_name, <span class="string">&#x27;/&#x27;</span>) &quot;Path&quot;</span><br><span class="line">   <span class="keyword">FROM</span> employees</span><br><span class="line">   <span class="keyword">WHERE</span> level <span class="operator">&lt;=</span> <span class="number">3</span> <span class="keyword">AND</span> department_id <span class="operator">=</span> <span class="number">80</span></span><br><span class="line">   <span class="keyword">START</span> <span class="keyword">WITH</span> last_name <span class="operator">=</span> <span class="string">&#x27;King&#x27;</span></span><br><span class="line">   <span class="keyword">CONNECT</span> <span class="keyword">BY</span> NOCYCLE PRIOR employee_id <span class="operator">=</span> manager_id <span class="keyword">AND</span> LEVEL <span class="operator">&lt;=</span> <span class="number">4</span></span><br><span class="line">   <span class="keyword">ORDER</span> <span class="keyword">BY</span> &quot;Employee&quot;, &quot;Cycle&quot;, LEVEL, &quot;Path&quot;;</span><br><span class="line"></span><br><span class="line">Employee                       <span class="keyword">Cycle</span>      LEVEL Path</span><br><span class="line"><span class="comment">------------------------- ---------- ---------- -------------------------</span></span><br><span class="line">Abel                               <span class="number">0</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Zlotkey<span class="operator">/</span>Abel</span><br><span class="line">Ande                               <span class="number">0</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Errazuriz<span class="operator">/</span>Ande</span><br><span class="line">Banda                              <span class="number">0</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Errazuriz<span class="operator">/</span>Banda</span><br><span class="line">Bates                              <span class="number">0</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Cambrault<span class="operator">/</span>Bates</span><br><span class="line">Bernstein                          <span class="number">0</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Russell<span class="operator">/</span>Bernstein</span><br><span class="line">Bloom                              <span class="number">0</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Cambrault<span class="operator">/</span>Bloom</span><br><span class="line">Cambrault                          <span class="number">0</span>          <span class="number">2</span> <span class="operator">/</span>King<span class="operator">/</span>Cambrault</span><br><span class="line">Cambrault                          <span class="number">0</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Russell<span class="operator">/</span>Cambrault</span><br><span class="line">Doran                              <span class="number">0</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Partners<span class="operator">/</span>Doran</span><br><span class="line">Errazuriz                          <span class="number">0</span>          <span class="number">2</span> <span class="operator">/</span>King<span class="operator">/</span>Errazuriz</span><br><span class="line">Fox                                <span class="number">0</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Cambrault<span class="operator">/</span>Fox</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h4 id="3-4-CONNECT-BY-ISLEAF-Example"><a href="#3-4-CONNECT-BY-ISLEAF-Example" class="headerlink" title="3.4 CONNECT_BY_ISLEAF Example"></a>3.4 <strong>CONNECT_BY_ISLEAF Example</strong></h4><p>以下语句显示了如何使用分层查询将列中的值转换为逗号分隔的列表：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> LTRIM(SYS_CONNECT_BY_PATH (warehouse_id,<span class="string">&#x27;,&#x27;</span>),<span class="string">&#x27;,&#x27;</span>) <span class="keyword">FROM</span></span><br><span class="line">   (<span class="keyword">SELECT</span> ROWNUM r, warehouse_id <span class="keyword">FROM</span> warehouses)</span><br><span class="line">   <span class="keyword">WHERE</span> CONNECT_BY_ISLEAF <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">   <span class="keyword">START</span> <span class="keyword">WITH</span> r <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">   <span class="keyword">CONNECT</span> <span class="keyword">BY</span> r <span class="operator">=</span> PRIOR r <span class="operator">+</span> <span class="number">1</span></span><br><span class="line">   <span class="keyword">ORDER</span> <span class="keyword">BY</span> warehouse_id; </span><br><span class="line"> </span><br><span class="line">LTRIM(SYS_CONNECT_BY_PATH(WAREHOUSE_ID,<span class="string">&#x27;,&#x27;</span>),<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line"><span class="comment">--------------------------------------------------------------------------------</span></span><br><span class="line"><span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span></span><br></pre></td></tr></table></figure>

<h4 id="3-5-CONNECT-BY-ROOT-Examples"><a href="#3-5-CONNECT-BY-ROOT-Examples" class="headerlink" title="3.5 CONNECT_BY_ROOT Examples"></a>3.5 <strong>CONNECT_BY_ROOT Examples</strong></h4><p>以下示例返回部门 110 中每个员工的姓氏、层次结构中该员工上方最高级别的每个经理、经理和员工之间的级别数以及两者之间的路径：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> last_name &quot;Employee&quot;, CONNECT_BY_ROOT last_name &quot;Manager&quot;,</span><br><span class="line">   LEVEL<span class="number">-1</span> &quot;Pathlen&quot;, SYS_CONNECT_BY_PATH(last_name, <span class="string">&#x27;/&#x27;</span>) &quot;Path&quot;</span><br><span class="line">   <span class="keyword">FROM</span> employees</span><br><span class="line">   <span class="keyword">WHERE</span> LEVEL <span class="operator">&gt;</span> <span class="number">1</span> <span class="keyword">and</span> department_id <span class="operator">=</span> <span class="number">110</span></span><br><span class="line">   <span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR employee_id <span class="operator">=</span> manager_id</span><br><span class="line">   <span class="keyword">ORDER</span> <span class="keyword">BY</span> &quot;Employee&quot;, &quot;Manager&quot;, &quot;Pathlen&quot;, &quot;Path&quot;;</span><br><span class="line"></span><br><span class="line">Employee        Manager            Pathlen Path</span><br><span class="line"><span class="comment">--------------- --------------- ---------- ------------------------------</span></span><br><span class="line">Gietz           Higgins                  <span class="number">1</span> <span class="operator">/</span>Higgins<span class="operator">/</span>Gietz</span><br><span class="line">Gietz           King                     <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Kochhar<span class="operator">/</span>Higgins<span class="operator">/</span>Gietz</span><br><span class="line">Gietz           Kochhar                  <span class="number">2</span> <span class="operator">/</span>Kochhar<span class="operator">/</span>Higgins<span class="operator">/</span>Gietz</span><br><span class="line">Higgins         King                     <span class="number">2</span> <span class="operator">/</span>King<span class="operator">/</span>Kochhar<span class="operator">/</span>Higgins</span><br><span class="line">Higgins         Kochhar                  <span class="number">1</span> <span class="operator">/</span>Kochhar<span class="operator">/</span>Higgins</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以下示例使用 GROUP BY 子句返回部门 110 中每个员工的总工资以及层次结构中该员工之上的所有员工：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> name, <span class="built_in">SUM</span>(salary) &quot;Total_Salary&quot; <span class="keyword">FROM</span> (</span><br><span class="line">   <span class="keyword">SELECT</span> CONNECT_BY_ROOT last_name <span class="keyword">as</span> name, Salary</span><br><span class="line">      <span class="keyword">FROM</span> employees</span><br><span class="line">      <span class="keyword">WHERE</span> department_id <span class="operator">=</span> <span class="number">110</span></span><br><span class="line">      <span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR employee_id <span class="operator">=</span> manager_id)</span><br><span class="line">      <span class="keyword">GROUP</span> <span class="keyword">BY</span> name</span><br><span class="line">   <span class="keyword">ORDER</span> <span class="keyword">BY</span> name, &quot;Total_Salary&quot;;</span><br><span class="line"></span><br><span class="line">NAME                      Total_Salary</span><br><span class="line"><span class="comment">------------------------- ------------</span></span><br><span class="line">Gietz                             <span class="number">8300</span></span><br><span class="line">Higgins                          <span class="number">20300</span></span><br><span class="line">King                             <span class="number">20300</span></span><br><span class="line">Kochhar                          <span class="number">20300</span></span><br></pre></td></tr></table></figure>







<h2 id="2-Hierarchical-Operators"><a href="#2-Hierarchical-Operators" class="headerlink" title="2. Hierarchical  Operators"></a>2. Hierarchical  Operators</h2><p>两个运算符 PRIOR 和 CONNECT_BY_ROOT 仅在分层查询中有效</p>
<h3 id="1-PRIOR"><a href="#1-PRIOR" class="headerlink" title="1. PRIOR"></a>1. PRIOR</h3><p>在分层查询中，CONNECT BY 条件中的一个表达式必须由 PRIOR 运算符限定。 如果 CONNECT BY 条件是复合条件，则只有一个条件需要 PRIOR 运算符，尽管您可以有多个 PRIOR 条件。 PRIOR 计算层次查询中当前行的父行的紧随其后的表达式。</p>
<p>PRIOR 最常用于使用相等运算符比较列值时。 （PRIOR 关键字可以在运算符的任一侧。） PRIOR 使 Oracle 使用列中父行的值。 在 CONNECT BY 子句中理论上可以使用除等号 (&#x3D;) 以外的运算符。 但是，这些其他运算符创建的条件可能会导致通过可能的组合的无限循环。 在这种情况下，Oracle 在运行时检测到循环并返回错误。 有关此运算符的更多信息（包括示例），请参阅分层查询。</p>
<p>如果还不理解 prior，见后面的例子<a href="#info"> prior 例子</a></p>
<h3 id="2-CONNECT-BY-ROOT"><a href="#2-CONNECT-BY-ROOT" class="headerlink" title="2. CONNECT_BY_ROOT"></a>2. CONNECT_BY_ROOT</h3><p>CONNECT_BY_ROOT 是一元运算符，仅在分层查询中有效。 当您使用此运算符限定列时，Oracle 使用根行中的数据返回列值。 此运算符扩展了分层查询的 CONNECT BY [PRIOR] 条件的功能。</p>
<p>对 CONNECT_BY_ROOT 的限制</p>
<p>您不能在 START WITH 条件或 CONNECT BY 条件中指定此运算符。</p>
<h2 id="3-Hierarchical-伪列"><a href="#3-Hierarchical-伪列" class="headerlink" title="3. Hierarchical  伪列"></a>3. Hierarchical  伪列</h2><p>分层查询伪列仅 (Pseudocolumns) 在分层查询中有效。 分层查询伪列是：</p>
<ul>
<li>[CONNECT_BY_ISCYCLE Pseudocolumn]</li>
<li>[CONNECT_BY_ISLEAF Pseudocolumn]</li>
<li>[LEVEL Pseudocolumn]</li>
</ul>
<p>要在查询中定义层次关系，您必须使用 CONNECT BY 子句。</p>
<h3 id="3-1-CONNECT-BY-ISCYCLE"><a href="#3-1-CONNECT-BY-ISCYCLE" class="headerlink" title="3.1 CONNECT_BY_ISCYCLE"></a>3.1 CONNECT_BY_ISCYCLE</h3><p>如果当前行有一个也是其祖先的子项，则 CONNECT_BY_ISCYCLE 伪列返回 1。 否则返回 0。</p>
<p>仅当您已指定 CONNECT BY 子句的 NOCYCLE 参数时，您才能指定 CONNECT_BY_ISCYCLE。 NOCYCLE 使 Oracle 能够返回查询的结果，否则该查询会因数据中的 CONNECT BY 循环而失败。</p>
<h3 id="3-2-CONNECT-BY-ISLEAF"><a href="#3-2-CONNECT-BY-ISLEAF" class="headerlink" title="3.2 CONNECT_BY_ISLEAF"></a>3.2 CONNECT_BY_ISLEAF</h3><p>如果当前行是由 CONNECT BY 条件定义的树的叶子，则 CONNECT_BY_ISLEAF 伪列返回 1。 否则返回 0。此信息指示是否可以进一步扩展给定行以显示更多层次结构。</p>
<p><strong>CONNECT_BY_ISLEAF Example</strong></p>
<p>以下示例显示了 hr.employees 表的前三个级别，为每一行指示它是叶行（在 IsLeaf 列中用 1 表示）还是有子行（在 IsLeaf 列中用 0 表示）：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> last_name &quot;Employee&quot;, CONNECT_BY_ISLEAF &quot;IsLeaf&quot;,</span><br><span class="line">       LEVEL, SYS_CONNECT_BY_PATH(last_name, <span class="string">&#x27;/&#x27;</span>) &quot;Path&quot;</span><br><span class="line">  <span class="keyword">FROM</span> employees</span><br><span class="line">  <span class="keyword">WHERE</span> LEVEL <span class="operator">&lt;=</span> <span class="number">3</span> <span class="keyword">AND</span> department_id <span class="operator">=</span> <span class="number">80</span></span><br><span class="line">  <span class="keyword">START</span> <span class="keyword">WITH</span> employee_id <span class="operator">=</span> <span class="number">100</span></span><br><span class="line">  <span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR employee_id <span class="operator">=</span> manager_id <span class="keyword">AND</span> LEVEL <span class="operator">&lt;=</span> <span class="number">4</span></span><br><span class="line">  <span class="keyword">ORDER</span> <span class="keyword">BY</span> &quot;Employee&quot;, &quot;IsLeaf&quot;;</span><br><span class="line"></span><br><span class="line">Employee                      IsLeaf      LEVEL Path</span><br><span class="line"><span class="comment">------------------------- ---------- ---------- -------------------------</span></span><br><span class="line">Abel                               <span class="number">1</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Zlotkey<span class="operator">/</span>Abel</span><br><span class="line">Ande                               <span class="number">1</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Errazuriz<span class="operator">/</span>Ande</span><br><span class="line">Banda                              <span class="number">1</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Errazuriz<span class="operator">/</span>Banda</span><br><span class="line">Bates                              <span class="number">1</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Cambrault<span class="operator">/</span>Bates</span><br><span class="line">Bernstein                          <span class="number">1</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Russell<span class="operator">/</span>Bernstein</span><br><span class="line">Bloom                              <span class="number">1</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Cambrault<span class="operator">/</span>Bloom</span><br><span class="line">Cambrault                          <span class="number">0</span>          <span class="number">2</span> <span class="operator">/</span>King<span class="operator">/</span>Cambrault</span><br><span class="line">Cambrault                          <span class="number">1</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Russell<span class="operator">/</span>Cambrault</span><br><span class="line">Doran                              <span class="number">1</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Partners<span class="operator">/</span>Doran</span><br><span class="line">Errazuriz                          <span class="number">0</span>          <span class="number">2</span> <span class="operator">/</span>King<span class="operator">/</span>Errazuriz</span><br><span class="line">Fox                                <span class="number">1</span>          <span class="number">3</span> <span class="operator">/</span>King<span class="operator">/</span>Cambrault<span class="operator">/</span>Fox</span><br><span class="line">. . . </span><br></pre></td></tr></table></figure>

<h3 id="3-3-LEVEL"><a href="#3-3-LEVEL" class="headerlink" title="3.3 LEVEL"></a>3.3 LEVEL</h3><p>对于分层查询返回的每一行，LEVEL 伪列为根行返回 1，为根的子行返回 2，依此类推。 根行是倒排树中的最高行。 子行是任何非根行。 父行是具有子行的任何行。 叶行是任何没有子行的行。 图 3-1 显示了倒排树的节点及其 LEVEL 值。</p>
<p><img src="https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlrf/img/sqlrf001.gif" alt="Description of Figure 3-1 follows"></p>
<h2 id="4-SYS-CONNECT-BY-PATH"><a href="#4-SYS-CONNECT-BY-PATH" class="headerlink" title="4. SYS_CONNECT_BY_PATH"></a>4. SYS_CONNECT_BY_PATH</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">SYS_CONNECT_BY_PATH (<span class="keyword">column</span>, <span class="type">char</span>) </span><br></pre></td></tr></table></figure>

<h3 id="4-1-功能"><a href="#4-1-功能" class="headerlink" title="4.1 功能"></a>4.1 功能</h3><p>SYS_CONNECT_BY_PATH 仅在分层查询中有效。 它返回列值从根到节点的路径，对于 CONNECT BY 条件返回的每一行，列值由 char 分隔。</p>
<p>column 和 char 都可以是任何数据类型 CHAR、VARCHAR2、NCHAR 或 NVARCHAR2。 返回的字符串是 VARCHAR2 数据类型，并且与列在同一字符集中。</p>
<h3 id="4-2-例子"><a href="#4-2-例子" class="headerlink" title="4.2 例子"></a>4.2 <strong>例子</strong></h3><p>以下示例返回从员工 Kochhar 到 Kochhar 的所有员工（及其员工）的员工姓名路径：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> LPAD(<span class="string">&#x27; &#x27;</span>, <span class="number">2</span><span class="operator">*</span>level<span class="number">-1</span>)<span class="operator">||</span>SYS_CONNECT_BY_PATH(last_name, <span class="string">&#x27;/&#x27;</span>) &quot;Path&quot;</span><br><span class="line">   <span class="keyword">FROM</span> employees</span><br><span class="line">   <span class="keyword">START</span> <span class="keyword">WITH</span> last_name <span class="operator">=</span> <span class="string">&#x27;Kochhar&#x27;</span></span><br><span class="line">   <span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR employee_id <span class="operator">=</span> manager_id;</span><br><span class="line"></span><br><span class="line">Path</span><br><span class="line"><span class="comment">------------------------------</span></span><br><span class="line">     <span class="operator">/</span>Kochhar<span class="operator">/</span>Greenberg<span class="operator">/</span>Chen</span><br><span class="line">     <span class="operator">/</span>Kochhar<span class="operator">/</span>Greenberg<span class="operator">/</span>Faviet</span><br><span class="line">     <span class="operator">/</span>Kochhar<span class="operator">/</span>Greenberg<span class="operator">/</span>Popp</span><br><span class="line">     <span class="operator">/</span>Kochhar<span class="operator">/</span>Greenberg<span class="operator">/</span>Sciarra</span><br><span class="line">     <span class="operator">/</span>Kochhar<span class="operator">/</span>Greenberg<span class="operator">/</span>Urman</span><br><span class="line">     <span class="operator">/</span>Kochhar<span class="operator">/</span>Higgins<span class="operator">/</span>Gietz</span><br><span class="line">   <span class="operator">/</span>Kochhar<span class="operator">/</span>Baer</span><br><span class="line">   <span class="operator">/</span>Kochhar<span class="operator">/</span>Greenberg</span><br><span class="line">   <span class="operator">/</span>Kochhar<span class="operator">/</span>Higgins</span><br><span class="line">   <span class="operator">/</span>Kochhar<span class="operator">/</span>Mavris</span><br><span class="line">   <span class="operator">/</span>Kochhar<span class="operator">/</span>Whalen</span><br><span class="line"> <span class="operator">/</span>Kochhar</span><br></pre></td></tr></table></figure>



<h2 id="5-例子"><a href="#5-例子" class="headerlink" title="5. 例子"></a>5. 例子</h2><h3 id="5-1-构造数据"><a href="#5-1-构造数据" class="headerlink" title="5.1 构造数据"></a>5.1 构造数据</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_tree (</span><br><span class="line">  test_id   <span class="type">INT</span>  <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  pid       <span class="type">INT</span>,</span><br><span class="line">  test_val  <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (test_id)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">1</span>, <span class="number">0</span>,   <span class="string">&#x27;.NET&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">2</span>, <span class="number">1</span>,      <span class="string">&#x27;C#&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">3</span>, <span class="number">1</span>,      <span class="string">&#x27;J#&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">4</span>, <span class="number">1</span>,      <span class="string">&#x27;ASP.NET&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">5</span>, <span class="number">1</span>,      <span class="string">&#x27;VB.NET&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">6</span>, <span class="number">0</span>,   <span class="string">&#x27;J2EE&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">7</span>, <span class="number">6</span>,      <span class="string">&#x27;EJB&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">8</span>, <span class="number">6</span>,      <span class="string">&#x27;Servlet&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">9</span>, <span class="number">6</span>,      <span class="string">&#x27;JSP&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">10</span>, <span class="number">0</span>,  <span class="string">&#x27;Database&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">11</span>, <span class="number">10</span>,    <span class="string">&#x27;DB2&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">12</span>, <span class="number">10</span>,    <span class="string">&#x27;MySQL&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">13</span>, <span class="number">10</span>,    <span class="string">&#x27;Oracle&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">14</span>, <span class="number">10</span>,    <span class="string">&#x27;SQL Server&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">15</span>, <span class="number">13</span>,    <span class="string">&#x27;PL/SQL&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">16</span>, <span class="number">15</span>,    <span class="string">&#x27;Function&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">17</span>, <span class="number">15</span>,    <span class="string">&#x27;Procedure&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">18</span>, <span class="number">15</span>,    <span class="string">&#x27;Package&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">19</span>, <span class="number">15</span>,    <span class="string">&#x27;Cursor&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_tree <span class="keyword">VALUES</span>(<span class="number">20</span>, <span class="number">14</span>,    <span class="string">&#x27;T-SQL&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  LEVEL,</span><br><span class="line">  test_id,</span><br><span class="line">  test_val,</span><br><span class="line">  SYS_CONNECT_BY_PATH(test_val, <span class="string">&#x27;\&#x27;</span>) <span class="keyword">AS</span> &quot;FullPath&quot;</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">  test_tree</span><br><span class="line"><span class="keyword">START</span> <span class="keyword">WITH</span></span><br><span class="line">  pid <span class="operator">=</span><span class="number">0</span></span><br><span class="line"><span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR test_id <span class="operator">=</span> pid</span><br><span class="line"><span class="keyword">ORDER</span> SIBLINGS <span class="keyword">BY</span> test_val;</span><br></pre></td></tr></table></figure>



<h3 id="5-2-执行结果解释"><a href="#5-2-执行结果解释" class="headerlink" title="5.2 执行结果解释"></a>5.2 执行结果解释</h3><p> start with 配合 level 解释比较好理解，如果不指定 start with， 那么所有数据都会作为 根行，也就是 level 1。</p>
<p>如果指定了 start with ，被指定的行为根行。 </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 不指定 start with</span></span><br><span class="line"><span class="keyword">SELECT</span>  level ,test_id, pid, test_val <span class="keyword">from</span> test_tree   <span class="keyword">CONNECT</span> <span class="keyword">BY</span>  prior test_id<span class="operator">=</span> pid </span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> <span class="number">1</span>,<span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>	<span class="number">1</span>	  <span class="number">0</span> 	.NET</span><br><span class="line"><span class="number">1</span>	<span class="number">2</span>  	<span class="number">1</span>  	C#</span><br><span class="line"><span class="number">1</span>	<span class="number">3</span>  	<span class="number">1</span>  	J#</span><br><span class="line"><span class="number">1</span>	<span class="number">4</span>	  <span class="number">1</span>  	ASP.NET</span><br><span class="line"><span class="number">1</span>	<span class="number">5</span>	  <span class="number">1</span>  	VB.NET</span><br><span class="line"><span class="number">1</span>	<span class="number">6</span>  	<span class="number">0</span>  	J2EE</span><br><span class="line"><span class="number">1</span>	<span class="number">7</span>	  <span class="number">6</span>  	EJB</span><br><span class="line"><span class="number">1</span>	<span class="number">8</span>	  <span class="number">6</span>  	Servlet</span><br><span class="line"><span class="number">1</span>	<span class="number">9</span>	  <span class="number">6</span>  	JSP</span><br><span class="line"><span class="number">1</span>	<span class="number">10</span>	<span class="number">0</span>	  Database</span><br><span class="line"><span class="number">1</span>	<span class="number">11</span>	<span class="number">10</span>	DB2</span><br><span class="line"><span class="number">1</span>	<span class="number">12</span>	<span class="number">10</span>	MySQL</span><br><span class="line"><span class="number">1</span>	<span class="number">13</span>	<span class="number">10</span>	Oracle</span><br><span class="line"><span class="number">1</span>	<span class="number">14</span>	<span class="number">10</span>	<span class="keyword">SQL</span> Server</span><br><span class="line"><span class="number">1</span>	<span class="number">15</span>	<span class="number">13</span>	PL<span class="operator">/</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">1</span>	<span class="number">16</span>	<span class="number">15</span>	<span class="keyword">Function</span></span><br><span class="line"><span class="number">1</span>	<span class="number">17</span>	<span class="number">15</span>	<span class="keyword">Procedure</span></span><br><span class="line"><span class="number">1</span>	<span class="number">18</span>	<span class="number">15</span>	Package</span><br><span class="line"><span class="number">1</span>	<span class="number">19</span>	<span class="number">15</span>	<span class="keyword">Cursor</span></span><br><span class="line"><span class="number">1</span>	<span class="number">20</span>	<span class="number">14</span>	T<span class="operator">-</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">2</span>	<span class="number">2</span>	  <span class="number">1</span>	  C#</span><br><span class="line"><span class="number">2</span>	<span class="number">3</span>  	<span class="number">1</span>	  J#</span><br><span class="line"><span class="number">2</span>	<span class="number">4</span>  	<span class="number">1</span>  	ASP.NET</span><br><span class="line"><span class="number">2</span>	<span class="number">5</span>  	<span class="number">1</span>  	VB.NET</span><br><span class="line"><span class="number">2</span>	<span class="number">7</span>	  <span class="number">6</span>  	EJB</span><br><span class="line"><span class="number">2</span>	<span class="number">8</span>	  <span class="number">6</span>  	Servlet</span><br><span class="line"><span class="number">2</span>	<span class="number">9</span>	  <span class="number">6</span>  	JSP</span><br><span class="line"><span class="number">2</span>	<span class="number">11</span>	<span class="number">10</span>	DB2</span><br><span class="line"><span class="number">2</span>	<span class="number">12</span>	<span class="number">10</span>	MySQL</span><br><span class="line"><span class="number">2</span>	<span class="number">13</span>	<span class="number">10</span>	Oracle</span><br><span class="line"><span class="number">2</span>	<span class="number">14</span>	<span class="number">10</span>	<span class="keyword">SQL</span> Server</span><br><span class="line"><span class="number">2</span>	<span class="number">15</span>	<span class="number">13</span>	PL<span class="operator">/</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">2</span>	<span class="number">16</span>	<span class="number">15</span>	<span class="keyword">Function</span></span><br><span class="line"><span class="number">2</span>	<span class="number">17</span>	<span class="number">15</span>	<span class="keyword">Procedure</span></span><br><span class="line"><span class="number">2</span>	<span class="number">18</span>	<span class="number">15</span>	Package</span><br><span class="line"><span class="number">2</span>	<span class="number">19</span>	<span class="number">15</span>	<span class="keyword">Cursor</span></span><br><span class="line"><span class="number">2</span>	<span class="number">20</span>	<span class="number">14</span>	T<span class="operator">-</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">3</span>	<span class="number">15</span>	<span class="number">13</span>	PL<span class="operator">/</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">3</span>	<span class="number">16</span>	<span class="number">15</span>	<span class="keyword">Function</span></span><br><span class="line"><span class="number">3</span>	<span class="number">17</span>	<span class="number">15</span>	<span class="keyword">Procedure</span></span><br><span class="line"><span class="number">3</span>	<span class="number">18</span>	<span class="number">15</span>	Package</span><br><span class="line"><span class="number">3</span>	<span class="number">19</span>	<span class="number">15</span>	<span class="keyword">Cursor</span></span><br><span class="line"><span class="number">3</span>	<span class="number">20</span>	<span class="number">14</span>	T<span class="operator">-</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">4</span>	<span class="number">16</span>	<span class="number">15</span>	<span class="keyword">Function</span></span><br><span class="line"><span class="number">4</span>	<span class="number">17</span>	<span class="number">15</span>	<span class="keyword">Procedure</span></span><br><span class="line"><span class="number">4</span>	<span class="number">18</span>	<span class="number">15</span>	Package</span><br><span class="line"><span class="number">4</span>	<span class="number">19</span>	<span class="number">15</span>	<span class="keyword">Cursor</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 指定 start with</span></span><br><span class="line"><span class="keyword">SELECT</span>  level ,test_id, pid, test_val <span class="keyword">from</span> test_tree  </span><br><span class="line"><span class="keyword">start</span> <span class="keyword">with</span> test_id<span class="operator">=</span><span class="number">10</span> <span class="keyword">CONNECT</span> <span class="keyword">BY</span>  prior test_id<span class="operator">=</span> pid <span class="keyword">order</span> <span class="keyword">by</span> <span class="number">1</span>,<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>	<span class="number">10</span>	<span class="number">0</span>	  Database</span><br><span class="line"><span class="number">2</span>	<span class="number">11</span>	<span class="number">10</span>	DB2</span><br><span class="line"><span class="number">2</span>	<span class="number">12</span>	<span class="number">10</span>	MySQL</span><br><span class="line"><span class="number">2</span>	<span class="number">13</span>	<span class="number">10</span>	Oracle</span><br><span class="line"><span class="number">2</span>	<span class="number">14</span>	<span class="number">10</span>	<span class="keyword">SQL</span> Server</span><br><span class="line"><span class="number">3</span>	<span class="number">15</span>	<span class="number">13</span>	PL<span class="operator">/</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">3</span>	<span class="number">20</span>	<span class="number">14</span>	T<span class="operator">-</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">4</span>	<span class="number">16</span>	<span class="number">15</span>	<span class="keyword">Function</span></span><br><span class="line"><span class="number">4</span>	<span class="number">17</span>	<span class="number">15</span>	<span class="keyword">Procedure</span></span><br><span class="line"><span class="number">4</span>	<span class="number">18</span>	<span class="number">15</span>	Package</span><br><span class="line"><span class="number">4</span>	<span class="number">19</span>	<span class="number">15</span>	<span class="keyword">Cursor</span></span><br></pre></td></tr></table></figure>



<p><a id="info"> prior例子 </a> 由于prior 可能会不大好理解，这里再详细解释一下</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  level ,test_id, pid, test_val <span class="keyword">from</span> test_tree  </span><br><span class="line"><span class="keyword">start</span> <span class="keyword">with</span> test_id<span class="operator">=</span><span class="number">10</span> <span class="keyword">CONNECT</span> <span class="keyword">BY</span>  prior test_id<span class="operator">=</span> pid <span class="keyword">order</span> <span class="keyword">by</span> <span class="number">1</span>,<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>	<span class="number">10</span>	<span class="number">0</span>	  Database</span><br><span class="line"><span class="number">2</span>	<span class="number">11</span>	<span class="number">10</span>	DB2</span><br><span class="line"><span class="number">2</span>	<span class="number">12</span>	<span class="number">10</span>	MySQL</span><br><span class="line"><span class="number">2</span>	<span class="number">13</span>	<span class="number">10</span>	Oracle</span><br><span class="line"><span class="number">2</span>	<span class="number">14</span>	<span class="number">10</span>	<span class="keyword">SQL</span> Server</span><br><span class="line"><span class="number">3</span>	<span class="number">15</span>	<span class="number">13</span>	PL<span class="operator">/</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">3</span>	<span class="number">20</span>	<span class="number">14</span>	T<span class="operator">-</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">4</span>	<span class="number">16</span>	<span class="number">15</span>	<span class="keyword">Function</span></span><br><span class="line"><span class="number">4</span>	<span class="number">17</span>	<span class="number">15</span>	<span class="keyword">Procedure</span></span><br><span class="line"><span class="number">4</span>	<span class="number">18</span>	<span class="number">15</span>	Package</span><br><span class="line"><span class="number">4</span>	<span class="number">19</span>	<span class="number">15</span>	<span class="keyword">Cursor</span></span><br><span class="line"></span><br><span class="line">                                此时 形成的 树形结构为</span><br><span class="line">         level <span class="number">1</span>                    <span class="number">10</span></span><br><span class="line">                                    ｜</span><br><span class="line">                         ————————<span class="comment">----------————————</span></span><br><span class="line">                        ｜      ｜       ｜        ｜</span><br><span class="line">         level <span class="number">2</span>        <span class="number">11</span>      <span class="number">12</span>      <span class="number">13</span>        <span class="number">14</span>     <span class="comment">-----&gt; prior 指定 父行</span></span><br><span class="line">                        ｜      ｜       ｜        ｜</span><br><span class="line">         level <span class="number">3</span>                        <span class="number">15</span>        <span class="number">20</span>     <span class="comment">-----&gt; prior 指定</span></span><br><span class="line">                                          <span class="operator">|</span></span><br><span class="line">                                  <span class="comment">---------------</span></span><br><span class="line">                                  <span class="operator">|</span>    <span class="operator">|</span>    <span class="operator">|</span>    <span class="operator">|</span></span><br><span class="line">                                  <span class="number">16</span>   <span class="number">17</span>  <span class="number">18</span>    <span class="number">19</span></span><br><span class="line">         level <span class="number">4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- prior 在另一侧，修改一下 start with 的条件。</span></span><br><span class="line"><span class="keyword">SELECT</span>  level ,test_id, pid, test_val <span class="keyword">from</span> test_tree  </span><br><span class="line"><span class="keyword">start</span> <span class="keyword">with</span> test_id <span class="operator">=</span> <span class="number">15</span> <span class="keyword">CONNECT</span> <span class="keyword">BY</span> test_id <span class="operator">=</span> prior pid <span class="keyword">order</span> <span class="keyword">by</span> <span class="number">1</span>,<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>	<span class="number">15</span>	<span class="number">13</span>	PL<span class="operator">/</span><span class="keyword">SQL</span></span><br><span class="line"><span class="number">2</span>	<span class="number">13</span>	<span class="number">10</span>	Oracle</span><br><span class="line"><span class="number">3</span>	<span class="number">10</span>	<span class="number">0</span>		Database</span><br><span class="line"></span><br><span class="line">                         此时 形成的 树形结构为</span><br><span class="line">         level <span class="number">1</span>             <span class="number">13</span>      <span class="comment">----&gt; prior 指定的父行pid = 13</span></span><br><span class="line">                             <span class="operator">|</span></span><br><span class="line">         level <span class="number">2</span>            <span class="number">10</span></span><br><span class="line">                             <span class="operator">|</span></span><br><span class="line">       	 level <span class="number">3</span>             <span class="number">0</span></span><br><span class="line"></span><br><span class="line">     </span><br></pre></td></tr></table></figure>



<p>完整功能</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 完整的功能有 10 个。</span></span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">test_id, pid, test_val,</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 1. 操作符</span></span><br><span class="line">connect_by_root test_id ,</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 2. 函数</span></span><br><span class="line">SYS_CONNECT_BY_PATH(pid, <span class="string">&#x27;/&#x27;</span>),</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 3. 伪列(三个)</span></span><br><span class="line">CONNECT_BY_ISCYCLE,</span><br><span class="line"><span class="comment">-- 4.</span></span><br><span class="line">CONNECT_BY_ISLEAF,</span><br><span class="line"><span class="comment">-- 5.</span></span><br><span class="line">level</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> test_tree  </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 6. 根行</span></span><br><span class="line"><span class="keyword">start</span> <span class="keyword">with</span> test_id<span class="operator">=</span><span class="number">10</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 7. 父行和子行的关系</span></span><br><span class="line"><span class="keyword">CONNECT</span> <span class="keyword">BY</span> nocycle <span class="comment">/* 8. ( cycle ) */</span> prior <span class="comment">/* 9. 操作符 */</span> test_id<span class="operator">=</span> pid </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 10. 排序</span></span><br><span class="line"><span class="keyword">ORDER</span> SIBLINGS <span class="keyword">BY</span> test_id;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">10</span>	<span class="number">0</span>		Database		<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span>					<span class="number">0</span>	<span class="number">0</span>	<span class="number">1</span></span><br><span class="line"><span class="number">11</span>	<span class="number">10</span>	DB2					<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span><span class="operator">/</span><span class="number">10</span>				<span class="number">0</span>	<span class="number">1</span>	<span class="number">2</span></span><br><span class="line"><span class="number">12</span>	<span class="number">10</span>	MySQL				<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span><span class="operator">/</span><span class="number">10</span>				<span class="number">0</span>	<span class="number">1</span>	<span class="number">2</span></span><br><span class="line"><span class="number">13</span>	<span class="number">10</span>	Oracle			<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span><span class="operator">/</span><span class="number">10</span>				<span class="number">0</span>	<span class="number">0</span>	<span class="number">2</span></span><br><span class="line"><span class="number">15</span>	<span class="number">13</span>	PL<span class="operator">/</span><span class="keyword">SQL</span>			<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span><span class="operator">/</span><span class="number">10</span><span class="operator">/</span><span class="number">13</span>		<span class="number">0</span>	<span class="number">0</span>	<span class="number">3</span></span><br><span class="line"><span class="number">16</span>	<span class="number">15</span>	<span class="keyword">Function</span>		<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span><span class="operator">/</span><span class="number">10</span><span class="operator">/</span><span class="number">13</span><span class="operator">/</span><span class="number">15</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">4</span></span><br><span class="line"><span class="number">17</span>	<span class="number">15</span>	<span class="keyword">Procedure</span>		<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span><span class="operator">/</span><span class="number">10</span><span class="operator">/</span><span class="number">13</span><span class="operator">/</span><span class="number">15</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">4</span></span><br><span class="line"><span class="number">18</span>	<span class="number">15</span>	Package			<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span><span class="operator">/</span><span class="number">10</span><span class="operator">/</span><span class="number">13</span><span class="operator">/</span><span class="number">15</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">4</span></span><br><span class="line"><span class="number">19</span>	<span class="number">15</span>	<span class="keyword">Cursor</span>			<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span><span class="operator">/</span><span class="number">10</span><span class="operator">/</span><span class="number">13</span><span class="operator">/</span><span class="number">15</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">4</span></span><br><span class="line"><span class="number">14</span>	<span class="number">10</span>	<span class="keyword">SQL</span> Server	<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span><span class="operator">/</span><span class="number">10</span>				<span class="number">0</span>	<span class="number">0</span>	<span class="number">2</span></span><br><span class="line"><span class="number">20</span>	<span class="number">14</span>	T<span class="operator">-</span><span class="keyword">SQL</span>				<span class="number">10</span>	<span class="operator">/</span><span class="number">0</span><span class="operator">/</span><span class="number">10</span><span class="operator">/</span><span class="number">14</span>		<span class="number">0</span>	<span class="number">1</span>	<span class="number">3</span></span><br></pre></td></tr></table></figure>





<h2 id="6-SQL-标准-CTE"><a href="#6-SQL-标准-CTE" class="headerlink" title="6. SQL 标准 CTE"></a>6. SQL 标准 CTE</h2><h3 id="6-1-CTE-描述"><a href="#6-1-CTE-描述" class="headerlink" title="6.1 CTE 描述"></a>6.1 CTE 描述</h3><p> **common table expression **或 CTE 是从简单的 SELECT 语句创建的临时命名结果集，可用于后续的 SELECT 语句。 每个 SQL CTE 就像一个命名查询，其结果存储在一个虚拟表 (CTE) 中，以便稍后在主查询中引用。</p>
<h3 id="6-2-CTE实现-connect-by"><a href="#6-2-CTE实现-connect-by" class="headerlink" title="6.2 CTE实现 connect by"></a>6.2 CTE实现 connect by</h3><p>我们之间将如何使用 CTE 来实现 oracle 的层级查询功能，直接看例子。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- connect by</span></span><br><span class="line"><span class="keyword">SELECT</span>  level ,test_id, pid, test_val <span class="keyword">from</span> test_tree  </span><br><span class="line"><span class="keyword">start</span> <span class="keyword">with</span> test_id<span class="operator">=</span><span class="number">10</span> <span class="keyword">CONNECT</span> <span class="keyword">BY</span>  prior test_id<span class="operator">=</span> pid <span class="keyword">order</span> <span class="keyword">by</span> <span class="number">1</span>,<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> LEVEL, empno, ename, mgr, sal</span><br><span class="line"><span class="keyword">FROM</span> emp_</span><br><span class="line"><span class="keyword">CONNECT</span> <span class="keyword">BY</span> PRIOR empno <span class="operator">=</span> mgr</span><br><span class="line"><span class="keyword">START</span> <span class="keyword">WITH</span> ename <span class="operator">=</span> <span class="string">&#x27;BLAKE&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- ctes 实现上述 层次查询</span></span><br><span class="line"><span class="keyword">with</span> <span class="keyword">recursive</span> cte_tab(level, test_id, pid, test_val) &#123;</span><br><span class="line">	<span class="keyword">select</span> <span class="number">1</span> <span class="keyword">AS</span> level,test_id, pid, test_val <span class="keyword">from</span> test_tree <span class="keyword">where</span> test_id<span class="operator">=</span><span class="number">10</span> </span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">	<span class="keyword">select</span>  cte_tab.level<span class="operator">+</span><span class="number">1</span> ,test_treetest_.id, test_tree.pid, test_tree.test_val <span class="keyword">from</span> test_tree, cte_tab </span><br><span class="line">	<span class="keyword">where</span> cte_tab.test_id<span class="operator">=</span> test_val.pid</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> cte_tab;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>







<h2 id="7-connect-by-算法"><a href="#7-connect-by-算法" class="headerlink" title="7. connect by 算法"></a>7. connect by 算法</h2><p>是一个查找算法。看完补充</p>
<h3 id="7-1-基本算法描述"><a href="#7-1-基本算法描述" class="headerlink" title="7.1 基本算法描述"></a>7.1 基本算法描述</h3><p>TODO </p>
<h3 id="7-2-算法伪代码"><a href="#7-2-算法伪代码" class="headerlink" title="7.2 算法伪代码"></a>7.2 算法伪代码</h3><p>后续补充。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title>存储</title>
    <url>/2023/10/08/2-%E6%95%B0%E6%8D%AE%E5%BA%93/5-%E7%AC%94%E8%AE%B0/15445-01/</url>
    <content><![CDATA[<p>数据库、操作系统和编译器是计算机软件的三大系统。其中数据库更接近业务层，几乎所有软件都会用到数据库，所以对数据库的熟练使用时每个开发人员必备的技能，而数据库对外最直接的接口就是 SQL。</p>
<p>今天我们来讲讲数据库SQL。</p>
<span id="more"></span>



<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Relational Databases</span><br><span class="line">Storage</span><br><span class="line">Execution</span><br><span class="line">Concurrency Control</span><br><span class="line">Recovery</span><br><span class="line">Distributed Databases</span><br><span class="line">Potpourri</span><br></pre></td></tr></table></figure>



<p>如何将数据存储在磁盘上 ？</p>
<p>需要暴露那些 API ？</p>
<p>如何表示磁盘上文件中的数据 ？</p>
<p>如果管理内存和磁盘之间的数据移动。（buffer pools）</p>
<p>第一个问题</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">File Storage</span><br><span class="line">Page Layout</span><br><span class="line">Tuple Layout</span><br></pre></td></tr></table></figure>



<p>首先 如何将 数据库组织在 一系列 page 中。</p>
<p>然后 如何将 这些 page 保存在文件中</p>
<p>然后 这些 page 中的 tuple 是什么样的</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Storage Manager 负责维护磁盘上的文件。</span><br><span class="line">这些文件为 page 的 集合。</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">database PAGES</span><br><span class="line"></span><br><span class="line">一个 page 是一个固定大小的数据块</span><br><span class="line">page 可以包含 tuples，meta-data，indexes，<span class="built_in">log</span> records。任何东西。</span><br><span class="line"></span><br><span class="line">有的数据库要求 page 元数据和数据保存在一起，这样即使丢了一个page 也不会影响其他page</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hardware page（4k） 执行原子写入存储设备的最低底层的东西. 对磁盘进行 write和flush操作，</span><br><span class="line">										存储设备只能保证每次写入4kb时是原子的</span><br><span class="line">OS page （4k）</span><br><span class="line">database page （512b - 16 K）</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">page storage architecture</span><br><span class="line">不同数据库管理 page 文件使用不同的方式</span><br><span class="line"></span><br><span class="line">HEAP FILE</span><br><span class="line">Sequential/Sorted FILE</span><br><span class="line">hashing File</span><br></pre></td></tr></table></figure>



<p>HEAP FILE 无序的</p>
<p>链表。page目录</p>
<h4 id="该如何表示page-存储架构"><a href="#该如何表示page-存储架构" class="headerlink" title="该如何表示page 存储架构?"></a>该如何表示page 存储架构?</h4><p>最常⻅的方式是使用Heap File Organization.</p>
<p>数据库中的 heap 文件是一个无序的 page 集合。</p>
<p>用 page 目录来表示page 对应的位置。</p>
<p>page header里面有 page 大小，checksum，数据库版本之类的东西。</p>
<p>当新版本发布时候，可以判断根据不同版本来解析page。</p>
<h4 id="在一个page中，我们可以通过两种不同的方式来表示数据"><a href="#在一个page中，我们可以通过两种不同的方式来表示数据" class="headerlink" title="在一个page中，我们可以通过两种不同的方式来表示数据"></a>在一个page中，我们可以通过两种不同的方式来表示数据</h4><p>面向 tuple 的方式 和 log-structured 的策略</p>
<p>page header 里面有个 slot 数组 ，表明 tuple 数据。</p>
<h3 id="buffer-pool"><a href="#buffer-pool" class="headerlink" title="buffer pool"></a>buffer pool</h3><p>malloc 一块内存，分成固定大小的 chunk，叫做  frame。</p>
<p>page table 用来跟踪内存中有哪些 page。必须是线程安全的</p>
<p>page catalog 记录page 在数据库的文件的什么位置。需要持久化。</p>
<p>page table 记录 buffer pool 中 page 的位置，不需要持久化。</p>
<p>LRU 算法 LRU 的变体clock；</p>
<p>优化 ：</p>
<ol>
<li><p>LRU-K</p>
</li>
<li><p>多个buff er池</p>
</li>
<li><p>priority hints(优先级提示)</p>
</li>
</ol>
<h2 id="hash-table"><a href="#hash-table" class="headerlink" title="hash table"></a>hash table</h2><ul>
<li>hash functions</li>
<li>Static Hashing Schemes</li>
<li>Dynamic Hashing Schemes</li>
</ul>
<p>hash functions</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">CRC-64 (1975)</span><br><span class="line">MurmurHash (2008)</span><br><span class="line">Google CityHash (2011)</span><br><span class="line">FaceBook XXHash (2012)   ---- 最好</span><br><span class="line">Google FarmHash (2014)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

























]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Linearizability versus Serializability</title>
    <url>/2023/10/25/2-%E6%95%B0%E6%8D%AE%E5%BA%93/1-cockroachdb/cockroach-blogs/Linearizability%20versus%20Serializability/</url>
    <content><![CDATA[<h2 id="Linearizability-versus-Serializability"><a href="#Linearizability-versus-Serializability" class="headerlink" title="[Linearizability versus Serializability]"></a>[Linearizability versus Serializability]</h2><p>线性化与串行化</p>
<p>原文链接</p>
<p>(<a href="http://www.bailis.org/blog/linearizability-versus-serializability/">http://www.bailis.org/blog/linearizability-versus-serializability/</a>)</p>
<span id="more"></span>

<p>Linearizability and serializability are both important properties about interleavings of operations in databases and distributed systems, and it’s easy to get them confused. This post gives a short, simple, and hopefully practical overview of the differences between the two.</p>
<p>线性化和串行化都是数据库和分布式系统中操作交错的重要属性，很容易将它们混淆。 这篇文章对两者之间的差异进行了简短、简单且实用的概述。</p>
<h4 id="Linearizability-single-operation-single-object-real-time-order"><a href="#Linearizability-single-operation-single-object-real-time-order" class="headerlink" title="Linearizability: single-operation, single-object, real-time order"></a>Linearizability: single-operation, single-object, real-time order</h4><p><em><a href="http://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf">Linearizability</a> is a guarantee about single operations on single objects.</em> It provides a real-time (i.e., wall-clock) guarantee on the behavior of a set of single operations (often reads and writes) on a single object (e.g., distributed register or data item).</p>
<p>线性化是对单个对象上的单个操作的保证。 它为单个对象（例如分布式寄存器或数据项）上的一组单个操作（通常是读取和写入）的行为提供实时（即挂钟）保证。</p>
<p>In plain English, under linearizability, writes should appear to be instantaneous. Imprecisely, once a write completes, all later reads (where “later” is defined by wall-clock start time) should return the value of that write or the value of a later write. Once a read returns a particular value, all later reads should return that value or the value of a later write.</p>
<p>用简单的英语来说，在线性化下，写入应该看起来是瞬时的。 不精确地说，一旦写入完成，所有后续读取（其中“稍后”由挂钟开始时间定义）都应返回该写入的值或稍后写入的值。 一旦读取返回特定值，所有后续读取都应返回该值或后续写入的值。</p>
<p>Linearizability for read and write operations is synonymous with the term “atomic consistency” and is the “C,” or “consistency,” in Gilbert and Lynch’s <a href="http://lpd.epfl.ch/sgilbert/pubs/BrewersConjecture-SigAct.pdf">proof of the CAP Theorem</a>. We say linearizability is <em>composable</em> (or “local”) because, if operations on each object in a system are linearizable, then all operations in the system are linearizable.</p>
<p>读写操作的线性化与术语“原子一致性”同义，在 Gilbert 和 Lynch 的 CAP 定理证明中是“C”或“一致性”。 我们说线性化是可组合的（或“局部的”），因为如果系统中每个对象的操作都是线性化的，那么系统中的所有操作都是线性化的。</p>
<h4 id="Serializability-multi-operation-multi-object-arbitrary-total-order"><a href="#Serializability-multi-operation-multi-object-arbitrary-total-order" class="headerlink" title="Serializability: multi-operation, multi-object, arbitrary total order"></a>Serializability: multi-operation, multi-object, arbitrary total order</h4><p><em>Serializability is a guarantee about transactions, or groups of one or more operations over one or more objects.</em> It guarantees that the execution of a set of transactions (usually containing read and write operations) over multiple items is equivalent to <em>some</em> serial execution (total ordering) of the transactions.</p>
<p><em>可串行性是对事务或对一个或多个对象的一个或多个操作组的保证。</em>它保证对多个项目执行一组事务（通常包含读取和写入操作）相当于<em>某些</em>串行 事务的执行（总排序）。</p>
<p>Serializability is the traditional “I,” or isolation, in <a href="http://sites.fas.harvard.edu/~cs265/papers/haerder-1983.pdf">ACID</a>. If users’ transactions each preserve application correctness (“C,” or consistency, in ACID), a serializable execution also preserves correctness. Therefore, serializability is a mechanism for guaranteeing database correctness.<a href="http://www.bailis.org/blog/linearizability-versus-serializability/#fn:mechanism">1</a></p>
<p>可串行性是 ACID 中传统的“I”或隔离。 如果每个用户的事务都保持应用程序的正确性（“C”，即 ACID 中的一致性），则可序列化执行也会保持正确性。 因此，可序列化是保证数据库正确性的一种机制。1</p>
<p>Unlike linearizability, serializability does not—by itself—impose any real-time constraints on the ordering of transactions. Serializability is also not composable. Serializability does not imply any kind of deterministic order—it simply requires that <em>some</em> equivalent serial execution exists.</p>
<p>与线性化不同，可串行化本身并不对事务的排序施加任何实时约束。 可串行化也是不可组合的。 可串行性并不意味着任何类型的确定性顺序 - 它只是需要存在某种等效的串行执行。</p>
<h4 id="Strict-Serializability-Why-don’t-we-have-both"><a href="#Strict-Serializability-Why-don’t-we-have-both" class="headerlink" title="Strict Serializability: Why don’t we have both?"></a>Strict Serializability: Why don’t we have both?</h4><p>Combining serializability and linearizability yields <em>strict serializability</em>: transaction behavior is equivalent to some serial execution, and the serial order corresponds to real time. For example, say I begin and commit transaction T1, which writes to item <em>x</em>, and you later begin and commit transaction T2, which reads from <em>x</em>. A database providing strict serializability for these transactions will place T1 before T2 in the serial ordering, and T2 will read T1’s write. A database providing serializability (but not strict serializability) could order T2 before T1.<a href="http://www.bailis.org/blog/linearizability-versus-serializability/#fn:implementation">2</a></p>
<p>将串行化和线性化相结合会产生严格的串行化：事务行为相当于某种串行执行，并且串行顺序对应于实时。 例如，假设我开始并提交事务 T1，它写入项目 x，而您稍后开始并提交事务 T2，它从 x 读取。 为这些事务提供严格可串行性的数据库将在串行排序中将 T1 置于 T2 之前，并且 T2 将读取 T1 的写入。 提供可序列化（但不是严格可序列化）的数据库可以在 T1.2 之前排序 T2</p>
<p>As <a href="http://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf">Herlihy and Wing</a> note, “linearizability can be viewed as a special case of strict serializability where transactions are restricted to consist of a single operation applied to a single object.”</p>
<p>正如 Herlihy 和 Wing 所指出的，“线性化可以被视为严格串行化的一种特殊情况，其中事务仅限于由应用于单个对象的单个操作组成。”</p>
<h4 id="Coordination-costs-and-real-world-deployments"><a href="#Coordination-costs-and-real-world-deployments" class="headerlink" title="Coordination costs and real-world deployments"></a>Coordination costs and real-world deployments</h4><p>Neither linearizability nor serializability is achievable without coordination. That is we can’t provide either guarantee with availability (i.e., CAP “AP”) under an asynchronous network.<a href="http://www.bailis.org/blog/linearizability-versus-serializability/#fn:hardness">3</a></p>
<p>如果没有协调，线性化和串行化都无法实现。 也就是说，我们无法在异步网络下提供可用性保证（即 CAP“AP”）。3</p>
<p>In practice, your database is <a href="http://www.bailis.org/blog/when-is-acid-acid-rarely/">unlikely to provide serializability</a>, and your multi-core processor is <a href="http://preshing.com/20120930/weak-vs-strong-memory-models/">unlikely to provide linearizability</a>—at least by default. As the above theory hints, achieving these properties requires a lot of expensive coordination. So, instead, real systems often use cheaper-to-implement and often <a href="http://www.bailis.org/blog/understanding-weak-isolation-is-a-serious-problem/">harder-to-understand</a> models. This trade-off between efficiency and programmability represents a fascinating and challenging design space.</p>
<p>实际上，您的数据库不太可能提供可串行化，并且您的多核处理器也不太可能提供线性化——至少在默认情况下是这样。 正如上述理论所暗示的，实现这些特性需要大量昂贵的协调。 因此，实际系统通常使用实施成本较低且通常较难理解的模型。 效率和可编程性之间的这种权衡代表了一个令人着迷且具有挑战性的设计空间。</p>
<h4 id="A-note-on-terminology-and-more-reading"><a href="#A-note-on-terminology-and-more-reading" class="headerlink" title="A note on terminology, and more reading"></a>A note on terminology, and more reading</h4><p>One of the reasons these definitions are so confusing is that linearizability hails from the distributed systems and concurrent programming communities, and serializability comes from the database community. Today, almost everyone uses <em>both</em> distributed systems and databases, which often leads to overloaded terminology (e.g., “consistency,” “atomicity”).</p>
<p>这些定义如此令人困惑的原因之一是，线性化来自分布式系统和并发编程社区，而串行化来自数据库社区。 如今，几乎每个人都使用分布式系统和数据库，这常常导致术语过多（例如“一致性”、“原子性”）。</p>
<p>There are many more precise treatments of these concepts. I like <a href="http://link.springer.com/book/10.1007%2F978-3-642-15260-3">this book</a>, but there is plenty of free, concise, and (often) accurate material on the internet, such as <a href="https://www.cs.rochester.edu/~scott/458/notes/04-concurrent_data_structures">these notes</a>.</p>
<p>这些概念还有许多更精确的处理方法。 我喜欢这本书，但是互联网上有大量免费、简洁且（通常）准确的材料，例如这些笔记。</p>
<h4 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h4><ol>
<li><p>But it’s not the only mechanism!</p>
<p>但这不是唯一的机制！</p>
<p>Granted, serializability is (more or less) the most <em>general</em> means of maintaining database correctness. In what’s becoming one of my favorite “underground” (i.e., relatively poorly-cited) references, <a href="http://en.wikipedia.org/wiki/H._T._Kung">H.T. Kung</a> and <a href="http://en.wikipedia.org/wiki/Christos_Papadimitriou">Christos Papadimitriou</a> dropped a paper in SIGMOD 1979 on “<a href="http://www.eecs.harvard.edu/~htk/publication/1979-sigmod-kung-papadimitriou.pdf">An Optimality Theory of Concurrency Control for Databases</a>.” In it, they essentially show that, if all you have are transactions’ syntactic modifications to database state (e.g., read and write) and <em>no</em> information about application logic, serializability is, in some sense, “optimal”: in effect, a schedule that is not serializable might modify the database state in a way that produces inconsistency for some (arbitrary) notion of correctness that is not known to the database.</p>
<p>诚然，可序列化（或多或少）是维护数据库正确性的最通用方法。 在成为我最喜欢的“地下”（即引用相对较少的）参考文献之一中，H.T. Kung 和 Christos Papadimitriou 在 SIGMOD 1979 上发表了一篇关于“数据库并发控制的最优理论”的论文。 在其中，它们本质上表明，如果您拥有的只是事务对数据库状态的语法修改（例如，读取和写入）并且没有有关应用程序逻辑的信息，那么可串行性在某种意义上是“最佳的”：实际上，是一个时间表 不可序列化的可能会修改数据库状态，从而导致数据库未知的某些（任意）正确性概念产生不一致。</p>
<p>However, if <em>do</em> you know more about your user’s notions of correctness (say, you <em>are</em> the user!), you can often do a lot more in terms of concurrency control and can circumvent many of the fundamental overheads imposed by serializability. Recognizing when you don’t need serializability (and subsequently exploiting this fact) is the best way I know to “beat CAP.” <a href="http://www.bailis.org/blog/linearizability-versus-serializability/#fnref:mechanism">↩</a></p>
<p>但是，如果您更多地了解用户的正确性概念（例如，您是用户！），您通常可以在并发控制方面做更多的事情，并且可以规避可串行性带来的许多基本开销。 认识到何时不需要可序列化（并随后利用这一事实）是我所知道的“击败 CAP”的最佳方法。 ↩</p>
</li>
<li><p>Note that some implementations of serializability (such as two-phase locking with long write locks and long read locks) actually provide strict serializability. As <a href="http://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf">Herlihy and Wing</a> point out, other implementations (such as some MVCC implementations) may not.</p>
<p>请注意，某些可串行性的实现（例如具有长写锁和长读锁的两阶段锁定）实际上提供了严格的可串行性。 正如 Herlihy 和 Wing 指出的那样，其他实现（例如某些 MVCC 实现）可能不会。</p>
<p>So, why didn’t the early papers that defined serializability call attention to this real-time ordering? In some sense, real time doesn’t really matter: all serializable schedules are equivalent in terms of their power to preserve database correctness! However, there are some weird edge cases: for example, returning NULL in response to every read-only transaction is serializable (provided we start with an empty database) but rather unhelpful.</p>
<p>那么，为什么早期定义可串行化的论文没有引起人们对这种实时排序的关注呢？ 从某种意义上说，实时并不重要：所有可序列化的调度在保持数据库正确性方面的能力都是相同的！ 然而，有一些奇怪的边缘情况：例如，响应每个只读事务返回 NULL 是可序列化的（假设我们从空数据库开始），但毫无帮助。</p>
<p>One tantalizingly plausible theory for this omission is that, back in the 1970s when serializability theory was being invented, everyone was running on single-site systems anyway, so linearizability essentially “came for free.” However, I believe this theory is unlikely: for example, database pioneer <a href="http://en.wikipedia.org/wiki/Phil_Bernstein">Phil Bernstein</a> was already looking at distributed transaction execution in his SDD-1 system <a href="http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA131789">as early as 1977</a> (and there are <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=4567884">older references</a> yet). Even in this early work, Bernstein (and company) are careful to stress that “there may in fact be <em>several</em> such equivalent serial orderings” [emphasis theirs]. To further put this theory to rest, Papadimitriou makes clear in his seminal <a href="https://www.cs.purdue.edu/homes/bb/cs542-06Spr-bb/SCDU-Papa-79.pdf">1979 JACM</a> article that he’s familiar with problems inherent in a distributed setting. (If you ever want to be blown away by the literature, look at how much of the foundational work on concurrency control was done by the early 1980s.) <a href="http://www.bailis.org/blog/linearizability-versus-serializability/#fnref:implementation">↩</a></p>
<p>对于这一遗漏，一个看似合理的理论是，早在 20 世纪 70 年代，当串行化理论被发明时，每个人都在单站点系统上运行，因此线性化本质上是“免费的”。 然而，我认为这个理论不太可能：例如，数据库先驱 Phil Bernstein 早在 1977 年就已经在他的 SDD-1 系统中研究分布式事务执行（并且还有更早的参考资料）。 即使在这项早期工作中，伯恩斯坦（和公司）也小心地强调“实际上可能有几个这样的等效序列顺序”[强调他们的]。 为了进一步证实这一理论，Papadimitriou 在其 1979 年 JACM 的开创性文章中明确表示，他熟悉分布式环境中固有的问题。 （如果您想被文献所震撼，请看看 20 世纪 80 年代初完成了多少并发控制的基础工作。） ↩</p>
</li>
<li><p>For distributed systems nerds: achieving linearizability for reads and writes is, in a formal sense, “easier” to achieve than serializability. This is probably deserving of another post (encouragement appreciated!), but here’s some intuition: terminating atomic register read&#x2F;write operations <a href="http://www.cse.huji.ac.il/course/2004/dist/p124-attiya.pdf">are achievable</a> in a fail-stop model. Yet atomic commitment—which is needed to execute multi-site serializable transactions (think: AC is to 2PC as consensus is to Paxos)—is not: the <a href="http://www.cs.utexas.edu/~lorenzo/corsi/cs380d/past/03F/notes/fischer.pdf">FLP result</a> says consensus is unachievable in a fail-stop model (hence <em>with One Faulty Process</em>), and (non-blocking) atomic commitment is <a href="http://link.springer.com/chapter/10.1007/BFb0022140">“harder” than consensus</a> (<a href="http://infoscience.epfl.ch/record/83471/files/1596162953p115-delporte.pdf">see also</a>). Also, keep in mind that linearizability for read-modify-write <a href="http://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf">is harder than</a> linearizable read&#x2F;write. (linearizable read&#x2F;write《 consensus《 atomic commitment) <a href="http://www.bailis.org/blog/linearizability-versus-serializability/#fnref:hardness">↩</a></p>
<p>对于分布式系统迷来说：从形式上来说，实现读写的线性化比串行化“更容易”实现。 这可能值得另一篇文章（感谢鼓励！），但这里有一些直觉：终止原子寄存器读&#x2F;写操作在故障停止模型中是可以实现的。 然而，原子承诺——执行多站点可序列化事务所需的原子承诺（想想：AC 之于 2PC，共识之于 Paxos）——却并非如此：FLP 结果表明，在故障停止模型中无法达成共识（因此出现了一个错误进程） ），并且（非阻塞）原子承诺比共识“更难”（另请参阅）。 另外，请记住，读-修改-写的线性化比线性化读&#x2F;写更难。 (线性化读&#x2F;写《共识》《原子承诺) ↩</p>
</li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title>Volcano</title>
    <url>/2023/08/15/2-%E6%95%B0%E6%8D%AE%E5%BA%93/4-%E8%AE%BA%E6%96%87/volcano/</url>
    <content><![CDATA[<h2 id="Volcano"><a href="#Volcano" class="headerlink" title="Volcano"></a>Volcano</h2><p>An Extensible and Parallel Query Evaluation System </p>
<p>Volcano-一个可扩展的并行查询评估系统</p>
<p>Abstract-To investigate the interactions  parallelism in database query processing, we have developed a new dataflow query execution system called Volcano. The Volcano effort provides a rich environment for research and education in database systems design, heuristics for query optimization, parallel query execution, and resource allocation.</p>
<p>摘要：为了研究数据库查询处理中可扩展性和并行性的相互作用，我们开发了一种新的数据流查询执行系统，称为 Volcano。 Volcano 的工作为数据库系统设计、查询优化启发式、并行查询执行和资源分配方面的研究和教育提供了丰富的环境。</p>
<span id="more"></span>

<p>Volcano uses a standard interface between algebra operators, allowing easy addition of new operators and operator implementations. Operations on individual items, e.g., predicates, are imported into the query processing operators using support functions. The semantics of support functions is not prescribed; any data type including complex objects and any operation can be realized. Thus, Volcano is extensible with new operators, algorithms, data types, and type-specific methods.</p>
<p>Volcano 在代数运算符之间使用标准接口，允许轻松添加新运算符和运算符实现。 使用支持函数将对单个项目（例如谓词）的操作导入到查询处理运算符中。 支持函数的语义没有规定； 可以实现包括复杂对象在内的任何数据类型和任何操作。 因此，Volcano 可以通过新的运算符、算法、数据类型和特定于类型的方法进行扩展。</p>
<p>Volcano includes two novel meta-operators. The choose-plan meta-operator supports dynamic query evaluation plans that al- low delaying selected optimization decisions until run-time, e.g., for embedded queries with free variables. The exchange meta-operator supports intra-operator parallelism on parti- tioned datasets and both vertical and horizontal inter-operator parallelism, translating between demand-driven dataflow within processes and data-driven dataflow between processes.</p>
<p>Volcano 包括两个新颖的元运算符。 选择计划元运算符支持动态查询评估计划，允许将选定的优化决策延迟到运行时，例如，对于具有自由变量的嵌入式查询。 交换元操作符支持分区数据集上的操作符内并行性以及垂直和水平操作符间并行性，在进程内的需求驱动数据流和进程之间的数据驱动数据流之间进行转换。</p>
<p>All operators, with the exception of the exchange operator, have been designed and implemented in a single-process envi- ronment, and parallelized using the exchange operator. Even operators not yet designed can be parallelized using this new operator if they use and provide the interator interface. Thus, the issues of data manipulation and parallelism have become orthogonal, making Volcano the first implemented query exe- cution engine that effectively combines extensibility and parallelism.</p>
<p>除交换运算符外，所有运算符都是在单进程环境中设计和实现的，并使用交换运算符进行并行化。 即使尚未设计的运算符如果使用并提供交互器接口，也可以使用这个新运算符进行并行化。 因此，数据操作和并行性问题变得正交，使 Volcano 成为第一个实现的、有效结合可扩展性和并行性的查询执行引擎。</p>
<p>index Terms-Dynamic query evaluation plans, extensible database systems, iterators, operator model of parallelization, query execution.</p>
<p>索引术语-动态查询评估计划、可扩展数据库系统、迭代器、并行化操作模型、查询执行。</p>
<h3 id="I-INTRODUCTION"><a href="#I-INTRODUCTION" class="headerlink" title="I. INTRODUCTION"></a>I. INTRODUCTION</h3><p>IN ORDER to investigate the interactions of extensibil- ity, efficiency, and parallelism in database query pro- cessing and to provide a testbed for databse systems research and education, we have designed and implemented a new query evaluation system called Volcano. It is intended to provide an experimental vehicle for research into query execution techniques and query optimization optimization heuristics rather than a database system ready to support applications. it is not a complete database systern as it lacks features such as a user-friendly query language, a type system for instances (record definitions), a query optimizer, and catalogs. Because of this focus, Volcano is able to serve as an experimental vehicle for a multitude of purposes, all .of them openended, which results in a combination of requirements that have not been integrated in a single system before. </p>
<p>为了研究数据库查询处理中可扩展性、效率和并行性的相互作用，并为数据库系统研究和教育提供测试平台，我们设计并实现了一个名为 Volcano 的新查询评估系统。 它旨在提供一个用于研究查询执行技术和查询优化启发式的实验工具，而不是一个准备支持应用程序的数据库系统。它不是一个完整的数据库系统，因为它缺乏用户友好的查询语言、实例类型系统（记录定义）、查询优化器和目录等功能。 由于这一重点，Volcano 能够作为多种目的的实验工具，所有这些目的都是开放式的，从而产生了以前从未集成到单个系统中的需求组合。</p>
<p>First, it is modular and extensible to enable future research, e.g., on algorithms, data models, resource allocation, parallel execution, load balancing, and query optimization heuristics. Thus, Vol- cano provides an infrastructure for experimental research rather than a final research prototype in itself. </p>
<p>首先，它是模块化和可扩展的，可以支持未来的研究，例如算法、数据模型、资源分配、并行执行、负载平衡和查询优化启发法。 因此，Volcano 为实验研究提供了基础设施，而不是其本身的最终研究原型。</p>
<p>Second, it is simple in its design to allow student use and research. Modularity and simplicity are very important for this pur- pose because they allow students to begin working on projects without an understanding of the entire design and all its details, and they permit several concurrent student projects. </p>
<p>其次，它的设计简单，方便学生使用和研究。 模块化和简单性对于此目的非常重要，因为它们允许学生在不了解整个设计及其所有细节的情况下开始项目工作，并且允许多个并发的学生项目。</p>
<p>Third, Volcano’s design does not presume any particular data model; the only assumption is that query processing is based on transforming sets of items using parameterized operators. To achieve data model indepen- dence, the design very consistently separates set process- ing control (which is provided and inherent in the Vol- cano operators) from interpretation and manipulation of data items (which is imported into the operators, as de- scribed later). </p>
<p>第三，Volcano的设计没有假设任何特定的数据模型； 唯一的假设是查询处理基于使用参数化运算符转换项目集。 为了实现数据模型的独立性，设计非常一致地将集合处理控制（由 Volcano 运算符提供和固有的）与数据项的解释和操作（如所述导入到运算符中）分开。 之后）。</p>
<p>Fourth, to free algorithm design, imple- mentation, debugging, tuning, and initial experimentation from the intricacies of parallelism but to allow experi- mentation with parallel query processing. Volcano can be used as a single-process or as a parallel system. Single- process query evaluation plans can already be parallelized easily on shared-memory machines and soon also on dis- tributed-memory machines. </p>
<p>第四，将算法设计、实现、调试、调整和初始实验从复杂的并行性中解放出来，但允许进行并行查询处理的实验。 Volcano 可以用作单进程或并行系统。 单进程查询评估计划已经可以在共享内存机器上轻松并行化，并且很快也可以在分布式内存机器上并行化。</p>
<p>Fifth, Volcano is realistic in its query execution paradigm to ensure that students learn how query processing is really done in commercial data- base products. For example, using temporary files to transfer data from one operation to the next as suggested in most textbooks has a substantial performance penalty, and is therefore used in neither real database systems nor in Volcano. </p>
<p>第五，Volcano 的查询执行范例是现实的，以确保学生了解商业数据库产品中的查询处理是如何真正完成的。 例如，按照大多数教科书的建议，使用临时文件将数据从一个操作传输到下一个操作会带来很大的性能损失，因此既不在真正的数据库系统中使用，也不在 Volcano 中使用。</p>
<p>Finally, Volcano’s means for parallel query processing could not be based on existing models since all models explored to date have been designed with a particular data model and operator set in mind. Instead, our design goal was to make parallelism and data manip- ulation orthogonal, which means that the mechanisms for parallel query processing are independent of the operator set and semantics, and that all operators, including new ones, could be designed and implemented independently of future parallel execution.</p>
<p>最后，Volcano 的并行查询处理方法不能基于现有模型，因为迄今为止探索的所有模型都是在设计时考虑了特定的数据模型和运算符集。 相反，我们的设计目标是使并行性和数据操作正交，这意味着并行查询处理的机制独立于操作符集和语义，并且所有操作符，包括新操作符，都可以独立于操作符集和语义来设计和实现。 未来的并行执行。</p>
<p>Following a design principle well established in operating systems research but not exploited in most database system designs, Volcano provides mechanisms to support policies. Policies can be set by a human experimenter or by a query optimizer. The separation of mechanisms and policies has contributed to the extensibility and modular- ity of modern operating systems, and may make the same contribution to extensible database systems. We will re- turn to this separation repeatedly in this paper.</p>
<p>Volcano 遵循操作系统研究中确立但大多数数据库系统设计中未采用的设计原则，提供了支持策略的机制。 策略可以由人类实验者或查询优化器设置。 机制和策略的分离有助于现代操作系统的可扩展性和模块化，并且可能对可扩展数据库系统做出同样的贡献。 我们将在本文中反复讨论这种分离。</p>
<p>Since its very purpose is to allow future extensions and research, Volcano is continuously being modified and ex- tended. Among the most important recent extensions were the design and implementation of two meta-operators. Both of them are not only new operators but also embody and encapsulate new concepts for query processing. They are meta-operators since they do not contribute to data manipulation, selection, derivation, etc., but instead pro- vide additional control over query processing that cannot be provided by conventional operators like file scan, sort, and merge join. The choose-plan operator implements dynamic query evaluation plans, a concept developed for queries that must be optimized with incomplete informa- tion [ 171. For example, it is not possible to reliably op- timize an embedded query if one of the constants in the query predicate is actually a program variable and there- fore unknown during compilation and optimization. Dy- namic plans allow preparation for multiple equivalent plans, each one optimal for a certain range of actual pa- rameter values. The choose-plan operator selects among these plans at runtime while all other operators in Vol- cano’s operator set (present or future) are entirely oblivious to the presence and function of the choose-plan operator.</p>
<p>由于其目的是为了未来的扩展和研究，Volcano 正在不断地被修改和扩展。 最近最重要的扩展是两个元运算符的设计和实现。 它们不仅是新的运算符，而且体现和封装了查询处理的新概念。 它们是元运算符，因为它们不参与数据操作、选择、派生等，而是提供对查询处理的额外控制，这是文件扫描、排序和合并连接等传统运算符无法提供的。 选择计划运算符实现动态查询评估计划，这是一个为必须使用不完整信息进行优化的查询而开发的概念[171。例如，如果常量之一，则不可能可靠地优化嵌入式查询 查询谓词中的实际上是一个程序变量，因此在编译和优化期间是未知的。 动态计划允许准备多个等效计划，每个计划对于特定范围的实际参数值都是最佳的。 选择计划运算符在运行时在这些计划中进行选择，而 Volcano 运算符集中的所有其他运算符（当前或未来）完全不知道选择计划运算符的存在和功能。</p>
<p>The second meta-operator, the exchange operator, im- plements and controls parallel query evaluation in Vol- cano. While operators can exchange data without the ex- change operator, in fact within processes as easily as a single procedure call, this new operator exchanges data across process and processor boundaries. All other oper- ators are implemented and execute without regard to par- allelism; all parallelism issues like partitioning and flow control are encapsulated in and provided by the exchange operator. Thus, data manipulation and parallelism are in- deed orthogonal in Volcano [20]. Beyond the cleanliness from a software engineering point of view, it is also very encouraging to see that this method of parallelizing a query processing engine does indeed allow linear or near- linear speedup .</p>
<p>第二个元运算符，即交换运算符，在 Volcano 中实现和控制并行查询评估。 虽然操作符可以在没有交换操作符的情况下交换数据，实际上在进程内就像单个过程调用一样容易，但这个新操作符可以跨进程和处理器边界交换数据。 所有其他运算符的实现和执行均不考虑并行性； 所有并行问题（例如分区和流量控制）都封装在交换运算符中并由交换运算符提供。 因此，数据操作和并行性在 Volcano 中确实是正交的[20]。 除了从软件工程角度来看的简洁性之外，看到这种并行化查询处理引擎的方法确实允许线性或近线性加速也非常令人鼓舞。</p>
<p>This paper is a general overview describing the overaii goals and design principles. Other articles on Volcano were written on special aspects of the system, e.g., [16]- [21], [25], [26]. These articles also include experimental performance evaluations of Volcano’s techniques and algorithms, in particular [ 181, [2 11. </p>
<p>本文是描述总体目标和设计原则的总体概述。 关于 Volcano 的其他文章是关于系统的特殊方面的，例如 [16]-[21]、[25]、[26]。 这些文章还包括 Volcano 技术和算法的实验性能评估，特别是 [181, [2 11.</p>
<p>The present paper is organized as follows. In the following section, we briefly review previous work that inluenced Volcano’s design. A detailed description of Vol- cano follows in Section III. Section IV contains a discussion of extensibility in the system. Dynamic query evaluation plans and their implementation are described in Section V. Parallel processing encapsulated in the ex- change module is described in Section VI. Section VII contains a summary and our conclusions from this effort.</p>
<p>本文的结构如下。 在下一节中，我们简要回顾一下影响 Volcano 设计的先前工作。 第三节对 Volcano 进行了详细描述。 第四节讨论了系统的可扩展性。 动态查询评估计划及其实现在第五节中描述。封装在交换模块中的并行处理在第六节中描述。 第七节包含总结和我们从这项工作中得出的结论。</p>
<h3 id="II-RELATED-WORK"><a href="#II-RELATED-WORK" class="headerlink" title="II. RELATED WORK"></a>II. RELATED WORK</h3><p>Since so many different systems have been developed to process large datesets efficiently, we only survey the systems that have significantly influenced the design of Volcano. Our work has been influenced most strongly by WiSS, GAMMA, and EXODUS. The Wisconsin Storage System (WiSS) [lo] is a record-oriented file system pro- viding heap files, B-tree and hash indexes, buffering, and scans with predicates. GAMMA [1l] is a software data- base machine running on a number of general-purpose CPU’s as a backend to a UNIX host machine. It was de- veloped on 17 VAX 11&#x2F;750’s connected with each other and the VAX 11&#x2F;750 host via a 80 Mb &#x2F;s token ring. Eight GAMMA processors had a local disk device, accessed us- ing WiSS. The disks were accessible only locally, and update and selection operators used only these eight pro- cessors. The other, diskless processors were used for join processing. Recently, the GAMMA software has been ported to an Intel iPSC&#x2F;2 hypercube with 32 nodes, each with a local disk drive. GAMMA uses hash-based algo- rithms extensively, implemented in such a way that each operator is executed on several (usually all) processors and the input stream for each operator is partitioned into disjoint sets according to a hash function.</p>
<p>由于已经开发了许多不同的系统来有效地处理大型数据集，因此我们只调查对 Volcano 设计有重大影响的系统。 我们的工作受 WiSS、GAMMA 和 EXODUS 的影响最为强烈。 威斯康星存储系统 (WiSS) [lo] 是一个面向记录的文件系统，提供堆文件、B 树和哈希索引、缓冲和谓词扫描。 GAMMA [1l] 是一个软件数据库机，运行在许多通用 CPU 上，作为 UNIX 主机的后端。 它是在 17 个 VAX 11&#x2F;750 上开发的，这些 VAX 11&#x2F;750 彼此之间以及 VAX 11&#x2F;750 主机通过 80 Mb &#x2F;s 令牌环连接。 八个 GAMMA 处理器有一个本地磁盘设备，可以使用 WiSS 进行访问。 磁盘只能在本地访问，更新和选择操作员仅使用这八个处理器。 其他无盘处理器用于连接处理。 最近，GAMMA 软件已被移植到具有 32 个节点的 Intel iPSC&#x2F;2 hypercube，每个节点都有一个本地磁盘驱动器。 GAMMA 广泛使用基于散列的算法，其实现方式是每个运算符在多个（通常是所有）处理器上执行，并且每个运算符的输入流根据散列函数划分为不相交的集合。</p>
<p>The limited data model and extensibility of GAMMA led to the search for a more flexible but equally powerful query processing model. The operator design used in the GAMMA database machine software gives each operator control within its own process, leaving it to the network- ing and operating system software to synchronize multi- ple operators in producer-consumer relationships using flow-control mechanisms. This design, while working ex- tremely well in GAMMA, does not lend itself to single- process query evaluation since multiple loci of control, i.e., multiple operators, cannot be realized inside a single process without special pseudo-multiprocess mechanisms such as threads. Therefore, GAMMA’s operator and data transfer concepts are not suitable for an efficient query processing engine intended for both sequential and par- allel query execution.</p>
<p>GAMMA 有限的数据模型和可扩展性导致人们寻找更灵活但同样强大的查询处理模型。 GAMMA数据库机器软件中使用的操作员设计使每个操作员能够在自己的流程中进行控制，将其留给网络和操作系统软件使用流量控制机制来同步生产者-消费者关系中的多个操作员。 这种设计虽然在 GAMMA 中工作得非常好，但不适合单进程查询评估，因为如果没有特殊的伪多进程机制（例如线程），就无法在单个进程内实现多个控制点（即多个运算符）。 因此，GAMMA 的运算符和数据传输概念不适合用于顺序和并行查询执行的高效查询处理引擎。</p>
<p>EXODUS [7] is an extensible database system with some  components followiong the “tool-kit” approach, e.g., the optimizer generator [ 131, [ 141 and the E database implementation language [27], [28], and other compo- nents built as powerful but fixed components, e.g., the storage manager [5]. Originally, EXODUS was conceived to be data-model-indepedent, i.e., it was supposed to support a wide variety of data models, but later a novel,powerful,structurally object-oriented data model called Extra was developed. The concept of data model independence as first explored in EXODUS has been retained in the Volcano project and the design and implementation of its software.During the design of the EXODUS storage manager, many storage and access issues explored in WiSS and GAMMA were revisited. Lessons learned and trade-offs explored in these discussions certainly helped in forming the ideas behind Volcano. The  design and development of E influenced the strong emphasis on iterators for query processing.</p>
<p>EXODUS [7]是一个可扩展的数据库系统，具有一些遵循“工具包”方法的组件，例如优化器生成器[131，[141]和E数据库实现语言[27]，[28]和其他组件 构建为功能强大但固定的组件，例如存储管理器 [5]。 最初，EXODUS 被认为是独立于数据模型的，即它应该支持多种数据模型，但后来开发了一种新颖的、强大的、结构面向对象的数据模型，称为 Extra。 EXODUS 中首次探索的数据模型独立性概念已保留在 Volcano 项目及其软件的设计和实现中。在 EXODUS 存储管理器的设计过程中，重新审视了 WiSS 和 GAMMA 中探索的许多存储和访问问题。 在这些讨论中吸取的经验教训和探索的权衡无疑有助于形成 Volcano 背后的想法。 E 的设计和开发影响了对用于查询处理的迭代器的强烈重视。</p>
<p>A number of further conventional (relational) and extensible systems have influenced our design. Ingres [32] and System R [9] have probably influenced most database systems, in particular their extensible follow-on projects  Starburst [23] and Postgres [35]. It is interesting to note  that independently of our work the Starburst group has also identified the demand-driven interator paradigm as a suitable basis for an extensible single-process query evaluation architecture after using it successfully in the System R relational system, but as yet has not been able to combine extensibility with parallelism. GENESIS [l] early on stressed the importance of uniform operator in- terfaces for extensibility and software reusability.</p>
<p>许多进一步的传统（关系）和可扩展系统影响了我们的设计。 Ingres [32] 和 System R [9] 可能影响了大多数数据库系统，特别是它们的可扩展后续项目 Starburst [23] 和 Postgres [35]。 有趣的是，独立于我们的工作，Starburst 小组在 System R 关系系统中成功使用需求驱动的交互器范例后，也将其确定为可扩展的单进程查询评估架构的合适基础，但迄今为止 无法将可扩展性与并行性结合起来。 GENESIS [l]很早就强调了统一操作员界面对于可扩展性和软件可重用性的重要性。</p>
<p>XPRS has been the first project aiming to combine extensibility with parallelism [34]. Its basic premise is to implement Postgres on top of RAID disk arrays and the Sprite operating system. XPRS and GAMMA basically differ in four ways. First, GAMMA supports. a purely relational data model while XPRS supports an extensible relational model, Postgres. Second, GAMMA’s main form of parallelism is intra-operator parallelism based on partitioned data sets. XPRS, on the other hand, will rely on bushy parallelism, i.e. , concurrent execution of different subtrees in a complex query evaluation plan. Fourth, GAMMA is built on the premise that distributed memory is required to achieve scalable linear speed-up while XPRS is being im- plemented on a shared-memory machine.</p>
<p>XPRS 是第一个旨在将可扩展性与并行性相结合的项目 [34]。 其基本前提是在 RAID 磁盘阵列和 Sprite 操作系统之上实现 Postgres。 XPRS 和 GAMMA 基本上有四个方面的不同。 首先，GAMMA支持。 纯粹的关系数据模型，而 XPRS 支持可扩展的关系模型 Postgres。 其次，GAMMA 的主要并行形式是基于分区数据集的算子内并行。 另一方面，XPRS 将依赖于密集并行性，即复杂查询评估计划中不同子树的并发执行。第四，GAMMA 的构建前提是需要分布式内存来实现可扩展的线性加速，而 XPRS 是在共享内存机器上实现的。</p>
<p>Both XPRS and Volcano combine parallelism and ex- tensibility, but XPRS is a far more comprehensive project than Volcano. In particular, XPRS includes a data model and a query optimizer. On the other hand, Volcano is more extensible precisely because it does not presume a data model. Therefore, Volcano could be used as the query processing engine in a parallel extensible-relational sys- tem such as XPRS. Moreover, it will eventually include a data-model-independent optimizer generator to form a complete query processing research environment.</p>
<p>XPRS 和 Volcano 都结合了并行性和可扩展性，但 XPRS 是一个比 Volcano 更全面的项目。 具体来说，XPRS 包括数据模型和查询优化器。 另一方面，Volcano 更具有可扩展性，正是因为它不假定数据模型。 因此，Volcano 可以用作并行可扩展关系系统（例如 XPRS）中的查询处理引擎。 而且，它最终将包括一个独立于数据模型的优化器生成器，以形成一个完整的查询处理研究环境。</p>
<h3 id="III-VOLCANO-SYSTEM-DESIGN"><a href="#III-VOLCANO-SYSTEM-DESIGN" class="headerlink" title="III. VOLCANO SYSTEM DESIGN"></a>III. VOLCANO SYSTEM DESIGN</h3><p>In this section, we provide an overview of the design of Volcano. At the current time, Volcano is a library of about two dozen modules with a total of about 15 000 lines of C code. These modules include a file system, buffer management, sorting, B+-trees, and two algorithms each (sort- and hash-based) for natural join, semi-join, all three outer joins, anti-joint, aggregation, duplicate elimination, union, intersection, difference, anti-difference,and relational division. Moreover, two modules implement dynamic query evaluation plans and allow parallel processing of all algorithms listed above.</p>
<p>在本节中，我们概述了 Volcano 的设计。 目前，Volcano 是一个包含大约两打模块的库，总共大约有 15,000 行 C 代码。 这些模块包括文件系统、缓冲区管理、排序、B+树以及两种算法（基于排序和散列），用于自然连接、半连接、所有三个外连接、反连接、聚合、重复消除、 并集、交集、差集、反差集、关系除法。 此外，两个模块实现动态查询评估计划并允许并行处理上面列出的所有算法。</p>
<p>All operations on individual records are deliberately  left open for later definition. Instead of inventing a language in which to specify selection predicates, hash functions,etc., functions are passed to the query processing operators to be called when necessary with the appropriate arguments.These support functions are descibed later in more detail One common and repeating theme in the design of Volcano is that it provides mechanisms for query evaluation to allow selection of and experimentation with policies. The separation of mechanisms and policies is  a very well-known and well-established principle in the design and implementation of operating systems, but it has not been used as extensively and consistently in the design and implementation of database systems. It has contributed significantly to the extensibility and modularity of modem operating systems, and may make the same contribution to extensible database systems.</p>
<p>对单个记录的所有操作都故意保留以供以后定义。 不是发明一种语言来指定选择谓词、散列函数等，而是将函数传递给查询处理运算符，以便在必要时使用适当的参数进行调用。稍后将更详细地描述这些支持函数。 一个常见且重复的主题 Volcano 设计的一个亮点是它提供了查询评估机制，以允许选择和试验策略。 机制和策略的分离是操作系统设计和实现中众所周知且公认的原则，但它在数据库系统的设计和实现中尚未得到广泛和一致的使用。 它对现代操作系统的可扩展性和模块化做出了重大贡献，并且可能对可扩展数据库系统做出同样的贡献。</p>
<p>Currently, Volcano consists of two layers, the file system layer and the query processing layer. The former provides record, file, and index operations including scans with optional predicates, and buffering; the latter is a set of query processing modules that can be nested to build complex query evaluation trees. Fig. 1 identifies Volcano’s main modules. This separation can be found in most query evaluation systems, e.g., RSS and RDS in System R [9] and Core and Corona in Starburst [23]. System catalogs or a data dictionary are not included in Volano since the system was designed to be extensible and independent from any particular data model. We start our descirption at the bottom, the file system, and then discuss the query processing modules.</p>
<p>目前，Volcano由两层组成，文件系统层和查询处理层。 前者提供记录、文件和索引操作，包括带有可选谓词的扫描和缓冲； 后者是一组查询处理模块，可以嵌套构建复杂的查询评估树。 图 1 标识了 Volcano 的主要模块。 这种分离可以在大多数查询评估系统中找到，例如 System R [9] 中的 RSS 和 RDS 以及 Starburst [23] 中的 Core 和 Corona。 Volano 中不包含系统目录或数据字典，因为该系统被设计为可扩展且独立于任何特定数据模型。 我们从最底层的文件系统开始描述，然后讨论查询处理模块。</p>
<p><img src="/img/volcano-pic/image-20230720151302454.png"></p>
<h4 id="A-The-File-System"><a href="#A-The-File-System" class="headerlink" title="A. The File System"></a>A. The File System</h4><p>Within our discussion of the Volcano file system, we also proceed bottom-up, from buffer management to data files and indices. The existing facilities are meant to pro- vide a backbone of a query processing system, and are designed such that modifications and additions can easily be accomplished as the need arises. The buffer manager is the most interesting part of the file system. Because buffer management is performance- critical in any database system, the Volcano buffer man- ager was designed to include mechanisms that can be used most effectively and efficiently in a large variety of con- texts and with a wide array of policies. In consequence, its features include multiple buffer pools, variable-length units of buffering that are called clustres in Volcano, and replacement hints from the next higher software level.</p>
<p>在我们对 Volcano 文件系统的讨论中，我们也是自下而上进行的，从缓冲区管理到数据文件和索引。 现有设施旨在提供查询处理系统的骨干，其设计使得可以在需要时轻松完成修改和添加。缓冲区管理器是文件系统中最有趣的部分。 由于缓冲区管理在任何数据库系统中都对性能至关重要，因此 Volcano 缓冲区管理器被设计为包含可在各种上下文和各种策略中最有效和高效地使用的机制。 因此，它的功能包括多个缓冲池、可变长度缓冲单元（在 Volcano 中称为簇）以及来自下一个更高软件级别的替换提示。</p>
<p>The buffer manager’s hint facility is an excellent example of Volcano’s design principle to implement mechanisms to suppent multiple policies. The buffer manager only provides the mechanisms, i.e.,pinning, page replacement, and reading and writing disk pages, while the higher level software determines the policies depending on data semantics, importance, and access patterns. It is surprising that database buffer managers derive replace- ment decisions from observed reference behavior in spite of the fact that this behavior is generated by higher level database software and thus known and foreseeable in ad- vance within the same system, albeit different subcom- ponents.</p>
<p>缓冲区管理器的提示功能是 Volcano 设计原则的一个很好的例子，它实现了支持多种策略的机制。 缓冲区管理器仅提供机制，即固定、页面替换以及读写磁盘页面，而更高级别的软件根据数据语义、重要性和访问模式确定策略。 令人惊讶的是，数据库缓冲区管理器从观察到的参考行为中得出替换决策，尽管这种行为是由更高级别的数据库软件生成的，因此在同一系统内（尽管子组件不同）是已知的和可预见的。 </p>
<p>Files are composed of records, clusters, and extents. Since file operations are invoked very frequently in any database system, all design decisions in the file module have been made to provide basic functionality with the highest attainable performance. A cluster, consisting of one or more pages, is the unit of I&#x2F;O and of buffering, as discussed above. The cluster size is set for each file in- dividually. Thus, different files on the same device can have different cluster sizes. Disk space for files is allo- cated in physically contiguous extents, because extents allow very fast scanning without seeks and large-chunk read-ahead and write-behind.</p>
<p>文件由记录、簇和范围组成。 由于文件操作在任何数据库系统中都会非常频繁地调用，因此文件模块中的所有设计决策都是为了提供具有最高可达到性能的基本功能。 如上所述，簇由一页或多页组成，是 I&#x2F;O 和缓冲的单位。 簇大小是为每个文件单独设置的。 因此，同一设备上的不同文件可以具有不同的簇大小。 文件的磁盘空间被分配在物理上连续的扩展区中，因为扩展区允许非常快速的扫描而无需查找以及大块的预读和后写。</p>
<p>Records are identified by a record identifier (RID), and can be accessed directly using the RID. For fast access to a large set of records, Volcano supports not only individ- ual file and record operations but also scans that support read-next and append operations. There are two interfaces to file scans; one is part of the file system and is described momentarily; the other is part of the query processing level and is described later. The first one has the standard procedures for file scans, namely open, next, close, and rewind. The next procedure returns the main memory ad- dress of the next record. This address is guaranteed (pinned) until the next operation is invoked on the scan.Thus, getting the next record within the same cluster does not require calling the buffer manager and can be per- formed very efficiently.</p>
<p>记录由记录标识符(RID) 标识，并且可以使用RID 直接访问。 为了快速访问大量记录，Volcano 不仅支持单个文件和记录操作，还支持支持读取下一个和追加操作的扫描。 文件扫描有两个接口； 一个是文件系统的一部分，稍后进行描述； 另一个是查询处理级别的一部分，稍后介绍。 第一个具有文件扫描的标准过程，即 open、next、close和 rewind。 next 过程返回下一条记录的主存地址。 在扫描中调用下一个操作之前，该地址得到保证（固定）。因此，获取同一簇内的下一条记录不需要调用缓冲区管理器，并且可以非常高效地执行。</p>
<p>For fast creation of files, scans support an append op- eration. It allocates a new record slot, and returns the new slot’s main memory address. It is the caller’s responsibil- ity to fill the provided record space with useful information, i.e., the append rourine is entirely oblivious to the data and their representation.</p>
<p>为了快速创建文件，扫描支持追加操作。 它分配一个新的记录槽，并返回新槽的主内存地址。 调用者有责任用有用的信息填充提供的记录空间，即附加例程完全不关心数据及其表示。</p>
<p>Scans also support optional predicates. The predicate function is called by the next procedure with the argument and a record address. Selective scans are the first example of support functions mentioned briefly in the introduction. Instead of determining a qualification itself, the scan mechanism relies on a predicate function imported from a higher level.</p>
<p>扫描还支持可选谓词。 谓词函数由下一个过程使用参数和记录地址调用。 选择性扫描是简介中简要提到的支持功能的第一个示例。 扫描机制不是确定限定本身，而是依赖于从更高级别导入的谓词函数。</p>
<p>Support functions are passed to an operation as a function entry point and a typeless pointer that serves as a predicate argument. Arguments to support functions can be used in two ways, namely in compiled and interpreted query execution. In compiled scans, i.e., when the pred- icate evaluation function is available in macvhine code, the argument can be used to pass a constant or a pointer to several constants to the predicate function. For exam- ple, if the predicate consists of comparing a record field with a string, the comparison function is passed as pred- icate function while the search string is passed as predi- cate argument. In interpreted scans, i.e., when a general interpreter is used to evaluate all predicates in query, they can be used to pass appropriate code to the interpreter. The interpreter’s entry point is given as predicate func- tion. Thus, both interpreted and compiled scans are sup- ported with a single simple and efficient mechanism. Vol- cano’s use of support functions and their arguments is another example for a mechanism that leaves a policy de- cision, in this case whether to use compiled or interpreted scans, open to be decided by higher level software.</p>
<p>支持函数作为函数入口点和充当谓词参数的无类型指针传递给操作。 支持函数的参数可以通过两种方式使用，即在编译和解释查询执行中。 在编译扫描中，即当谓词求值函数在 macvhine 代码中可用时，参数可用于将常量或指向多个常量的指针传递给谓词函数。 例如，如果谓词包括将记录字段与字符串进行比较，则比较函数作为谓词函数传递，而搜索字符串作为谓词参数传递。 在解释扫描中，即当使用通用解释器来评估查询中的所有谓词时，它们可用于将适当的代码传递给解释器。 解释器的入口点作为谓词函数给出。 因此，解释扫描和编译扫描都由一个简单而有效的机制支持。 Volcano 对支持函数及其参数的使用是一种机制的另一个例子，该机制将策略决策（在本例中是使用编译扫描还是解释扫描）由更高级别的软件决定。</p>
<p>indices are implemented currently only in the form of B + -trees with an interface similar to files. A leaf entry consists of a key and information. The information part typically is a RID, but it could include more or different information. The key and the information can be of any type; a comparison function must be provided to compare keys. The comparison function uses an argument equiv- alent to the one described for scan predicates. Permitting any information in the leaves gives more choices in phys- ical database design. It is another example of Volcano providing a mechanism to allow a multitude of designs and usage policies. B + -trees support scans similar to files, including predicates and append operations for fast loading In addition, B+ -tree scans allow seeking to a partic- ular key, and setting lower and upper bounds.</p>
<p>索引目前仅以 B+ 树的形式实现，其接口类似于文件。 叶条目由密钥和信息组成。 信息部分通常是 RID，但它可以包括更多或不同的信息。 密钥和信息可以是任何类型； 必须提供比较函数来比较键。 比较函数使用的参数与扫描谓词所描述的参数等效。 允许叶子中存在任何信息可以为物理数据库设计提供更多选择。 这是 Volcano 提供允许多种设计和使用策略的机制的另一个例子。 B+ 树支持与文件类似的扫描，包括用于快速加载的谓词和附加操作。此外，B+ 树扫描允许查找特定键，并设置下限和上限。</p>
<p>For intermediate results in query processing (later called streams), Volcano uses special devices called virtual de- vices. The difference between virtual and disk devices is that data pages of virtual devices only exist in the buffer. As soon as such data pages are unpinned, they disappear and their contents are lost. Thus, Volcano uses the same mechanisms and function calls for permanent and inter- mediate data sets, easing implementation of new opera- tors significantly.</p>
<p>对于查询处理中的中间结果（后来称为流），Volcano 使用称为虚拟设备的特殊设备。 虚拟设备和磁盘设备的区别在于虚拟设备的数据页只存在于缓冲区中。 一旦此类数据页被取消固定，它们就会消失并且其内容也会丢失。 因此，Volcano 对永久和中间数据集使用相同的机制和函数调用，从而显着简化了新运算符的实现。</p>
<p>In summary, much of Volcano’s file system is conven- tional in its goals but implemented in a flexible, efficient, and compact way. The file system supports basic abstractions and operations, namely devices, files, records,B+-trees, and scans. It provides mechanisms to access these objects, leaving many policy decisions to higher level software. High performance was a very important goal in the design and implementation of these mecha- nisms since performance studies and parallelization only make sense if the underlying mechanisms are efficient. Furthermore, research into implementation and perfor- mance trade-offs for extensible database systems and new data models is only relevant if an efficient evaluation platform is used.</p>
<p>总之，Volcano 的文件系统的大部分目标都是传统的，但以灵活、高效和紧凑的方式实现。 文件系统支持基本的抽象和操作，即设备、文件、记录、B+树和扫描。 它提供了访问这些对象的机制，将许多策略决策留给更高级别的软件。 高性能是这些机制的设计和实现中的一个非常重要的目标，因为只有当底层机制高效时，性能研究和并行化才有意义。 此外，只有使用有效的评估平台，对可扩展数据库系统和新数据模型的实施和性能权衡的研究才有意义。</p>
<h4 id="B-Query-Processing"><a href="#B-Query-Processing" class="headerlink" title="B. Query Processing"></a>B. Query Processing</h4><p>The file system routines described above are utilized by the query processing routines to evaluate complex quer- ies. Queries are expressed as query plans or algebra expressions; the operators of this algebra are query pro- cessing algorithms and we call the algebra an executable algebra as opposed to logical algebras, ‘e .g . , relational algebra. We will describe the operations using relational terminology hoping that this will assist the reader.We must point out, however, that the operations can be viewed and are implemented as operations on sets of objects, and that Volcano does not depend on assumptions about the internal structure of such objects. In fact, we intend to use Volcano for query processing in an object- oriented database system [ 151. The key to this use of Vol- cano is that set processing and interpretation of data items are separated.</p>
<p>查询处理例程利用上述文件系统例程来评估复杂的查询。 查询被表示为查询计划或代数表达式； 该代数的运算符是查询处理算法，我们将该代数称为可执行代数，而不是逻辑代数，“例如” ，关系代数。 我们将使用关系术语来描述这些操作，希望这会对读者有所帮助。但是，我们必须指出，这些操作可以被视为并实现为对对象集的操作，并且 Volcano 不依赖于有关内部对象的假设。 此类对象的结构。 事实上，我们打算在面向对象的数据库系统中使用 Volcano 进行查询处理[151。使用 Volcano 的关键在于数据项的集合处理和解释是分离的。</p>
<p>In Volcano, all algebra operators are implemented as iterators, i.e., they support a simple open-next-close pro- tocol. Basically, iterators provide the iteration component of a loop, i.e., initialization, increment, loop termination condition, and final housekeeping. These functions allow “iteration’ ’ over the results of any operation similar to the iteration over the result of a conventional file scan.Associated with each iterator is a state record type. A state record contains arguments, e.g., the size of a hash table to be allocated in the open procedure, and state, e.g., the location of a hash table. All state information of an iterator is kept in its state record and there are no ‘ ‘static’ ’ variables; thus, an algorithm may be used multiple times in a query by including more than one state record in the query.</p>
<p>在 Volcano 中，所有代数运算符都被实现为迭代器，即它们支持简单的 open-next-close 协议。 基本上，迭代器提供循环的迭代组件，即初始化、增量、循环终止条件和最终内务处理。 这些函数允许对任何操作的结果进行“迭代”，类似于对传统文件扫描的结果进行迭代。与每个迭代器相关联的是一个状态记录类型。 状态记录包含参数（例如要在打开过程中分配的哈希表的大小）和状态（例如哈希表的位置）。 迭代器的所有状态信息都保存在其状态记录中，并且不存在“静态”变量； 因此，通过在查询中包括多于一个状态记录，可以在查询中多次使用算法。</p>
<p>All manipulation and interpretation of data objects,e.g., comparisons and hashing, is passed to the iterators by means of pointers to the entry points of appropriate support functions. Each of these support functions uses an argument allowing interpreted or compiled query eval- uation, as described earlier for file scan predicates. With- out the support functions, Volcano’s iterators are empty algorithm shells that cannot perform any useful work. In effect, the split into algorithm shells and support functions separates control and iteration over sets from interpreta- tion of records or objects. This separation is one of the cornerstones’ of Volcano’s data model independent and extensibility, which will be discussed in Section IV.</p>
<p>数据对象的所有操作和解释，例如比较和散列，都通过指向适当支持函数入口点的指针传递给迭代器。 这些支持函数中的每一个都使用一个允许解释或编译查询评估的参数，如前面针对文件扫描谓词所述。 如果没有支持函数，Volcano 的迭代器就是空的算法外壳，无法执行任何有用的工作。 实际上，分成算法外壳和支持函数将集合的控制和迭代与记录或对象的解释分开。 这种分离是 Volcano 数据模型独立性和可扩展性的基石之一，这将在第四节中讨论。</p>
<p>Iterators can be nested and then operate similarly to coroutines. State records are linked together by means of input pointers. The input pointers are also kept in the state records. Fig. 2 shows two operators in a query evaluation plan. Purpose and capabilities of the Jilter operator will be discussed shortly; one of its possible functions is to print items of a stream using a function passed to the filter operator as one of its arguments. The structure at the top gives access to the functions as well as to the state record. Using a pointer to this structure, the filter functions can be called and their local state can be passed to them as a procedure argument. The functions themselves, e.g., open–filter, can use the input pointer contained in the state record to invoke the input operator’s functions. Thus, the filter functions can invoke the file scan functions as needed, and can pace the file scan according to the needs of the filter. In other words, Fig. 2 shows a complete query evaluation plan that prints selected records from a file.</p>
<p>迭代器可以嵌套，然后与协程类似地进行操作。 状态记录通过输入指针链接在一起。 输入指针也保存在状态记录中。 图 2 显示了查询评估计划中的两个运算符。 Jilter 操作员的目的和功能将很快讨论； 它的可能功能之一是使用传递给过滤器运算符作为其参数之一的函数来打印流的项目。 顶部的结构可以访问函数以及状态记录。 使用指向该结构的指针，可以调用过滤器函数，并且可以将它们的本地状态作为过程参数传递给它们。 函数本身（例如 open–filter）可以使用状态记录中包含的输入指针来调用输入运算符的函数。 因此，过滤器函数可以根据需要调用文件扫描函数，并且可以根据过滤器的需要调整文件扫描的速度。 换句话说，图 2 显示了一个完整的查询评估计划，该计划打印从文件中选择的记录。</p>
<p><img src="/img/volcano-pic/image-20230720152944923.png"></p>
<p>Using Volcano’s standard form of iterators, an operator does not need to know what kind of operator produces its input, or whether its input comes from a complex query tree or from a simple file scan. We call this concept anon- ymous inputs or streams. Streams are a simple but pow- erful abstraction that allows combining any number and any kind of operators to evaluate a complex query, a sec- ond cornerstone to Volcano’s extensibility. Together with the iterator control paradigm, streams represent the most efficient execution model in terms of time (overhead for synchronizing operators) and space (number of records that must reside in memory concurrently) for single-pro- cess query evaluation.</p>
<p>使用 Volcano 的标准形式的迭代器，操作符不需要知道哪种操作符产生其输入，或者其输入是来自复杂的查询树还是来自简单的文件扫描。 我们将这个概念称为匿名输入或流。 流是一种简单但功能强大的抽象，它允许组合任意数量和任意类型的运算符来评估复杂的查询，这是 Volcano 可扩展性的第二个基石。 与迭代器控制范例一起，流代表了单进程查询评估的时间（同步运算符的开销）和空间（必须同时驻留在内存中的记录数量）方面最有效的执行模型。</p>
<p>Calling open for the top-most operator results in instan- tiations for the associated state record’s state, e.g., allo- cation of a hash table, and in open calls for all inputs. In this way, all iterators in a query are initiated recursively. In order to process the query, next for the top-most op- erator is called repeatedly until it fails with an end-of- stream indicator. The top-most operator calls the next procedure of its input if it needs more input data to pro- duce an output record. Finally, the close call recursively “shuts down” all iterators in the query. This model of query execution matches very closely the ones being in- eluded in the E database implementation language in EX- ODUS and the query executor of the Starburst relational database system.</p>
<p>对最顶层运算符调用 open 会导致关联状态记录的状态实例化，例如哈希表的分配，以及对所有输入的 open 调用。 这样，查询中的所有迭代器都会递归启动。 为了处理查询，重复调用最顶层运算符的 next ，直到它失败并出现流结束指示符。 如果需要更多输入数据来生成输出记录，最顶层的运算符将调用其输入的下一个过程。 最后，关闭调用递归地“关闭”查询中的所有迭代器。 这种查询执行模型与 EXODUS 中的 E 数据库实现语言和 Starburst 关系数据库系统的查询执行器中包含的模型非常匹配。</p>
<p>A number of query and environment parameters may nfluence policy decisions during opening a query evaluation plan, e.g., query predicate constants and system load information. Such parameters are passed between all open procedures in Volcano with a parameter called bindings. This is a typeless pointer that can be used to pass infor- mation for policy decisions. Such policy decisions are im- plemented using support functions again. For example, the module implementing hash join allows dynamic de- termination of the size of a hash table-another example of the separation of mechanism and policy. This bindings parameter is particularly useful in dynamic query evalu- ation plans, which will be discussed later in Section V.</p>
<p>许多查询和环境参数可能会影响打开查询评估计划期间的策略决策，例如查询谓词常量和系统负载信息。 此类参数通过称为绑定的参数在 Volcano 中的所有打开过程之间传递。 这是一个无类型指针，可用于传递策略决策信息。 此类政策决策再次使用支持功能来实施。 例如，实现散列连接的模块允许动态确定散列表的大小——机制和策略分离的另一个例子。 这个绑定参数在动态查询评估计划中特别有用，稍后将在第五节中讨论。</p>
<p>The tree-structured query evaluation plan is used to ex- ecute queries by demand-driven dataflow. The return value of a next operation is, besides a status indicator, a structure called Next-Record, which consists of an RID and a record address in the buffer pool. This record is pinned in the buffer. The protocol about fixing and unfixng records is as follows. Each record pinned in the buffer is owned by exactly one operator at any point in time.After receiving a record, the operator can hold on to it for a while, e.g., in a hash table, unfix it, e.g., when a pred- icate fails, or pass it on to the next operator. Complex operations that create new records, e.g., join, have to fix their output records in the buffer before passing them on, and have to unfix their input records. Since this could re- sult in a large number of buffer calls (one per record in each operator in the query), the interface to the buffer manager was recently redesigned such that it will require a total of two buffer calls per cluster on the procedure side (e. g., a file scan) independently of how many records a cluster contains, and only one buffer call per cluster on the consumer side.</p>
<p>树结构的查询评估计划用于通过需求驱动的数据流执行查询。 下一个操作的返回值除了状态指示符之外，还有一个名为Next-Record的结构，它由RID和缓冲池中的记录地址组成。 该记录被固定在缓冲区中。 关于修复和取消修复记录的协议如下。 固定在缓冲区中的每条记录在任何时间点都由一个操作员拥有。收到一条记录后，操作员可以将其保留一段时间（例如，在哈希表中），然后取消固定它，例如，当预测时 icate 失败，或者将其传递给下一个操作员。 创建新记录的复杂操作（例如连接）必须在传递它们之前修复缓冲区中的输出记录，并且必须取消修复它们的输入记录。 由于这可能会导致大量的缓冲区调用（查询中每个运算符中的每个记录一个），因此最近重新设计了缓冲区管理器的接口，使得过程中的每个集群总共需要两次缓冲区调用 端（例如文件扫描）独立于集群包含多少条记录，并且在消费者端每个集群只有一个缓冲区调用。</p>
<p>A Next-Record structure can point to one record only. All currently implemented query processing algorithms pass complete records between operators, e.g., join creates new, complete records by copying fields from two input records. It can be argued that creating complete new records and passing them between operators is prohibitively expensive. An alternative is to leave original records in the buffer as they were retrieved from the stored data, and compose Next-Record pairs, triples, etc., as intermediate results. Although this alternative results in less memory-to-memory copying, it is not implemented explicitly because Volcano already provides the necessary mechanisms, namely the Biter iterator (see next subsec- tion) that can replace each record in a stream by an RID- pointer pair or vice versa.</p>
<p>下一条记录结构只能指向一条记录。 当前实现的所有查询处理算法都在运算符之间传递完整的记录，例如，连接通过复制两个输入记录中的字段来创建新的完整记录。 可以说，创建完整的新记录并在运营商之间传递它们的成本过高。 另一种方法是将原始记录保留在缓冲区中，因为它们是从存储的数据中检索的，并组合下一个记录对、三元组等作为中间结果。 虽然这种替代方案会减少内存到内存的复制，但它并没有明确实现，因为 Volcano 已经提供了必要的机制，即 Biter 迭代器（参见下一小节），它可以用 RID 指针替换流中的每个记录 配对或反之亦然。</p>
<p> In summary, demand-driven dataflow is implemented by encoding operators as iterators, i.e., with open, next, and close procedures, since this scheme promises gener- ality , extensibility, efficiency, and low overhead. The next few sections describe some of Volcano’s existing iterators in more detail. In very few modules, the described operators provide much of the functionality of other query evaluation systems through generality and separation of mechanisms and policies. Furthermore, the separation of set processing control (iteration) from item interpretation and manipulation provides this functionality independently from any data model.</p>
<p>总之，需求驱动的数据流是通过将运算符编码为迭代器来实现的，即使用 open、next 和 close 过程，因为该方案具有通用性、可扩展性、高效性和低开销。 接下来的几节将更详细地描述 Volcano 的一些现有迭代器。 在极少数模块中，所描述的运算符通过机制和策略的通用性和分离性提供了其他查询评估系统的许多功能。 此外，集合处理控制（迭代）与项目解释和操作的分离提供了独立于任何数据模型的功能。</p>
<ol>
<li><p>Scans, Functional Join, and Filter: The first scan interface was discussed with the file system. The second interface to scans, both file scans and B+-tree scans, pro- vides an iterator interface suitable for query processing. The open procedures open the file or B+-tree and initiate a scan using the scan procedures of the file system level. The file name or closed file descriptor are given in the state record as are an optional predicate and bounds for B+-tree scans. Thus, the two scan interfaces are function- ally equivalent. Their difference is that the file system scan interface is used by various internal modules, e.g., by the device module for the device table of contents, while the iterator interface is used to provide leaf operators for query evaluation plans.</p>
<p>扫描、功能连接和过滤：第一个扫描接口是与文件系统一起讨论的。 第二个扫描接口（文件扫描和 B+ 树扫描）提供了适合查询处理的迭代器接口。 打开过程打开文件或 B+ 树并使用文件系统级别的扫描过程启动扫描。 文件名或关闭文件描述符在状态记录中给出，作为 B+ 树扫描的可选谓词和边界。 因此，两个扫描接口在功能上是等效的。 它们的区别在于，文件系统扫描接口由各种内部模块使用，例如，由用于设备内容表的设备模块使用，而迭代器接口用于为查询评估计划提供叶运算符。</p>
<p>Typically, Bf-tree indices hold keys and RID’s in their leaves. In order to use B+-tree indices, the records in the data file must be retrieved. In Volcano, this look-up op- eration is split from the B+-tree scan iterator and is performed by the functional join operator. This operator re- quires a stream of records containing RID’s as input and either outputs the records retrieved using the RID’s or it composes new records from the input records and the re- trieved records, thus “joining” the B+-tree entries and their corresponding data records.</p>
<p>通常，B+ 树索引在其叶子中保存键和 RID。 为了使用 B+ 树索引，必须检索数据文件中的记录。 在 Volcano 中，此查找操作从 B+ 树扫描迭代器中分离出来，并由函数连接运算符执行。 该运算符需要包含 RID 的记录流作为输入，并且输出使用 RID 检索到的记录，或者从输入记录和检索到的记录组成新记录，从而“连接”B+ 树条目及其对应的记录。 数据记录。</p>
<p>B+-tree scan and functional join are separated for a number of reasons. First, it is not clear that storing data in B+-tree leaves never is a good idea. At times, it may be desirable to experiment with having other types of in- formation associated with look-up keys. Second, this sep- aration allows experimentation with manipulation of RID- lists for complex queries. Third, while functional join is currently implemented rather naively, this operation can be made more intelligent to assemble complex objects recursively. In summary, separating index search and record retrieval is another example for porviding mechanisms in Volcano to allow for experiments with policies, a design principle employed to ensure that the Volcano software would be flexible and extensible.</p>
<p>由于多种原因，B+ 树扫描和功能连接是分开的。 首先，目前尚不清楚将数据存储在 B+ 树叶子中永远不是一个好主意。 有时，可能需要尝试使用与查找键相关联的其他类型的信息。 其次，这种分离允许对复杂查询的 RID 列表进行实验操作。 第三，虽然函数式连接目前的实现相当简单，但可以使该操作更加智能，以递归地组装复杂对象。 总之，分离索引搜索和记录检索是 Volcano 中提供允许进行策略实验的机制的另一个例子，这是用于确保 Volcano 软件灵活且可扩展的设计原则.</p>
<p>The filter opeartor used in the example above performs three functions, depeding on presence or absence of corresponding support functions in the state record. The predicate function apples a selection predicate.e.g., to implement bit vector filtering. The transform function creates a new record,typically of a new type, from each old record.An example would be a relational projection (without duplicate elimination). More complex examples include compression and decompression, other changes in codes and representations, and reducing a stream of rec- ords to RID-pointer pairs. Finally, the apply function is invoked once on each record for the venefit of its side effects. Typical examples are updates and printing. Notice that updates are done within streams and query evaluation plans. Thus, Volcano plans are not only retrieval but also update plans. The filter operator is also called the ‘ ‘side-effect operator. ’ ’ Another example is creating a fil- ter for bit vector filtering. In other words, the filter op- erator is a very versatile single-input single-output oper- ator that can be used for a variety of purposes. Bit vector filtering is an example for a special version of separationof policy and mechanism, namely the rule not to provide an operation that can be composed easily and efficiently using existing operations.</p>
<p>上面示例中使用的过滤器运算符执行三个功能，具体取决于状态记录中是否存在相应的支持功能。 谓词函数应用选择谓词，例如，实现位向量过滤。 变换函数从每个旧记录创建一个新记录，通常是新类型。一个例子是关系投影（没有重复消除）。 更复杂的示例包括压缩和解压缩、代码和表示的其他更改以及将记录流减少为 RID 指针对。 最后，apply 函数在每条记录上调用一次，以消除其副作用。 典型的例子是更新和打印。 请注意，更新是在流和查询评估计划内完成的。 因此，Volcano计划不仅是检索计划，而且是更新计划。 过滤运算符也称为“副作用运算符”。 ” 另一个例子是创建一个用于位向量过滤的过滤器。 换句话说，过滤器运算符是一种非常通用的单输入单输出运算符，可用于多种目的。 位向量过滤是策略和机制分离的特殊版本的示例，即不提供可以使用现有操作轻松且高效地组合的操作的规则。</p>
</li>
<li><p>One-to-One Match: Together with the filter opera- tor, the one-to-one match operator will probably be among the most frequently used query processing operators in Volcano as it implements a variety of set-matching func- tions. In a single operator, it realizes join, semi-join, outer joint, anti-joint, intersection, union, difference, anti-dif- ference, aggregation, and duplicate elimination. The one- to-one match operator is a physical operator like sort, i.e., part of the executable algebra, not a logical operator like the operators of relational algebra. It is the operator that implements all operations in which an item is included in the output depending on the result of a comparison be- tween a pair of items.</p>
<p>一对一匹配：与过滤运算符一起，一对一匹配运算符可能是 Volcano 中最常用的查询处理运算符之一，因为它实现了各种集合匹配功能。 在单个算子中，它实现了连接、半连接、外连接、反连接、交集、并集、差分、反差分、聚合和重复消除。 一对一匹配运算符是像排序这样的物理运算符，即可执行代数的一部分，而不是像关系代数运算符那样的逻辑运算符。 该运算符实现所有操作，其中根据一对项目之间的比较结果将项目包含在输出中。</p>
<p>Fig. 3 shows the basic principle underlying the one-to- one match operator for binary operations, namely sepa- ration of the matching and non-matching components of two sets, called R and S in the Fig. 3, and producing ap- propriate subsets, possibly after some transformation and combination as in the case of a join. Since all these operations require basically the same steps, it was logical to mplement them in one general and efficient module. The main difference between the unary and binary operations, e.g., aggregate functions and equi-join, is that the former require comparing items of the same input while the latter require comparing items of two different inputs.</p>
<p>图 3 显示了二元运算的一对一匹配运算符的基本原理，即分离两个集合的匹配和不匹配分量（在图 3 中称为 R 和 S），并生成 ap- 适当的子集，可能是在一些转换和组合之后，如连接的情况。 由于所有这些操作都需要基本相同的步骤，因此在一个通用且高效的模块中实现它们是合乎逻辑的。 一元和二元运算（例如聚合函数和等连接）之间的主要区别在于，前者需要比较相同输入的项目，而后者需要比较两个不同输入的项目。</p>
<p><img src="/img/volcano-pic/image-20230720155442652.png"></p>
<p>Since the implementation of Volcano’s one-to-one match is data-model-independent and all operations on data items are imported via support functions, the module s not restricted to the relational model but can perform set matching functions for arbitrary data types. Furthermore, the hash-based version provides recursive hash table overflow avoidance [121and resolution similar to hybrid hash join [31] and can therefore handle very large nput sizes. The sort-based version of one-to-one match is based on an external sort operator and can also operate on arbitrarily large inputs.</p>
<p>由于Volcano的一对一匹配的实现是与数据模型无关的，并且对数据项的所有操作都是通过支持函数导入的，因此该模块不限于关系模型，而是可以对任意数据类型执行集合匹配函数。 此外，基于散列的版本提供了递归散列表溢出避免[121]和类似于混合散列连接[31]的解决方案，因此可以处理非常大的输入大小。 一对一匹配的基于排序的版本基于外部排序运算符，并且还可以对任意大的输入进行操作。</p>
<p>While there seems to be an abundance <strong>of</strong> join algo- rithms, our design goals of extensibility and limited sys- tem size led to the choice of only two algorithms (at the current time) to be implemented in Volcano, namely merge join and hybrid hash join. This choice will also allow experimental research into the duality and trade-offs between sort- and hash-based query processing algo- rithms.</p>
<p>虽然连接算法似乎很丰富，但我们的可扩展性和有限系统规模的设计目标导致我们只选择了两种算法（目前）在 Volcano 中实现，即合并连接和混合哈希 加入。 这种选择还允许对基于排序和基于散列的查询处理算法之间的二元性和权衡进行实验研究。</p>
<p>The classic hashjoin algorithm (which is the in-mem- ory component of hybrid hash join) proceeds in two phases. In the first phase, a hash table is built from one input; it is therefore called the build phase. In the second phase, the hash table is probed using tuples from the other input to determine matches and to compose output tuples; it is called the probe phase. After the probe phase, the hash table and its entries are discarded. Instead, our one- to-one match operator uses a third phase called thejush phase, which is needed for aggregate functions and some other operations.</p>
<p>经典的哈希连接算法（混合哈希连接的内存组件）分两个阶段进行。 在第一阶段，根据一个输入构建哈希表； 因此，它被称为构建阶段。 在第二阶段，使用来自其他输入的元组来探测哈希表以确定匹配并组成输出元组； 它被称为探测阶段。 探测阶段结束后，哈希表及其条目将被丢弃。 相反，我们的一对一匹配运算符使用称为 thejush 阶段的第三阶段，这是聚合函数和其他一些操作所需要的。</p>
<p>Since the one-to-one match operator is an interator like all Volcano operators, the three phases are assigned to the <strong>open, next,</strong> and <strong>close</strong> functions. <strong>Open</strong> includes the build phase, while the other two phases are included in the <strong>next</strong> function. Successive invocations of the <strong>next</strong> function au- tomatically switch from the probe phase to the flush phase when the second input is exhausted.</p>
<p>由于一对一匹配运算符像所有 Volcano 运算符一样是一个迭代器，因此三个阶段被分配给 open、next 和 close 函数。 Open 包含构建阶段，而其他两个阶段包含在 next 函数中。 当第二个输入耗尽时，连续调用下一个函数会自动从探测阶段切换到刷新阶段。</p>
<p>The build phase can be used to eliminate duplicates or to perform an aggregate function in the build input. The one-to-one match module does not require a probe input; if only an aggregation is required without subsequent join, the absence of the probe input in the state record signals to the module that the probe phase should be skipped. For aggregation, instead of inserting a new tuple into the hash table as in the classic hash join, an input tuple is first matched with the tuples in its prospective hash bucket. If a match is found, the new tuple is discarded or its values are aggregated into the existing tuple.</p>
<p>构建阶段可用于消除重复项或在构建输入中执行聚合函数。 一对一匹配模块不需要探针输入； 如果仅需要聚合而无需后续连接，则状态记录中缺少探测输入会向模块发出应跳过探测阶段的信号。 对于聚合，不是像经典哈希连接那样将新元组插入到哈希表中，而是首先将输入元组与其预期哈希桶中的元组进行匹配。 如果找到匹配项，则丢弃新元组或将其值聚合到现有元组中。</p>
<p>While hash tables in main memory are usually quite fast, a severe problem occurs if the build input does not fit in main memory. This situation is called <strong>hash table overjlow.</strong> There are two ways to deal with hash table over- flow. First, if a query optimizer is used and can anticipate overflow, it can be avoided by partitioning the input(s). This <strong>overjlow avoidance</strong> technique is the basis for the hash join algorithm used in the Grace database machine [121. Second, overflow files can be created using <strong>overfrow res- olution</strong> after the problem occurs.</p>
<p>虽然主内存中的哈希表通常非常快，但如果构建输入不适合主内存，则会出现严重问题。 这种情况称为哈希表溢出。 有两种方法可以处理哈希表溢出。 首先，如果使用查询优化器并且可以预见溢出，则可以通过对输入进行分区来避免溢出。 这种过度避免技术是 Grace 数据库机中使用的哈希连接算法的基础 [121。 其次，可以在问题发生后使用溢出解决方案创建溢出文件。</p>
<p>For Volcano’s one-to-one match, we have adopted hy- brid hash join. Compared to the hybrid hash algorithm used in GAMMA, our overflow resolution scheme has several improvements. Items can be inserted into the hash table without copying, i.e., the hash table points directly to records in the buffer as produced by one-to-one match’s build input. If input items are not densely packed, how- ever, the available buffer memory can fill up very quickly. Therefore, the one-to-one match operator has an argu- ment called the packing threshold. When the number of items in the hash table reaches this threshold, items are packed densely into overflow files. However, the clusters (pages) of these overflow files are not yet unfixed in the buffer, i.e., no t &#x2F; O is performed as yet. Only when the number of items in the hash table reaches a second thresh- old called spilling threshold is the first of the partition files unfixed. The clusters of this file are written to disk and the count of items in the hash table accordingly re- duced. When this number reaches the spilling threshold again, the next partition is unfixed, etc. If necessary, par- titioning is performed recursively, with automatically ad- justed packing and spilling thresholds. The unused por- tions of the hash table, i.e., the portions corresponding to spilled buckets, are used for bit vector filtering to save I&#x2F;O to overflow files.</p>
<p>对于 Volcano 的一对一匹配，我们采用了混合哈希连接。 与 GAMMA 中使用的混合哈希算法相比，我们的溢出解决方案有一些改进。 可以将项目插入到哈希表中而无需复制，即哈希表直接指向由一对一匹配的构建输入生成的缓冲区中的记录。 然而，如果输入项不是密集排列的，则可用缓冲存储器很快就会被填满。 因此，一对一匹配运算符有一个称为打包阈值的参数。 当哈希表中的项目数量达到此阈值时，项目将被密集地打包到溢出文件中。 然而，这些溢出文件的簇(页)在缓冲区中尚未被固定，即尚未执行t&#x2F;O。 仅当哈希表中的项目数达到称为溢出阈值的第二个阈值时，第一个分区文件才会被取消修复。 该文件的簇被写入磁盘，哈希表中的项目数相应减少。 当这个数字再次达到溢出阈值时，下一个分区将不固定，等等。如果有必要，分区会递归执行，并自动调整打包和溢出阈值。 哈希表的未使用部分，即与溢出桶相对应的部分，用于位向量过滤，以节省溢出文件的 I&#x2F;O。</p>
<p>The fan-out of the first partitioning step is determined by the total available memory minus the memory required to reach the packing threshold. By choosing the packing and spilling thresholds, a query optimizer can avoid re- cord copying entirely for small build inputs, specify overflow avoidance (and the maximum fan-out) for very large build inputs, or determine packing and spilling thresholds based on the expected build input size. In fact, because the input sizes cannot be estimated precisely if the inputs are produced by moderately complex expres- sions, the optimizer can adjust packing and spilling thresholds based on the esimated probability distributions of input sizes. For example, if overflow is very unlikely, it might be best to set the packing threshold quite high such that, with high probability, the operation can pro- ceed without copying. On the other hand, if overflow is more likely, the packing threshold should be set lower to obtain a larger partitioning fan-out.</p>
<p>第一个分区步骤的扇出由总可用内存减去达到打包阈值所需的内存确定。 通过选择打包和溢出阈值，查询优化器可以完全避免小型构建输入的记录复制，为非常大的构建输入指定溢出避免（和最大扇出），或者根据预期确定打包和溢出阈值 构建输入大小。 事实上，由于如果输入是由中等复杂的表达式生成的，则无法精确估计输入大小，因此优化器可以根据输入大小的估计概率分布来调整打包和溢出阈值。 例如，如果溢出的可能性很小，则最好将打包阈值设置得相当高，以便很有可能操作可以继续进行而无需复制。 另一方面，如果溢出的可能性更大，则应将打包阈值设置得较低以获得更大的分区扇出。</p>
<p>The initial packing and spilling thresholds can be set to zero; in that case, Volcano’s one-to-one match performs overflow avoidance very similar to the join algorithm used in the Grace database machine. Beyond this parameter- ization of overflow avoidance and resolution, Volcano’s one-to-one match algorithm also permits optimizations of cluster size and recursion depth similar to the ones used for sorting [4], <strong>[21]</strong> and for nonuniform hash value dis- tributions, and it can operate on inputs with variable- length records.</p>
<p>初始打包和溢出阈值可以设置为零； 在这种情况下，Volcano 的一对一匹配执行溢出避免，与 Grace 数据库机器中使用的连接算法非常相似。 除了溢出避免和解析的参数化之外，Volcano 的一对一匹配算法还允许优化簇大小和递归深度，类似于用于排序 [4]、[21] 和非均匀哈希值分布的优化 ，并且它可以对具有可变长度记录的输入进行操作。</p>
<p>The extension of the module described so far to set op- erations started with the observation that the intersection of two union-compatible relations is the same as the nat- ural join of these relations, and can be best implemented as semi-join. The union is the (double-sided) outer join of union-compatible relations. Difference and anti-differ- ence of two sets can be computed using special settings of the algorithm’s bells and whistles. Finally, a Cartesian product can be implemented by matching successfully all possible pairs of items from the two inputs.</p>
<p>到目前为止描述的模块对设置操作的扩展始于观察到两个并集兼容关系的交集与这些关系的自然连接相同，并且可以最好地实现为半连接。 联合是联合兼容关系的（双面）外部联接。 可以使用算法花哨的特殊设置来计算两个集合的差异和反差异。 最后，可以通过成功匹配两个输入中所有可能的项目对来实现笛卡尔积。</p>
<p><strong>A</strong> second version of one-to-one match is based on sort- ing. Its two modules are a disk-based merge-sort and the actual merge-join. Merge-join has been generalized sim- ilarly to hash-join to support semi-join, outer join, anti-join, and set operations. The sort operator has been im- plemented in such a way that it uses and provides the it- erator interface. Opening the <strong>sort</strong> iterator prepares sorted runs for merging. If the number of runs is larger than the maximal fan-in, runs are merged into larger runs until the remaining runs can be merged in a single step. The final merge is performed on demand by the <strong>next</strong> function. If the entire input fits into the sort buffer, it is kept there until demanded by the <strong>next</strong> function. The sort operator also supports aggregation and duplicate elimination. It can perform these operations early, i.e., while writing tem- porary files [2]. The sort algorithm is described and eval- uated in detail in <strong>[2****11.</strong></p>
<p>一对一匹配的第二个版本基于排序。 它的两个模块是基于磁盘的合并排序和实际的合并连接。 合并连接已被推广为类似于散列连接，以支持半连接、外连接、反连接和集合操作。 排序运算符的实现方式是使用并提供迭代器接口。 打开排序迭代器为合并排序运行做好准备。 如果运行数量大于最大扇入，运行将合并为更大的运行，直到可以在单个步骤中合并剩余运行。 最终合并由下一个函数按需执行。 如果整个输入适合排序缓冲区，则它将保留在那里，直到下一个函数需要为止。 排序运算符还支持聚合和重复消除。 它可以尽早执行这些操作，即在写入临时文件时[2]。 排序算法在[211.</p>
<p>In summary, Volcano’s one-to-one match operators are very powerful parts of Volcano’s query execution alge- bra. By separating the control required to operate on sets of items and the interpretation and manipulation of indi- vidual items it can perform a variety of set matching tasks frequently used in database query processing, and can perform these tasks for arbitrary data types and data models. The separation of mechanisms and policies for overflow management supports overflow avoidance as well as hybrid hash overflow resolution, both recursively if required. Implementing sort- and hash-based algo- rithms in a comparable fashion will allow meaningful ex- perimental research into the duality and trade-offs be- tween sort- and hash-based query processing algorithms. The iterator interface guarantees that the one-to-one match operator can easily be combined with other operations, including new iterators yet to be designed.</p>
<p>总之，Volcano 的一对一匹配运算符是 Volcano 查询执行代数中非常强大的部分。 通过分离对项目集进行操作所需的控制以及对单个项目的解释和操作，它可以执行数据库查询处理中经常使用的各种集合匹配任务，并且可以对任意数据类型和数据模型执行这些任务。 溢出管理机制和策略的分离支持溢出避免以及混合散列溢出解决，如果需要的话可以递归地解决。 以类似的方式实现基于排序和散列的算法将允许对基于排序和散列的查询处理算法之间的二元性和权衡进行有意义的实验研究。 迭代器接口保证一对一匹配运算符可以轻松地与其他操作组合，包括尚未设计的新迭代器。</p>
</li>
<li><p><strong>One-to-Many Match:</strong> While the one-to-one match operator includes an item in its output depending on a comparison of two items with one another, the one-to- many match operator compares each item with a number of other items to determine whether a new item is to be produced. <strong>A</strong> typical example is relational division, the re- lational algebra operator corresponding to universal quan- tification in relational calculus. There are two versions of relational division in Volcano. The first version, called <strong>native division,</strong> is based on sorting. The second version, called <strong>hash-division,</strong> utilizes two hash tables, one on the divisor and one on the quotient. An exact description of the two algorithms and altemative algorithms based on aggregate functions can be found in <strong>[16]</strong> along with ana- lytical and experimental performance comparisons and detailed discussions of two partitioning strategies for hash table overflow and multiprocessor implementations. W e are currently studying how to generalize these algo- rithms in a way comparable with the generalizations of aggregation and join, e.g., for a <strong>majority</strong> function.</p>
<p>一对多匹配：一对一匹配运算符根据两个项目之间的比较在其输出中包含一个项目，而一对多匹配运算符将每个项目与多个其他项目进行比较 以确定是否要生产新产品。 一个典型的例子是关系除法，关系代数运算符对应于关系微积分中的通用量化。 Volcano 中的关系划分有两个版本。 第一个版本称为本机划分，基于排序。 第二种版本称为哈希除法，它使用两个哈希表，一个用于除数，一个用于商。 两种算法和基于聚合函数的替代算法的准确描述可以在[16]中找到，以及分析和实验性能比较以及哈希表溢出和多处理器实现的两种分区策略的详细讨论。 我们目前正在研究如何以与聚合和连接的泛化相当的方式来泛化这些算法，例如，对于多数函数.</p>
</li>
</ol>
<h3 id="IV-EXTENSIBILITY"><a href="#IV-EXTENSIBILITY" class="headerlink" title="IV. EXTENSIBILITY"></a>IV. EXTENSIBILITY</h3><p>A number of database research efforts strive for exten- sibility, e.g., EXODUS, GENESIS, Postgres, Starburst, DASDBS <strong>[30],</strong> Cactis <strong>[24],</strong> and others. Volcano is a very open query evaluation architecture that provides easy ex- tensibility. Let us consider a number of frequently pro- posed database extensions and how they can be accom- modated in Volcano.</p>
<p>许多数据库研究工作都致力于可扩展性，例如 EXODUS、GENESIS、Postgres、Starburst、DASDBS [30]、Cactis [24] 等。 Volcano 是一个非常开放的查询评估架构，提供简单的可扩展性。 让我们考虑一些经常提出的数据库扩展以及如何将它们容纳在 Volcano 中。</p>
<p>First, when extending the object type system, e.g., with a new abstract data type (ADT) like date or box, the Volcano software is not affected at all because it does not provide a type system for objects. All manipulation of and calculation based on individual objects is performed by support functions. To a certain extent, Volcano is incomplete (it is not a database system), but by separating set processing and instance interpretation and providing a well-defined interface between them, Volcano is inherently extensible on the level of instance types and semantics.</p>
<p>首先，当扩展对象类型系统时，例如使用日期或框等新的抽象数据类型（ADT），Volcano 软件根本不受影响，因为它不提供对象的类型系统。 所有基于单个对象的操作和计算都是由支持函数执行的。 在某种程度上，Volcano 是不完整的（它不是一个数据库系统），但是通过将集合处理和实例解释分开并在它们之间提供定义良好的接口，Volcano 在实例类型和语义层面上具有本质上的可扩展性。</p>
<p>As a rule, data items that are transferred between operators using some next iterator procedure are records. For an extensible or object-oriented database system, this would be an unacceptable problem and limitation. The solution to be used in Volcano is to pass only the root component (record) between operators after loading and fixing necessary component records in the buffer and suit- ably swizzling inter-record pointers. Very simple objects can be assembled in Volcano with the functional join op- erator. Generalizations of this operator are necessary for object-oriented o r non-first-normal-form database sys- tems, but can be included in Volcano without difficulty. In fact, a prototype for such an assembly operator has been built [ 2 6 ] for use in the revelation object - oriented database systems project [151.</p>
<p>通常，使用某个下一个迭代器过程在运算符之间传输的数据项是记录。 对于可扩展或面向对象的数据库系统，这将是一个不可接受的问题和限制。 Volcano 中使用的解决方案是在缓冲区中加载和修复必要的组件记录并适当混合记录间指针后，仅在运算符之间传递根组件（记录）。 非常简单的对象可以通过函数连接运算符在 Volcano 中组装。 该运算符的推广对于面向对象或非第一范式数据库系统是必要的，但可以毫无困难地包含在 Volcano 中。 事实上，这样一个汇编操作符的原型已经被构建出来了[2 6]，用于revelation 面向对象的数据库系统项目[151]。</p>
<p>Second, in order to add new functions on individual objects or aggregate functions, e.g., geometric mean, to the database and query processing system, the appropriate support function is required and passed to a query pro- cessing routine. In other words, the query processing rou- tines are not affected by the semantics of the support func- tions as long as interface and return values are correct. The reason Volcano software is not affected by extensions of the functionality on individual objects is that Volcano’s software only provides abstractions and implementations for dealing with and sequencing <strong>sets</strong> of objects using streams, whereas the capabilities for interpreting and ma- nipulating individual objects are <strong>imported</strong> in the form of support functions.</p>
<p>其次，为了向数据库和查询处理系统添加单个对象或聚合函数的新函数（例如几何平均值），需要适当的支持函数并将其传递给查询处理例程。 换句话说，只要接口和返回值正确，查询处理例程就不会受到支持函数语义的影响。 Volcano 软件不受单个对象功能扩展影响的原因是，Volcano 软件仅提供使用流处理和排序对象集的抽象和实现，而解释和操作单个对象的功能是在 Volcano 软件中导入的。 支持功能的形式。</p>
<p>Third, in order to incorporate a new access method, e.g., multidimensional indices in form of R-trees [22], appropriate iterators have to be defined. Notice that it makes sense to perform not only retrieval but also main- tenance of storage structures in the form of iterators. For example, if a set of items defined via a predicate (selec- tion) needs to be updated, the iterator or query tree im- plementing the selection can “feed” its data into a main- tenance iterator. The items fed into the maintenance operator should include a reference to the part of the storage structure to be updated, e.g., a RID or a key, and appropriate new values if they have been computed in the selection, e.g., new salaries from old salaries. Updating multiple structures (multiple indices) can be organized and executed very efficiently using nested iterators, i.e., a query evaluation plan. Furthermore, if ordering makes maintenance more efficient as for B-trees, an ordering or sort iterator can easily be included in the plan. In other words, it makes sense to think of plans not only as query plans used in retrieval but also as “update plans” or com- binations of retrieval and update plans. The stream con- cept is very open; in particular, anonymous inputs shield existing query processing modules and the new iterators from one another.</p>
<p>第三，为了合并新的访问方法，例如 R 树 [22] 形式的多维索引，必须定义适当的迭代器。 请注意，不仅以迭代器的形式执行检索，而且还执行存储结构的维护都是有意义的。 例如，如果需要更新通过谓词（选择）定义的一组项目，则实现选择的迭代器或查询树可以将其数据“馈送到”维护迭代器中。 馈入维护操作符的项目应包括对要更新的存储结构部分的引用，例如，RID或密钥，以及适当的新值（如果它们已在选择中计算），例如，从旧工资中计算出新工资 。 使用嵌套迭代器（即查询评估计划）可以非常有效地组织和执行更新多个结构（多个索引）。 此外，如果排序使 B 树的维护更加高效，则可以轻松地将排序或排序迭代器包含在计划中。 换句话说，将计划不仅视为检索中使用的查询计划，而且视为“更新计划”或检索和更新计划的组合是有意义的。 流的概念非常开放； 特别是，匿名输入可以屏蔽现有查询处理模块和新迭代器之间的相互影响。</p>
<p>Fourth, to include a new query processing algorithm in Volcano, e.g., an algorithm for transitive closure or <strong>nest</strong> and <strong>unnest</strong> operations for nested relations, the algorithm needs to be coded in the iterator paradigm. In other words, the algorithm implementation must provide <strong>open, next,</strong> and <strong>close</strong> procedures, and must use these procedures for its input stream or streams. After an algorithm has been brought into this form, its integration with Volcano is trivial. In fact, as the Volcano query processing software became more complex and complete, this was done a number of times. For example, the one-to-many match or division operators [16] were added without regard to the other operators, and when the early in-memory-only ver- sion of hash-based one-to-one match was replaced by the version with overflow management described above, none of the other operators or meta-operators had to be changed. Finally, a complex object assembly operator was added recently to Volcano <strong>[26].</strong></p>
<p>第四，要在 Volcano 中包含新的查询处理算法，例如用于嵌套关系的传递闭包或嵌套和取消嵌套操作的算法，该算法需要以迭代器范例进行编码。 换句话说，算法实现必须提供 open、next 和 close 过程，并且必须将这些过程用于其一个或多个输入流。 当算法采用这种形式后，它与 Volcano 的集成就很简单了。 事实上，随着 Volcano 查询处理软件变得更加复杂和完整，这种情况已经被完成了很多次。 例如，添加了一对多匹配或除法运算符[16]，而不考虑其他运算符，并且当基于哈希的一对一匹配的早期仅内存版本被替换为 在上述具有溢出管理的版本中，无需更改任何其他运算符或元运算符。 最后，Volcano 最近添加了一个复杂的对象组装操作符 [26]。</p>
<p>Extensibility can also be considered in a different con- text. In the long run, it clearly is desirable to provide an interactive front-end to make using Volcano easier. We are currently working on a two front-end, a nonoptimized command interpreter based on Volcano’s executable al- gebra and an optimized one based on a logical algebra or calculus language including query optimization imple- mented with a new optimizer generator. The translation between plans as produced by an optimizer and Volcano will be accomplished using a module that “walks” query evaluation plans produced by the optimizer and Volcano plans, i.e., state records, support functions, etc. We will also use the optimizing front-end as a vehicle for experi- mentation with <strong>dynamic</strong> <em>query</em> <strong>evaluation plans</strong> that are outlined in the next section.</p>
<p>还可以在不同的上下文中考虑可扩展性。 从长远来看，显然需要提供一个交互式前端以使 Volcano 的使用更加容易。 我们目前正在开发一种双前端，一种是基于 Volcano 可执行代数的非优化命令解释器，另一种是基于逻辑代数或微积分语言的优化命令解释器，包括使用新的优化器生成器实现的查询优化。 优化器和 Volcano 生成的计划之间的转换将使用一个模块来完成，该模块“遍历”优化器和 Volcano 计划生成的查询评估计划，即状态记录、支持函数等。我们还将使用优化前端 最终作为动态查询评估计划实验的工具，这些计划将在下一节中概述。</p>
<p>In summary, since Volcano is very modular in its de- sign, extensibility is provided naturally. It could be ar- gued that this is the case only because Volcano does not address the hard problems in extensibility. However, this argument does not hold. Rather, Volcano is only one component of a database system, namely the query exe- cution engine. Therefore, it addresses only a subset of the extensibility problems and ignores a different subset. As a query processing engine, it provides extensibility of its set of query processing algorithms, and it does so in a way that matches well with the extensibility as provided by query optimizer generators. It does not provide other da- tabase services and abstractions like a type system and type checking for the support functions since it is not an extensible database system. The Volcano routines assume that query evaluation plans and their support functions are correct. Their correctness has to be ensured before Vol- cano is invoked, which is entirely consistent with the gen- eral database systems concept to ensure correctness at the highest possible level, i.e., as soon as possible after a user query is parsed. The significance of Volcano as an exten- sible query evaluation system is that it provides a simple but very useful and powerful set of mechanisms for effi- cient query processing and that it can and has been used as a flexible research tool. Its power comes not only from the fact that it has been implemented following a few con- sistent design principles but also from its two meta-op- erators described in the next two sections.</p>
<p>总而言之，由于 Volcano 的设计非常模块化，因此自然地提供了可扩展性。 可以说，出现这种情况只是因为 Volcano 没有解决可扩展性方面的难题。 然而，这个论点并不成立。 相反，Volcano 只是数据库系统的一个组件，即查询执行引擎。 因此，它仅解决可扩展性问题的一个子集并忽略不同的子集。 作为查询处理引擎，它提供了查询处理算法集的可扩展性，并且它的实现方式与查询优化器生成器提供的可扩展性很好地匹配。 它不提供其他数据库服务和抽象，例如类型系统和支持功能的类型检查，因为它不是可扩展的数据库系统。 Volcano 例程假设查询评估计划及其支持函数是正确的。 在调用 Volcano 之前必须确保它们的正确性，这与一般数据库系统的概念完全一致，以确保尽可能高的级别的正确性，即在解析用户查询后尽快确保正确性。 Volcano 作为一个可扩展的查询评估系统的重要性在于，它为高效查询处理提供了一套简单但非常有用且强大的机制，并且它可以并且已经被用作灵活的研究工具。 它的力量不仅来自于它是按照一些一致的设计原则实现的，而且还来自于接下来两节中描述的两个元运算符。</p>
<h3 id="V-DYNAMIC-QUERY-EVALUATION-PLANS"><a href="#V-DYNAMIC-QUERY-EVALUATION-PLANS" class="headerlink" title="V. DYNAMIC QUERY EVALUATION PLANS"></a>V. DYNAMIC QUERY EVALUATION PLANS</h3><p>In most database systems, a query embedded in a program written in a conventional programming language <strong>is</strong> opti- mized when the program is compiled. The query opti- mizer must make assumptions about the values of the pro- gram variables that appear as constants in the query and the data in the database. These assumptions include that the query can be optimized realistically using guessed “typical” values for the program variables and that the database will not change significantly between query op- timization and query evaluation. The optimizer must also anticipate the resources that can be committed to query evaluation, e.g., the size of the buffer or the number of processors. The optimality of the resulting query evalua- tion plan depends on the validity of these assumptions. If a query evaluation plan is used repeatedly over an ex- tended period of time, it is important to determine when reoptimization is necessary. We are working on a scheme in which reoptimization can be avoided by using a new technique called <strong>dynamic query evaluation plans</strong> <strong>[I</strong> **71.**’</p>
<p>在大多数数据库系统中，嵌入在用传统编程语言编写的程序中的查询在程序编译时被优化。 查询优化器必须对查询中作为常量出现的程序变量的值和数据库中的数据做出假设。 这些假设包括可以使用程序变量的猜测“典型”值来实际优化查询，并且数据库在查询优化和查询评估之间不会发生显着变化。 优化器还必须预测可用于查询评估的资源，例如缓冲区的大小或处理器的数量。 结果查询评估计划的最优性取决于这些假设的有效性。 如果在较长时间内重复使用查询评估计划，则确定何时需要重新优化非常重要。 我们正在研究一种方案，通过使用一种称为动态查询评估计划的新技术来避免重新优化[I 71。”</p>
<p>Volcano includes a <strong>choose-plan</strong> operator that allows re- alization of both multiplan access modules and dynamic plans. In some sense, it is not an operator as it does not perform any data manipulations. Since it provides control for query execution it is a <strong>metu-operator.</strong> This operator provides the same <strong>open-next-close</strong> protocol as the other operators and can therefore be inserted into a query plan at any location. The <strong>open</strong> operation decides which of sev- eral equivalent query plans to use and invokes the <strong>open</strong> operation for this input. <strong>Open</strong> calls upon a support func- tion for this policy decision, passing it the <strong>bindings</strong> pa- rameter described above. The <strong>next</strong> and <strong>close</strong> operations simply call the appropriate operation for the input chosen during <strong>open.</strong></p>
<p>Volcano 包括一个选择计划运算符，允许实现多计划访问模块和动态计划。 从某种意义上说，它不是一个运算符，因为它不执行任何数据操作。 由于它提供对查询执行的控制，因此它是一个元运算符。 该运算符提供与其他运算符相同的打开-下一个-关闭协议，因此可以插入到查询计划的任何位置。 open 操作决定使用几个等效查询计划中的哪一个，并为此输入调用 open 操作。 Open 调用此策略决策的支持函数，并向其传递上述绑定参数。 接下来和关闭操作只需为打开期间选择的输入调用适当的操作。</p>
<p>Fig. 4 shows a very simple dynamic plan. Imagine a selection predicate controlled by a program variable. The index scan and functional join can be much faster than the file scan, but not when the index is nonclustering and a large number of items must be retrieved. Using the plan of Fig. 4, however, the optimizer can prepare effectively for both cases, and the application program using this dy- namic plan will perform well for any predicate value.</p>
<p>图 4 显示了一个非常简单的动态计划。 想象一下由程序变量控制的选择谓词。 索引扫描和函数连接可以比文件扫描快得多，但当索引是非聚集的并且必须检索大量项目时则不然。 然而，使用图 4 的计划，优化器可以有效地为这两种情况做好准备，并且使用此动态计划的应用程序对于任何谓词值都将表现良好。</p>
<p><img src="/img/volcano-pic/image-20230720160212513.png"></p>
<p>The <strong>choose-plan</strong> operator allows considerable flexibil- ity. If only one <strong>choose-plan</strong> operator is used as the top of a query evaluation plan, it implements a multiplan access module. If multiple <strong>choose-plan</strong> operators are included in a plan, they implement a dynamic query evaluation plan. Thus, all forms of dynamic plans identified in [17] can be realized with one simple and effective mechanism. Note that the <strong>choose-plan</strong> operator does not make the policy decision concerning which of several plans to execute; it only provides the mechanism. The policy is imported us- ing a support function. Thus, the decision can be made depending on bindings for query variables (e.g., program variables used as constants in a query predicate), on the resource and contention situation (e.g., the availability of processors and memory), other considerations such as user priority, or all of the above.</p>
<p>选择计划运算符具有相当大的灵活性。 如果仅使用一个选择计划运算符作为查询评估计划的顶部，则它会实现多计划访问模块。 如果一个计划中包含多个选择计划运算符，它们将实现动态查询评估计划。 因此，[17]中确定的所有形式的动态计划都可以通过一种简单而有效的机制来实现。 请注意，选择计划操作员并不做出有关执行多个计划中哪一个的策略决定； 它仅提供机制。 该策略是使用支持功能导入的。 因此，可以根据查询变量的绑定（例如，在查询谓词中用作常量的程序变量）、资源和争用情况（例如，处理器和内存的可用性）、其他考虑因素（例如用户优先级）来做出决定 ，或以上全部。</p>
<p>The <strong>choose-plan</strong> operator provides significant new freedom in query optimization and evaluation with an ex- tremely small amount of code. Since it is compatible with the query processing paradigm, its presence does not af- fect the other operators at all, and it can be used in a very flexible way. The operator is another example for Vol- cano’s design principle to provide mechanisms to imple- ment a multitude of policies. We used the same philoso- phy when designing and implementing a scheme for parallel query evaluation.</p>
<p>选择计划运算符以极少量的代码为查询优化和评估提供了显着的新自由度。 由于它与查询处理范例兼容，因此它的存在根本不会影响其他运算符，并且可以以非常灵活的方式使用。 运营商是 Volcano 设计原则的另一个例子，它提供了实施多种策略的机制。 在设计和实现并行查询评估方案时，我们使用了相同的理念。</p>
<h3 id="VI-MULTIPROCESSOR-QOURERY-EVALUATION"><a href="#VI-MULTIPROCESSOR-QOURERY-EVALUATION" class="headerlink" title="VI. MULTIPROCESSOR  QOURERY  EVALUATION"></a>VI. MULTIPROCESSOR  QOURERY  EVALUATION</h3><p>A large number of research and development projects have shown over the last decade that query processing in relational database systems can benefit significantly from parallel algorithms. The main reasons parallelism is rel- atively easy to exploit in relational query processing sys- tems are 1) query processing is performed using a tree of operators that can be executed in separate processes and processors connected with pipelines (inter-operator par- allelism) and 2) each operator consumes and produces sets that can be partitioned or fragmented into disjoint subsets to be processed in parallel (intra-operator parallelism). Fortunately, the reasons parallelism is easy to exploit in relational systems does not require the relational data model per se, only that queries be processed as sets of data items in a tree of operators. These are exactly the assumptions made in the design of Volcano, and it was therefore logical to parallelize extensible query process- ing in Volcano.</p>
<p>过去十年中的大量研究和开发项目表明，关系数据库系统中的查询处理可以从并行算法中受益匪浅。 在关系查询处理系统中并行性相对容易利用的主要原因是：1）查询处理是使用运算符树执行的，该运算符树可以在与管道连接的单独进程和处理器中执行（运算符间并行性） 2) 每个运算符消耗并生成可以被分区或分段为不相交子集以进行并行处理的集合（运算符内并行性）。 幸运的是，并行性在关系系统中易于利用的原因并不需要关系数据模型本身，只需要将查询作为运算符树中的数据项集进行处理即可。 这些正是 Volcano 设计中所做的假设，因此在 Volcano 中并行化可扩展查询处理是合乎逻辑的。</p>
<p>When Volcano was ported to a multiprocessor machine, it was desirable to use all single-process query processing code existing at that point without any change.The result is very clean, self-scheduling parallel processing. We call this novel approach the operator model of parallelizing a query evaluation engine [20].*In this model, all parallelism issues are localized in one operator that uses and provides the standard iterator interface to the operators above and below in a query tree.</p>
<p>当 Volcano 被移植到多处理器机器上时，希望使用当时存在的所有单进程查询处理代码而不进行任何更改。结果是非常干净的、自调度的并行处理。 我们将这种新颖的方法称为并行化查询评估引擎的运算符模型[20]。*在此模型中，所有并行问题都集中在一个运算符中，该运算符使用标准迭代器接口并向查询树中的上方和下方运算符提供标准迭代器接口。</p>
<p>The module responsible for parallel execution and syn- chronization is called the <strong>exchange</strong> iterator in Volcano. Notice that it is an iterator with <strong>open, next,</strong> and <strong>close</strong> pro- cedures; therefore, it can be inserted at any one place or at multiple places in a complex query tree. Fig. <em>5</em> shows a complex query execution plan that includes data pro- cessing operators, i.e., file scans and joins, and exchange operators. The next two figures will show the processes created when this plan is executed.</p>
<p>负责并行执行和同步的模块在 Volcano 中称为交换迭代器。 请注意，它是一个具有 open、next 和 close 过程的迭代器； 因此，它可以插入到复杂查询树中的任意一处或多处。 图 5 显示了一个复杂的查询执行计划，其中包括数据处理运算符，即文件扫描和连接以及交换运算符。 接下来的两幅图将显示执行该计划时创建的流程。</p>
<p><img src="/img/volcano-pic/image-20230720160833887.png"></p>
<p>This section describes how the <strong>exchange</strong> iterator im- plements vertical and horizontal parallelism followed by discussions of alternative modes of operation of Vol- cano’s <strong>exchange</strong> operator and modifications to the file system required for multiprocess query evaluation. The description goes into a fair amount of detail since the <strong>ex- change</strong> operator adds significantly to the power of Vol- cano. In fact, it represents a new concept in parallel query execution that is likely to prove useful in parallelizing both existing commercial database products and extensible sin- gle-process systems. It is described here for shared-mem- ory systems only; considerations for the distributed-mem- ory version are outlined as future work in the last section of this paper.</p>
<p>本节介绍交换迭代器如何实现垂直和水平并行性，然后讨论 Volcano 交换运算符的替代操作模式以及对多进程查询评估所需的文件系统的修改。 由于交易所运营商显着增强了 Volcano 的功能，因此描述非常详细。 事实上，它代表了并行查询执行的一个新概念，可能在现有商业数据库产品和可扩展单进程系统的并行化方面很有用。 此处仅针对共享内存系统进行描述； 本文最后一部分概述了分布式内存版本的考虑因素作为未来的工作。</p>
<h4 id="A-Vertical-Parallelism-垂直并行性"><a href="#A-Vertical-Parallelism-垂直并行性" class="headerlink" title="A. Vertical Parallelism 垂直并行性"></a><strong>A. Vertical Parallelism</strong> 垂直并行性</h4><p>The first function of exchange is to provide <strong>vertical parallelism</strong> or pipelining between processes. The <strong>open</strong> procedure creates a new process after creating a data structure in shared memory called a <strong>port</strong> for synchroni- zation and data exchange. The child process is an exact duplicate of the parent process. The exchange operator then takes different paths in the parent and child pro- cesses.</p>
<p>交换的第一个功能是在进程之间提供<strong>垂直并行性</strong>或流水线。 <strong>open</strong> 过程在共享内存中创建称为<strong>端口</strong> 的数据结构后创建一个新进程，用于同步和数据交换。 子进程是父进程的精确副本。 然后交换操作符在父进程和子进程中采取不同的路径。</p>
<p>The parent process serves as the consumer and the child process as the producer in Volcano. The exchange oper- ator in the consumer process acts as a normal iterator, the only difference from other iterators is that it receives its input via inter-process communication rather than iterator (procedure) calls. After creating the child process, open-exchange in the consumer is done. Next-exchange waits for data to arrive via the port and returns them a record at a time. Close-exchange informs the producer that it can close, waits for an acknowledgment, and re- turns.</p>
<p>在 Volcano 中，父进程充当消费者，子进程充当生产者。 消费者进程中的交换运算符充当普通迭代器，与其他迭代器的唯一区别是它通过进程间通信而不是迭代器（过程）调用接收输入。 创建子进程后，消费者中的开放交换就完成了。 Next-exchange 等待数据通过端口到达并一次返回一条记录。 关闭交换通知生产者它可以关闭，等待确认并返回。</p>
<p>Fig. <strong>6</strong> shows the processes created for vertical paral- lelism or pipelining by the exchange operators in the query plan of the previous figure. The exchange operators have created the processes, and are executing on both sides of the process boundaries, hiding the existence of process boundaries from the “work” operators. The fact that the join operators are executing within the same process, i.e., the placement of the exchange operators in the query tree, was arbitrary. The exchange operator provides only the mechanisms for parallel query evaluation, and many other choices (policies) would have been possible. In fact, the mechanisms provided in the operator model tend to be more flexible and amenable to more different policies than in the alternative bracket model <strong>[20].</strong></p>
<p>图 6 显示了上图查询计划中的交换操作符为垂直并行或流水线创建的进程。 交换操作员创建了流程，并在流程边界的两侧执行，向“工作”操作员隐藏了流程边界的存在。 事实上，连接运算符在同一进程中执行，即交换运算符在查询树中的放置是任意的。 交换运算符仅提供并行查询评估的机制，并且许多其他选择（策略）也是可能的。 事实上，与替代支架模型相比，运营商模型中提供的机制往往更加灵活并且能够适应更多不同的政策[20]。</p>
<p><img src="/img/volcano-pic/image-20230720160942516.png"></p>
<p>In the producer process, the exchange operator be- comes the <strong>driver</strong> for the query tree below the exchange operator using <strong>open, next,</strong> and <strong>close</strong> on its input. The out- put of <strong>next</strong> is collected in <strong>packets,</strong> which are arrays of <strong>Next-Record</strong> structures. The packet size is an argument in the exchange iterator’s state record, and can be set be- tween l and <strong>32</strong> 000 records. When a packet is filled, it is inserted into a linked list originating in the <strong>port</strong> and a semaphore is used to inform the consumer about the new packet. Records in packets are fixed in the shared buffer and must be unfixed by a consuming operator.</p>
<p>在生产者进程中，交换运算符成为交换运算符下方查询树的驱动程序，在其输入上使用 open、next 和 close。 next 的输出被收集在数据包中，这些数据包是 Next-Record 结构的数组。 数据包大小是交换迭代器状态记录中的一个参数，可以设置在 1 到 32 000 条记录之间。 当数据包被填满时，它将被插入到源自端口的链表中，并使用信号量来通知消费者有关新数据包的信息。 数据包中的记录固定在共享缓冲区中，并且必须由消费操作员取消固定。</p>
<p>When its input is exhausted, the exchange operator in the producer process marks the last packet with an end- of-stream tag, passes it to the consumer, and waits until the consumer allows closing all open files. This delay is necessary in Volcano because files on virtual devices must not be closed before all their records are unpinned in the buffer. In other words, it is a peculiarity due to other de- sign decisions in Volcano rather than inherent in the ex- change iterator on the operator model of parallelization.</p>
<p>当其输入耗尽时，生产者进程中的交换操作符会使用流结束标记标记最后一个数据包，将其传递给消费者，并等待消费者允许关闭所有打开的文件。 这种延迟在 Volcano 中是必要的，因为虚拟设备上的文件在其所有记录都在缓冲区中取消固定之前不得关闭。 换句话说，这是由于 Volcano 中的其他设计决策而产生的特性，而不是并行化操作模型上交换迭代器固有的特性。</p>
<p>The alert reader has noticed that the exchange module uses a different dataflow paradigm than all other operators. While all other modules are based on demand-driven dataflow (iterators, lazy evaluation), the producer-con- sumer relationship of exchange uses data-driven dataflow (eager evaluation). There are two reasons for this change in paradigms. First, we intend to use the exchange oper- ator also for horizontal parallelism, to be described be- low, which is easier to implement with data-driven data- flow. Second, this scheme removes the need for request messages. Even though a scheme with request messages, e.g., using a semaphore, would probably perform accept- ably on a shared-memory machine, it would create un- necessary control overhead and delays. Since very-high degrees of parallelism and very-high-performance query evaluation require a closely tied network, e.g., a hyper- cube, of shared-memory machines, we decided to use a paradigm for data exchange that has been proven to per- form well in a “shared-nothing” database machine [111.<br>A run-time switch of exchange enablesjow control or back pressure using an additional semaphore. If the pro- ducer is significantly faster than the consumer, the pro- ducer may pin a significant portion of the buffer, thus impeding overall system performance. If flow control is enabled, after a producer has inserted a new packet into the port, it must request the flow control semaphore. After a consumer has removed a packet from the port, it re- leases the flow control semaphore. The initial value of the flow control semaphore determines how many packets the producers may get ahead of the consumers.</p>
<p>细心的读者已经注意到，交换模块使用与所有其他运算符不同的数据流范例。 虽然所有其他模块都基于需求驱动的数据流（迭代器、惰性求值），但生产者-消费者交换关系使用数据驱动的数据流（热切求值）。 这种范式的改变有两个原因。 首先，我们打算将交换运算符也用于水平并行性，如下所述，这更容易通过数据驱动的数据流来实现。 其次，该方案消除了对请求消息的需要。 尽管带有请求消息的方案（例如使用信号量）可能在共享内存机器上表现良好，但它会产生不必要的控制开销和延迟。 由于非常高的并行度和非常高性能的查询评估需要一个紧密相连的网络，例如共享内存机器的超立方体，因此我们决定使用一种已经被证明可以满足以下条件的数据交换范例： 在“无共享”数据库机器中很好地形成[111。<br>交换的运行时开关可以使用附加信号量进行流控制或背压。 如果生产者明显快于消费者，则生产者可能会固定缓冲区的很大一部分，从而影响整体系统性能。 如果启用了流量控制，则在生产者将新数据包插入端口后，它必须请求流量控制信号量。 当消费者从端口移除数据包后，它会释放流量控制信号量。 流量控制信号量的初始值决定了生产者可以领先于消费者多少个数据包。</p>
<p>Notice that flow control and demand-driven dataflow are not the same. One significant difference is that flow control allows some “slack” in the synchronization of producer and consumer and therefore truly overlapped ex- ecution, while demand-driven dataflow is a rather rigid structure of request and delivery in which the consumer waits while the producer works on its next output. The second significant difference is that data-driven dataflow is easier to combine efficiently with horizontal parallelism and partitioning.</p>
<p>请注意，流控制和需求驱动的数据流并不相同。 一个显着的区别是，流控制允许生产者和消费者的同步存在一定的“松弛”，因此真正实现了重叠执行，而需求驱动的数据流是一种相当严格的请求和交付结构，其中消费者在生产者工作时等待 关于其下一个输出。 第二个显着区别是数据驱动的数据流更容易与水平并行性和分区有效地结合。</p>
<h4 id="B-Horizontal-Parallelism-水平并行性"><a href="#B-Horizontal-Parallelism-水平并行性" class="headerlink" title="B. Horizontal Parallelism 水平并行性"></a><strong>B. Horizontal Parallelism</strong> 水平并行性</h4><p>There are two forms of horizontal parallelism, which we call <strong>bushy parallelism</strong> and <strong>intra-operator</strong> parallelism. In bushy parallelism, different CPU’s execute different subtrees of a complex query tree. Bushy parallelism and vertical parallelism are forms of <strong>inter-operator</strong> parallel- ism. Intra-operator parallelism means that several CPU’s perform the same operator on different subsets of a stored dataset or an intermediate result.</p>
<p>水平并行有两种形式，我们称之为浓密并行和运算符内并行。 在密集并行中，不同的 CPU 执行复杂查询树的不同子树。 Bushy 并行和垂直并行是运算符间并行的形式。 运算符内并行性意味着多个 CPU 对存储数据集或中间结果的不同子集执行相同的运算符。</p>
<p>Bushy parallelism can easily be implemented by insert- ing one or two exchange operators into a query tree. For example, in order to sort two inputs into a merge-join in parallel, the first or both inputs are separated from the merge-join by an exchange operation. The parent process turns to the second sort immediately after forking the child process that will produce the first input in sorted order. Thus, the two sort operations are working in parallel.</p>
<p>通过将一两个交换运算符插入到查询树中，可以轻松实现密集并行。 例如，为了并行地将两个输入排序到合并连接中，第一个或两个输入通过交换操作与合并连接分开。 父进程在分叉子进程后立即转向第二种排序，该子进程将按排序顺序生成第一个输入。 因此，两个排序操作是并行工作的。</p>
<p>Intra-operator parallelism requires data partitioning. Partitioning of stored datasets is achieved by using mul- tiple files, preferably on different devices. Partitioning of intermediate results is implemented by including multiple queues in a port. If there are multiple consumer pro- cesses, each uses its own input queue. The producers use a support function to decide into which of the queues (or actually, into which of the packets being filled by the pro- ducer) an output record must go. Using a support function allows implementing round-robin-, key-range-, or hash- partitioning.</p>
<p>运算符内并行性需要数据分区。 存储数据集的分区是通过使用多个文件来实现的，最好是在不同的设备上。 中间结果的分区是通过在端口中包含多个队列来实现的。 如果有多个消费者进程，则每个进程都使用自己的输入队列。 生产者使用支持函数来决定输出记录必须进入哪个队列（或者实际上，进入由生产者填充的哪个数据包）。 使用支持函数可以实现循环、键范围或散列分区。</p>
<p>Fig. 7 shows the processes created for horizontal par- allelism or partitioning by the exchange operators in the query plan shown earlier. The join operators are executed by three processes while the file scan operators are exe- cuted by one or two processes each, typically scanning file partitions on different devices. To obtain this group- ing of processes, the only difference to the query plan used for the previous figure is that the “degree of parallelism” arguments in the exchange state records have to be set to 2 or <strong>3,</strong> respectively, and that partitioning support func- tions must be provided for the exchange operators that transfer file scan output to the joint processes. All file scan processes can transfer data to all join processes; however, data transfer between the join operators occurs only within each of the join processes. Unfortunately, this restriction renders this parallelization infeasible if the two joins are on different attributes and partitioning-based parallel join methods are used. For this case, a variant of exchange is supported in Volcano exchange operator called <strong>inrer- change,</strong> which is described in the next section.</p>
<p>图 7 显示了前面显示的查询计划中交换运算符为水平并行或分区创建的进程。 连接运算符由三个进程执行，而文件扫描运算符分别由一两个进程执行，通常扫描不同设备上的文件分区。 为了获得这个进程分组，与上图使用的查询计划的唯一区别是交换状态记录中的“并行度”参数必须分别设置为 2 或 3，并且分区支持 必须为交换操作员提供将文件扫描输出传输到联合进程的功能。 所有文件扫描进程都可以向所有连接进程传输数据； 然而，连接运算符之间的数据传输仅发生在每个连接进程内。 不幸的是，如果两个连接位于不同的属性上并且使用基于分区的并行连接方法，则此限制使得这种并行化不可行。 对于这种情况，Volcano 交换操作符支持一种称为 inrer-change 的交换变体，这将在下一节中进行描述。</p>
<p><img src="/img/volcano-pic/image-20230720161343962.png"></p>
<p>​	If an operator or an operator subtree is executed in par- allel by a group of processes, one of them is designated the master. When a query tree is opened, only one process is running, which is naturally the master. When a master forks a child process in a producer-consumer relation- ship, the child process becomes the master within its group. The first action of the master producer is to determine how many slaves are needed by calling an appro- priate support function. If the producer operation is to run in parallel, the master producer forks the other producer processes.</p>
<p>如果一个运算符或一个运算符子树由一组进程并行执行，则其中一个被指定为主进程。 当一棵查询树被打开时，只有一个进程在运行，这自然是主进程。 当主进程在生产者-消费者关系中分叉子进程时，子进程就成为其组内的主进程。 主生产者的第一个动作是通过调用适当的支持函数来确定需要多少个从设备。 如果生产者操作要并行运行，则主生产者会分叉其他生产者进程。</p>
<p>After all producer processes are forked, they run with- out further synchronization among themselves, with two exceptions. First, when accessing a shared data structure, e.g., the port to the consumers or a buffer table, short- term locks must be acquired for the duration of one linked- list insertion. Second, when a producer group is also a consumer group, i.e., there are at least two exchange op- erators and three process groups involved in a vertical pipeline, the processes that are both consumers and pro- ducers synchronize twice. During the (very short) interval between synchronizations, the master of this group cre- ates a port that serves all processes in its group.</p>
<p>在所有生产者进程被分叉后，它们之间的运行不会进一步同步，但有两个例外。 首先，当访问共享数据结构时，例如消费者的端口或缓冲表，必须在一次链表插入期间获取短期锁。 其次，当生产者组也是消费者组时，即垂直管道中至少涉及两个交换操作符和三个进程组时，既是消费者又是生产者的进程会同步两次。 在同步之间的（非常短的）间隔期间，该组的主设备创建一个为其组中的所有进程提供服务的端口。</p>
<p>When a <strong>close</strong> request is propagated down the tree and reaches the first exchange operator, the master consum- er’s <strong>close-exchange</strong> procedure informs all producer pro- cesses that they are allowed to close down using the semaphore mentioned above in the discussion on vertical parallelism. If the producer processes are also consumers, the master of the process group informs its producers, etc. <strong>In</strong> this way, all operators are shut down in an orderly fash- ion, and the entire query evaluation is self-scheduling.</p>
<p>当关闭请求沿着树传播并到达第一个交换操作符时，主消费者的关闭交换过程通知所有生产者进程，它们可以使用上面在垂直并行性讨论中提到的信号量来关闭。 如果生产者进程也是消费者，则进程组的主进程会通知其生产者等。这样，所有操作符都会以有序的方式关闭，并且整个查询评估是自我调度的。</p>
<h4 id="C-Variants-of-the-Exchange-Operator-Exchange-Operator-的变体"><a href="#C-Variants-of-the-Exchange-Operator-Exchange-Operator-的变体" class="headerlink" title="C. Variants of the Exchange Operator Exchange Operator 的变体"></a><strong>C. Variants</strong> <strong>of</strong> <strong>the Exchange Operator</strong> Exchange Operator 的变体</h4><p>There are a number of situations for which the <strong>ex-</strong> <strong>change</strong> operator described so far required some modifi- cations or extensions. In this section, we outline addi- tional capabilities implemented in Volcano’s exchange operator. All of these variants have been implemented in the <strong>exchange</strong> operator and are controlled by arguments in the state record.</p>
<p>到目前为止所描述的交换运营商在许多情况下都需要进行一些修改或扩展。 在本节中，我们概述了 Volcano 交易所运营商实现的其他功能。 所有这些变体都已在交换运算符中实现，并由状态记录中的参数控制。</p>
<p>For some operations, it is desirable to replicate or broadcast a stream to all consumers. For example, one of the two partitioning methods for hash-division [16] re- quires that the divisor be replicated and used with each partition of the dividend. Another example are fragment- and-replicate parallel join algorithms in which one of the two input relations is not moved at all while the other relation is sent to all processors. To support these algo- rithms, the exchange operator can be directed to send all records to all consumers, after pinning them appropriately multiple times in the buffer pool. Notice that it is not nec- essary to copy the records since they reside in a shared buffer pool; it is sufficient to pin them such that each con- sumer can unpin them as if it were the only process using them.</p>
<p>对于某些操作，需要将流复制或广播给所有消费者。 例如，哈希除法[16]的两种分区方法之一要求复制除数并与被除数的每个分区一起使用。 另一个例子是片段复制并行连接算法，其中两个输入关系之一根本不移动，而另一个关系被发送到所有处理器。 为了支持这些算法，可以指示交换操作员将所有记录发送给所有消费者，然后将它们适当地固定在缓冲池中多次。 请注意，没有必要复制记录，因为它们驻留在共享缓冲池中； 固定它们就足够了，这样每个消费者都可以取消固定它们，就好像它是唯一使用它们的进程一样。</p>
<p>During implementation and benchmarking of parallel sorting <strong>[18],</strong> [21], we added two more features to <strong>ex- change.</strong> First, we wanted to implement a merge network in which some processors produce sorted streams merge concurrently by other processors. Volcano’s <strong>sort</strong> iterator can be used to generate a sorted stream. <strong>A</strong> <strong>merge</strong> iterator was easily derived from the sort module. It uses a single level merge, instead of the cascaded merge of runs used in sort. The input of <strong>a</strong> <strong>merge</strong> iterator is an <strong>exchange,</strong> Dif- ferently from other operators, the merge iterator requires to distinguish the input records by their producer. <strong>As</strong> an example, for a join operation it does not matter where the input records were created, and all inputs can be accu- mulated in a single input stream. For a merge operation, it is crucial to distinguish the input records by their pro- ducer in order to merge multiple sorted streams correctly.</p>
<p>在并行排序[18]、[21]的实现和基准测试期间，我们添加了另外两个特征来交换。 首先，我们想要实现一个合并网络，其中一些处理器生成排序流，同时由其他处理器进行合并。 Volcano 的排序迭代器可用于生成排序流。 合并迭代器很容易从排序模块中派生出来。 它使用单级合并，而不是排序中使用的级联合并。 合并迭代器的输入是一个交换，与其他运算符不同，合并迭代器需要通过其生产者来区分输入记录。 例如，对于连接操作，输入记录在哪里创建并不重要，所有输入都可以累积在单个输入流中。 对于合并操作，区分输入记录的生产者至关重要，以便正确合并多个排序流。</p>
<p>We modified the <strong>exchange</strong> module such that it can keep the input records separated according to their producers. <strong>A</strong> third argument to <strong>next-exchange</strong> is used to communi- cate the required producer from the <strong>merge</strong> to the <strong>exchange</strong> iterator. Further modifications included increasing the number of input buffers used by <strong>exchange,</strong> the number of semaphores (including for flow control) used between producer and consumer part of <strong>exchange,</strong> and the logic for <strong>end-of-stream.</strong> All these modifications were imple- mented in such a way that they support multilevel merge trees, e.g., a parallel binary merge tree as used in <strong>[3].</strong> The merging paths are selected automatically such that the load is distributed as evenly as possible in each level.</p>
<p>我们修改了交换模块，以便它可以根据输入记录的生产者将输入记录分开。 next-exchange 的第三个参数用于将合并所需的生产者传递给交换迭代器。 进一步的修改包括增加交换使用的输入缓冲区的数量、交换的生产者和消费者部分之间使用的信号量（包括用于流量控制的）数量以及流结束的逻辑。 所有这些修改都是以支持多级合并树的方式实现的，例如[3]中使用的并行二元合并树。 合并路径是自动选择的，以便负载尽可能均匀地分布在每个级别中。</p>
<p>Second, we implemented a sort algorithm that sorts data randomly partitioned (or “striped” [29]) over multiple disks into a range-partitioned file with sorted partitions, i.e., a sorted file distributed over multiple disks. When using the same number of processors and disks, two pro- cesses per CPU were required, one to perform the file scan and partition the records and another one to sort them. Creating and running more processes than proces- sors can inflict a significant cost since these processes compete for the CPU’s and therefore require operating system scheduling.</p>
<p>其次，我们实现了一种排序算法，将多个磁盘上随机分区（或“条带化”[29]）的数据排序为具有排序分区的范围分区文件，即分布在多个磁盘上的排序文件。 当使用相同数量的处理器和磁盘时，每个 CPU 需要两个进程，一个执行文件扫描并对记录进行分区，另一个对记录进行排序。 创建和运行比处理器更多的进程可能会造成巨大的成本，因为这些进程会竞争 CPU，因此需要操作系统调度。</p>
<p>In order to make better use of the available processing power, we decided to redue the number of processes by half, effectively moving to one process per CPU. This required modifications to the exchange operator. Until then, the exchange operator could “live” only at the top or the bottom of the operator tree in a process. Since the modification, the exchange operator can also be in the middle of a process’ operator tree. When the exchange operator is opened, it does not fork any processes but es- tablishes a communication port for data exchange. The next operation requests records from its input tree, pos- sibly sending them off to other processes in the group, until a record for its own partition is found. This mode of operation was termed interchange, and was referred to earlier in the discussion of Fig. 7.</p>
<p>为了更好地利用可用的处理能力，我们决定将进程数量减少一半，有效地改为每个 CPU 一个进程。 这需要对交换运营商进行修改。 在此之前，交换运算符只能“生存”在进程中运算符树的顶部或底部。 修改后，交换运算符也可以位于进程运算符树的中间。 当交换操作符打开时，它不会派生任何进程，而是建立一个用于数据交换的通信端口。 下一个操作从其输入树请求记录，可能将它们发送到组中的其他进程，直到找到其自己的分区的记录。 这种操作模式称为交换，并在前面图 7 的讨论中提到过。</p>
<p>This mode of operation also makes flow control obso- lete. A process runs a producer (and produces input for the other processes) only if it does not have input for the consumer. Therefore, if the producers are in danger of overrunning the consumers, none of the producer opera- tors gets scheduled, and the consumers consume the available records.</p>
<p>这种操作模式也使得流量控制变得过时。 仅当进程没有消费者的输入时，才会运行生产者（并为其他进程生成输入）。 因此，如果生产者面临超出消费者的危险，则不会调度任何生产者操作员，并且消费者会消耗可用记录。</p>
<h4 id="D-File-System-Modijications-修改"><a href="#D-File-System-Modijications-修改" class="headerlink" title="D. File System Modijications 修改"></a><strong>D. File System Modijications</strong> 修改</h4><p>The file system required some modifications to serve several processes concurrently. In order to restrict the ex- tent of such modifications, Volcano currently does not in- clude protection of files and records other than each disk’s volume table of contents. Furthermore, typically nonre- petitive actions like mounting a device must be invoked by the query root process before or after a query is eval- uated by multiple processes.</p>
<p>文件系统需要进行一些修改才能同时服务多个进程。 为了限制此类修改的范围，Volcano 目前不包括对每个磁盘卷内容表之外的文件和记录的保护。 此外，在多个进程评估查询之前或之后，查询根进程必须调用通常的非重复操作（例如安装设备）。</p>
<p>The most intricate changes were required for the <strong>bufer</strong> module. In fact, making sure the buffer manager would not be a bottleneck in a shared-memory machine was an interesting subproject independent of database query pro- cessing [<strong>181.</strong> Concurrency control in the buffer manager was designed to provide a testbed for future research with effective and efficient mechanisms, and not to destroy the separation of policies and mechanisms.</p>
<p>缓冲区模块需要进行最复杂的更改。 事实上，确保缓冲区管理器不会成为共享内存机器中的瓶颈是一个独立于数据库查询处理的有趣的子项目[181。 缓冲区管理器中的并发控制旨在为未来研究提供有效且高效的机制的测试平台，而不是破坏策略和机制的分离。</p>
<p>Using one exclusive lock is the simplest way to protect a buffer pool and its internal data structures. However, decreased concurrency would have removed most or all advantages of parallel query processing. Therefore, the buffer uses a two-level scheme. There is a lock for each buffer pool and one for each descriptor (page or cluster resident in the buffer). The buffer pool lock must be held while searching or updating the hash tables and bucket chains. It is never held while doing <strong>Z&#x2F;O;</strong> thus, it is never held for a long period of time. <strong>A</strong> descriptor or cluster lock must be held while doing <strong>I&#x2F;O</strong> or while updating a descrip- tor in the buffer, e.g., to decrease its fix count.</p>
<p>使用一个独占锁是保护缓冲池及其内部数据结构的最简单方法。 然而，并发性的降低会消除并行查询处理的大部分或全部优势。 因此，缓冲器采用两级方案。 每个缓冲池都有一把锁，每个描述符（驻留在缓冲区中的页或簇）都有一把锁。 在搜索或更新哈希表和桶链时必须持有缓冲池锁。 做 Z&#x2F;O 时绝不会持有它； 因此，它不会被长期持有。 在执行 I&#x2F;O 或更新缓冲区中的描述符时，必须保持描述符或簇锁，例如，为了减少其修复计数。</p>
<p>If a process finds a requested cluster in the buffer, it uses an atomic test-and-lock operation to lock the descrip- tor. If this operation fails, the pool lock is released, the operation delayed and restarted. It is necessary to restart the buffer operation including the hash table lookup be- cause the process that holds the lock might be replacing the requested cluster. Therefore, the requesting process must wait to determine the outcome of the prior operation. Using this restart-scheme for descriptor locks has the ad- ditional benefit of avoiding deadlocks. The four condi- tions for deadlock are mutual exclusion, hold-and-wait no preemption, and circular wait; Volcano’s restart scheme does not satisfy the second condition. On the other hand, starvation is theoretically possible but has become extremely unlikely after buffer modifications that basi- cally eliminated buffer contention.</p>
<p>如果进程在缓冲区中找到请求的簇，它就会使用原子测试和锁定操作来锁定描述符。 如果此操作失败，则释放池锁，操作延迟并重新启动。 有必要重新启动缓冲区操作（包括哈希表查找），因为持有锁的进程可能正在替换所请求的簇。 因此，请求进程必须等待才能确定先前操作的结果。 使用描述符锁的重新启动方案还有避免死锁的额外好处。 死锁的四个条件是互斥、保持等待无抢占、循环等待； Volcano的重启方案不满足第二个条件。 另一方面，饥饿在理论上是可能的，但在缓冲区修改基本上消除了缓冲区争用之后，这种情况变得极不可能发生。</p>
<p>In summary, the exchange module encapsulates paral- lel query processing in Volcano. It provides a large set of mechanisms useful in parallel query evaluation. Only very few changes had to be made in the buffer manager and the other file system modules to accommodate parallel exe- cution. The most important properties of the exchange module are that it implements three forms of parallel pro- cessing within a single module, that it makes parallel query processng entirely self-scheduling, supports a va- riety of policies, e.g., partitioning schemes or packet sizes, and that it did not require any changes in the exist- ing query processing modules, thus leveraging signifi- cantly the time and effort spent on them and allowing easy parallel implementation of new algorithms. It entirely separates data selection, manipulation, derivation, etc. from all parallelism issues, and may therefore prove use- ful in parallelizing other systems, both relational com- mercial and extensible research systems.</p>
<p>总之，交换模块封装了 Volcano 中的并行查询处理。 它提供了大量可用于并行查询评估的机制。 只需对缓冲区管理器和其他文件系统模块进行很少的更改即可适应并行执行。 交换模块最重要的属性是它在单个模块内实现了三种形式的并行处理，它使并行查询处理完全自我调度，支持各种策略，例如分区方案或数据包大小 ，并且它不需要对现有查询处理模块进行任何更改，从而显着地利用在这些模块上花费的时间和精力，并允许轻松并行实现新算法。 它将数据选择、操作、推导等与所有并行问题完全分开，因此可能在并行其他系统（关系商业系统和可扩展研究系统）时有用。</p>
<h3 id="VII-SUMMARAYN-D-CONCLUSIONS"><a href="#VII-SUMMARAYN-D-CONCLUSIONS" class="headerlink" title="VII. SUMMARAYN D CONCLUSIONS"></a>VII. <strong>SUMMAR</strong>A<strong>Y</strong>N D CONCLUSIONS</h3><p>We have described Volcano, a new query evaluation system that combines compactness, efficiency, extensi- bility, and parallelism in a dataflow query evaluation sys- tem. Compactness is achieved by focusing on few general algorithms. For example, the one-to-one match operator implements join, semi-join, our join, anti-join, duplica- tion elimination, aggregation, intersection, union, differ- ence, and anti-difference. Extensibility is achieved by im- plementing only one essential abstraction, streams, and by relying on imported <strong>support functions</strong> for object inter- pretation and manipulation. The details of streams, e.g., type and structure of their elements, are not part of the stream definition and its implementation, and can be de- termined at will, making Volcano a <strong>data-model-inde- pendent set processor.</strong> The separation of set processing control in <strong>iterators</strong> and object interpretation and manip- ulation through support functions contributes significantly to Volcano’s extensibility.</p>
<p>我们描述了 Volcano，一种新的查询评估系统，它在数据流查询评估系统中结合了紧凑性、效率、可扩展性和并行性。 紧凑性是通过关注少数通用算法来实现的。 例如，一对一匹配运算符实现连接、半连接、我们的连接、反连接、重复消除、聚合、交集、并集、差分和反差分。 可扩展性是通过仅实现一种基本抽象（流）并依靠导入的支持函数来进行对象解释和操作来实现的。 流的细节，例如其元素的类型和结构，不是流定义及其实现的一部分，可以随意确定，使 Volcano 成为数据模型独立的集合处理器。 迭代器中的集合处理控制与通过支持函数进行的对象解释和操作的分离极大地提高了 Volcano 的可扩展性。</p>
<p>The Volcano design and implementation was guided by a few simple but generally useful principles. First, Vol- cano implements <strong>mechanisms</strong> to support <strong>policies</strong> that can be determined by a human experimenter or a query opti- mizer. Second, operators are implemented as iterators to allow efficient transfer of data and control within a single process. Third, a uniform operator interface allows for integration of new query processing operators and algo- rithms. Fourth, the interpretation and manipulation of stream elements is consistently left open to allow sup- porting any data model and processing items of any type, shape, and representation. Finally, the encapsulated im- plementation of parallelism allows developing query pro- cessing algorithms in a single-process environment but executing them in parallel. These principles have led to a very flexible, extensible, and powerful query processing engine.</p>
<p>Volcano 的设计和实施遵循一些简单但普遍有用的原则。 首先，Volcano 实现了支持可由人类实验者或查询优化器确定的策略的机制。 其次，运算符被实现为迭代器，以允许在单个进程内有效地传输数据和控制。 第三，统一的运算符接口允许集成新的查询处理运算符和算法。 第四，流元素的解释和操作始终保持开放，以允许支持任何数据模型和处理任何类型、形状和表示的项。 最后，并行性的封装实现允许在单进程环境中开发查询处理算法，但并行执行它们。 这些原则导致了非常灵活、可扩展且强大的查询处理引擎。</p>
<p>Volcano introduces two novel <strong>meta-operators.</strong> Dy- namic query evaluation plans are a new concept intro- duced in [171that allow efficientevaluation of queries with free variables. The <strong>choose-plan</strong> meta-operator at the top of a plan or a subplan makes an efficient decision which alternative plan to use when the plan is invoked. Dynamic plans have the potential of increasing the performance of embedded and repetitive queries significantly.</p>
<p>Volcano 引入了两个新颖的元运算符。 动态查询评估计划是[171]中引入的一个新概念，它允许使用自由变量对查询进行有效评估。 计划或子计划顶部的选择计划元运算符可以有效地决定在调用计划时使用哪个替代计划。 动态计划有可能显着提高嵌入式和重复查询的性能。</p>
<p>Dataflow techniques are used within processes as well as between processes. Within a process, demand-driven dataflow is implemented by means of streams and itera- tors. Streams and iterators represent the most efficient ex- ecution model in terms of time and space for single-pro- cess query evaluation. Between processes, data-driven dataflow is used to pass data between producers and con- sumers efficiently. If necessary, Volcano’s data-driven dataflow can be augmented with flow control or back pressure. Horizontal partitioning can be used both on stored and intermediate datasets to allow intra-operator parallelism. The design of the <strong>exchange</strong> meta-operator encapsulates the parallel execution mechanism for verti- cal, bushy, and intra-operator parallelism, and it performs the translations from demand-driven to data-driven data- flow and back [20].</p>
<p>数据流技术在进程内以及进程之间使用。 在流程中，需求驱动的数据流是通过流和迭代器来实现的。 流和迭代器代表了单进程查询评估的时间和空间上最有效的执行模型。 在进程之间，数据驱动的数据流用于在生产者和消费者之间有效地传递数据。 如有必要，可以通过流量控制或背压来增强 Volcano 的数据驱动数据流。 水平分区可用于存储数据集和中间数据集，以允许运算符内并行性。 交换元操作符的设计封装了垂直、密集和操作符内并行性的并行执行机制，并执行从需求驱动到数据驱动的数据流的转换[20]。</p>
<p>Encapsulating all issues of parallelism control in one operator and thus orthogonalizing data manipulation and parallelism offers important extensibility and portability advantages. All data manipulation operators are shielded from parallelism issues, and have been designed, de- bugged, tuned, and preliminarily evaluated in a single- process environment. To parallelize a new operator, it only has to be combined with the exchange operator in a query evaluation plan. T o port all V olcano operators to a new parallel machine, only the exchange operator re- quires appropriate modifications. At the current time, the exchange operator supports parallelism only on shared- memory machines. We are currently working on extend- ing this operator to support query processing on distrib- uted-memory machines while maintaining its encapsula- tion properties. However, we do not want to give up the advantages of shared memory, namely fast communica- tion and synchronization. <strong>A</strong> recent investigation demon- strated that shared-memory architectures can deliver near- linear speed-up for limited degrees of parallelism; we ob- served a speed-up of 14.9 with 16 CPU’s for parallel sort- ing in Volcano [18]. To combine the bets of both worlds, we are building our software such that it runs on a closely- tied group, e.g., a hypercube or mesh architecture, of shared-memory parallel machines. Once this version of Volcano’s exchange operator and therefore all of Volcano runs on such machines, we can investigate query process- ing on hierarchical architectures and heuristics of how CPU and <strong>U0</strong> power as well as memory can best be placed and exploited in such machines.</p>
<p>将并行控制的所有问题封装在一个运算符中，从而使数据操作和并行正交化，提供了重要的可扩展性和可移植性优势。 所有数据操作运算符都不受并行性问题的影响，并且已在单进程环境中进行设计、调试、调整和初步评估。 要并行化新的运算符，只需将其与查询评估计划中的交换运算符组合即可。 要将所有 Volcano 操作器移植到新的并行机，仅交换操作器需要进行适当的修改。 目前，交换运算符仅在共享内存机器上支持并行性。 我们目前正在努力扩展该运算符以支持分布式内存机器上的查询处理，同时保持其封装属性。 然而，我们不想放弃共享内存的优点，即快速通信和同步。 最近的一项调查表明，共享内存架构可以为有限的并行度提供近线性的加速； 我们观察到在 Volcano 中使用 16 个 CPU 进行并行排序时速度提高了 14.9 [18]。 为了结合两个世界的赌注，我们正在构建我们的软件，使其运行在一个紧密联系的组上，例如共享内存并行机器的超立方体或网状架构。 一旦这个版本的 Volcano 交换运算符以及所有 Volcano 在此类机器上运行，我们就可以研究分层架构上的查询处理以及如何在此类机器中最好地放置和利用 CPU 和 U0 功率以及内存的启发式方法。</p>
<p>Most of today’s parallel machines are built as one of the two extreme cases of this hierarchical design: a dis- tributed-memory machine uses single-CPU nodes, while a shared-memory machine consists of a single node. Soft- ware designed for this hierarchical architecture will run on either conventional design as well as a genuinely hi- erarchical machine, and will allow exploring trade-offs in the range of altematives in between. Thus, the operator model of parallelization also offers the advantage of ar- chitecture- and topology-independent parallel query eval- uation [191.</p>
<p>当今大多数并行机都是作为这种分层设计的两个极端情况之一构建的：分布式内存机器使用单 CPU 节点，而共享内存机器由单个节点组成。 为这种分层架构设计的软件将运行在传统设计以及真正的分层机器上，并且允许探索之间的替代方案范围的权衡。 因此，并行化的运算符模型还提供了独立于架构和拓扑的并行查询评估的优点[191。</p>
<p>A number of features make Volcano an interesting ob- ject for further performance studies. First, the LRU&#x2F;MRU buffer replacement strategy switched by a keep-or-toss hint needs to be evaluated. Second, using clusters of different sizes on a single device and avoiding buffer shuf- fling by allocating buffer space dynamically instead of statically require careful evaluation. Third, the duality and trade-offs between sort- and hash-based query processing algorithms and their implementations will be explored further. Fourth, Volcano allows measuring the perfor- mance of parallel algorithms and identifying bottlenecks on a shared-memory architecture, as demonstrated for in- stance in [ 181. W e intend to perform similar studies on distributed-memory and, as they become available, hier- archical architectures, Fifth, the advantages and disad- vantages of a separate scheduler process in distributed- memory query processing (as used in GAMMA) will be evaluated. Finally, after data-driven dataflow has been shown to work well on a shared-nothing database machine [111, the combination of demand- and data-driven data- flow should be explored on a network on shared-memory computers.</p>
<p>许多特征使 Volcano 成为进一步性能研究的有趣对象。 首先，需要评估由 keep-or-toss 提示切换的 LRU&#x2F;MRU 缓冲区替换策略。 其次，在单个设备上使用不同大小的集群并通过动态而不是静态分配缓冲区空间来避免缓冲区改组需要仔细评估。 第三，将进一步探讨基于排序和基于散列的查询处理算法及其实现之间的二元性和权衡。 第四，Volcano 允许测量并行算法的性能并识别共享内存架构上的瓶颈，如[181]中所示。我们打算对分布式内存进行类似的研究，并且当它们可用时， 第五，将评估分布式内存查询处理（如 GAMMA 中使用的）中单独的调度程序进程的优点和缺点。 最后，在数据驱动的数据流被证明在无共享数据库机器上运行良好之后[111，应该在共享内存计算机的网络上探索需求驱动和数据驱动的数据流的组合。</p>
<p>While Volcano is a working system in its current form, we are considering several extensions and improvements. First, Volcano currently does very extensive error detec- tion, but it does not encapsulate errors in <strong>fail-fast</strong> mod- ules. It would be desirable to modify all modules such that they have all-or-nothing semantics for all requests. This might prove particularly tricky for the exchange module, even more so in a distributed-memory environment. Sec- ond, for a more complete performance evaluation, Vol- cano should be enhanced to a multiuser system that allows inter-query parallelism. Third, to make it a complete data manager and query processor, transactions semantics in- cluding recovery should be added.</p>
<p>虽然 Volcano 是目前形式的工作系统，但我们正在考虑进行一些扩展和改进。 首先，Volcano 目前进行了非常广泛的错误检测，但它没有将错误封装在快速失败模块中。 最好修改所有模块，使它们对所有请求都具有“全有或全无”语义。 这对于交换模块来说可能特别棘手，在分布式内存环境中更是如此。 其次，为了更完整的性能评估，Volcano 应该增强为允许查询间并行的多用户系统。 第三，为了使其成为一个完整的数据管理器和查询处理器，应该添加包括恢复在内的事务语义。</p>
<p>Volcano <strong>is</strong> the first operational query evaluation system that combines extensibility and parallelism. We believe that Volcano is a powerful tool for database systems re- search and education. We are making it available for stu- dent use, e . g . , for implementation and performance stud- ies, and have given copies to selected outside organizations. We intend to use it in a number of further research projects, including research on the optimization and evaluation of dynamic query evaluation plans [ 171 and the REVELATIOpNroject on query optimization and exe- cution in object-oriented database systems with encapsu- lated behavior [151.</p>
<p>Volcano是第一个结合了可扩展性和并行性的操作查询评估系统。 我们相信 Volcano 是数据库系统研究和教育的强大工具。 我们将其提供给学生使用，例如。 G 。 ，用于实施和绩效研究，并向选定的外部组织提供了副本。 我们打算在许多进一步的研究项目中使用它，包括动态查询评估计划的优化和评估的研究[171，以及关于具有封装行为的面向对象数据库系统中的查询优化和执行的REVELATIOpNroject研究[151] 。</p>
<h3 id="ACKNOWLEDGM"><a href="#ACKNOWLEDGM" class="headerlink" title="ACKNOWLEDGM"></a>ACKNOWLEDGM</h3><p>The one-to-one match operators were implemented by Tom Keller starting with existing hash join, hash aggregate, merge join, and sort code. Hash table overflow man- agement was added by Mark Swain. Dynamic query eval- uation plans and the choose-plan operator were designed and implemented by Karen Ward. We are also very much indebted to all members of the GAMMA and EXODUS projects. Leonard Shapiro contributed to the quality and clarity of the exposition with many insightful comments. David DeWitt, Jim Gray, David Maier, Bill McKenna, Marguerite Murphy, and Mike Stonebraker gave very helpful comments on earlier drafts of this paper. The anonymous referees gave some further helpful sugges- tions.</p>
<p>一对一匹配运算符是由 Tom Keller 从现有的哈希连接、哈希聚合、合并连接和排序代码开始实现的。 哈希表溢出管理是由 Mark Swain 添加的。 动态查询评估计划和选择计划运算符由 Karen Ward 设计和实现。 我们也非常感谢 GAMMA 和 EXODUS 项目的所有成员。 伦纳德·夏皮罗 (Leonard Shapiro) 发表了许多富有洞察力的评论，为展览的质量和清晰度做出了贡献。 David DeWitt、Jim Gray、David Maier、Bill McKenna、Marguerite Murphy 和 Mike Stonebraker 对本文的早期草稿给出了非常有帮助的评论。 匿名审稿人还提出了一些进一步的有益建议。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>Real transactions are serializable</title>
    <url>/2023/10/25/2-%E6%95%B0%E6%8D%AE%E5%BA%93/1-cockroachdb/cockroach-blogs/Real%20transactions%20are%20serializable/</url>
    <content><![CDATA[<p>Most databases offer a choice of several transaction isolation levels, offering a tradeoff between correctness and performance. However, that performance comes at a price, as developers must study their transactional interactions carefully or risk introducing subtle bugs. CockroachDB provides strong (“<code>SERIALIZABLE</code>”) isolation by default to ensure that your application always sees the data it expects. In this post I’ll explain what this means and how insufficient isolation impacts real-world applications.</p>
<p>大多数数据库提供多种事务隔离级别的选择，在正确性和性能之间进行权衡。 然而，这种性能是有代价的，因为开发人员必须仔细研究他们的事务交互，否则就有引入微妙错误的风险。 CockroachDB 默认提供强（“可串行化”）隔离，以确保您的应用程序始终看到它期望的数据。 在这篇文章中，我将解释这意味着什么以及隔离不足如何影响实际应用程序。</p>
<span id="more"></span>

<h2 id="Isolation-in-the-SQL-Standard"><a href="#Isolation-in-the-SQL-Standard" class="headerlink" title="Isolation in the SQL Standard"></a>Isolation in the SQL Standard</h2><p>The SQL standard defines four isolation levels:</p>
<ul>
<li><code>SERIALIZABLE</code></li>
<li><code>REPEATABLE READ</code></li>
<li><code>READ COMMITTED</code></li>
<li><code>READ UNCOMMITTED</code></li>
</ul>
<p><code>SERIALIZABLE</code> transactions run <em>as if</em> only one transaction were running at a time; the other isolation levels allow what the SQL standard euphemistically calls “the three phenomena”: dirty reads, non-repeatable reads, and phantom reads. <a href="http://www.cs.umb.edu/cs734/CritiqueANSI_Iso.pdf">Subsequent research</a> has identified additional “phenomena” and isolation levels.</p>
<p>SERIALIZABLE 事务的运行就像一次只有一个事务在运行一样； 其他隔离级别允许 SQL 标准委婉地称为“三种现象”：脏读、不可重复读和幻读。 随后的研究发现了额外的“现象”和隔离级别。</p>
<p>In modern research, these “phenomena” are more commonly called “anomalies”, or more bluntly, <a href="http://hpts.ws/papers//2015/jepsen.pdf">“lies”</a>. When you use a non-<code>SERIALIZABLE</code> isolation level, you’re giving the database permission to return an incorrect answer in the hope that it will be faster than producing the correct one. The SQL standard recognizes that this is dangerous and requires that <code>SERIALIZABLE</code> is the default isolation level. Weaker isolation levels are provided as a potential optimization for applications that can tolerate these anomalies.</p>
<p>在现代研究中，这些“现象”通常被称为“异常”，或者更直白地称为“谎言”。 当您使用非 SERIALIZABLE 隔离级别时，您就授予数据库返回错误答案的权限，希望它比生成正确答案更快。 SQL 标准认识到这是危险的，并要求 SERIALIZABLE 是默认的隔离级别。 提供较弱的隔离级别作为可以容忍这些异常的应用程序的潜在优化。</p>
<h2 id="Isolation-in-Real-Databases"><a href="#Isolation-in-Real-Databases" class="headerlink" title="Isolation in Real Databases"></a>Isolation in Real Databases</h2><p>Most databases ignore the specification that <code>SERIALIZABLE</code> be the default, and instead prioritize performance over safety by defaulting to the weaker <code>READ COMMITTED</code> or <code>REPEATABLE READ</code> isolation levels. More worryingly, some databases (including Oracle, and PostgreSQL prior to version 9.1) do not provide a serializable transaction implementation at all. Oracle’s implementation of the <code>SERIALIZABLE</code> isolation level is actually a weaker mode called “snapshot isolation”.</p>
<p>大多数数据库都会忽略 SERIALIZABLE 为默认值的规范，而是通过默认较弱的 READ COMMITTED 或 REPEATABLE READ 隔离级别来优先考虑性能而非安全性。 更令人担忧的是，一些数据库（包括Oracle和9.1版本之前的PostgreSQL）根本不提供可序列化事务的实现。 Oracle对SERIALIZABLE隔离级别的实现实际上是一种较弱的模式，称为“快照隔离”。</p>
<p>Snapshot isolation was developed after the initial standardization of the SQL language, but has been implemented in multiple database systems because it provides a good balance of performance and consistency. It is stronger than <code>READ COMMITTED</code> but weaker than <code>SERIALIZABLE</code>. It is similar to <code>REPEATABLE READ</code> but not exactly equivalent (<code>REPEATABLE READ</code> permits phantom reads but prevents write skew, while the reverse is true of snapshot isolation). The databases that have implemented snapshot isolation have made different decisions about how to fit it into the four SQL standard levels. Oracle takes the most aggressive stance, calling their snapshot implementation <code>SERIALIZABLE</code>. CockroachDB and Microsoft SQL Server are conservative and treat <code>SNAPSHOT</code> as a separate fifth isolation level. PostgreSQL (since version 9.1) falls in between, using snapshot isolation in place of <code>REPEATABLE READ</code>.</p>
<p>快照隔离是在 SQL 语言最初标准化之后开发的，但由于它提供了性能和一致性的良好平衡，已在多个数据库系统中实现。 它比 READ COMMITTED 强，但比 SERIALIZABLE 弱。 它与 REPEATABLE READ 类似，但并不完全相同（REPEATABLE READ 允许幻读，但防止写入倾斜，而快照隔离则相反）。 已经实现快照隔离的数据库对于如何将其适应四个 SQL 标准级别做出了不同的决定。 Oracle 采取了最激进的立场，称他们的快照实现是可串行化的。 CockroachDB 和 Microsoft SQL Server 比较保守，将 SNAPSHOT 视为单独的第五个隔离级别。 PostgreSQL（自版本 9.1 起）介于两者之间，使用快照隔离代替可重复读取。</p>
<p>Because serializable mode is used less often in databases that default to weaker isolation, it is often less thoroughly tested or optimized. For example, PostgreSQL has a fixed-size memory pool that it uses to track conflicts between serializable transactions, which can be exhausted under heavy load.</p>
<p>由于可序列化模式在默认隔离较弱的数据库中使用较少，因此通常没有经过彻底的测试或优化。 例如，PostgreSQL 有一个固定大小的内存池，用于跟踪可序列化事务之间的冲突，这些冲突在重负载下可能会耗尽。</p>
<p>Most database vendors treat stronger transaction isolation as an exotic option to be enabled by applications with exceptional consistency needs. Most applications, however, are expected to work with the faster but unsafe weak isolation modes. This backwards approach to the problem exposes applications to a variety of subtle bugs. At Cockroach Labs, we like thinking about transactional anomalies so much that we named all our conference rooms after them, but I would have a hard time advising with confidence when it is both safe and beneficial to choose <code>SNAPSHOT</code> isolation instead of <code>SERIALIZABLE</code>. Our philosophy is that it’s better to start with safety and work towards performance than the other way around.</p>
<p>大多数数据库供应商将更强的事务隔离视为一种奇特的选项，由具有特殊一致性需求的应用程序启用。 然而，大多数应用程序都希望使用更快但不安全的弱隔离模式。 这种向后解决问题的方法使应用程序面临各种微妙的错误。 在 Cockroach Labs，我们非常喜欢考虑事务异常，因此我们以它们的名字命名了所有会议室，但当选择快照隔离而不是串行隔离既安全又有益时，我很难充满信心地提出建议。 我们的理念是，最好从安全开始，努力提高性能，而不是相反。</p>
<h2 id="ACIDRain-Finding-Transactional-Bugs"><a href="#ACIDRain-Finding-Transactional-Bugs" class="headerlink" title="ACIDRain: Finding Transactional Bugs"></a>ACIDRain: Finding Transactional Bugs</h2><p><a href="http://www.bailis.org/papers/acidrain-sigmod2017.pdf">Recent research at Stanford</a> has explored the degree to which weak isolation leads to real-world bugs. Todd Warszawski and Peter Bailis examined 12 eCommerce applications and found 22 bugs related to transactions, five of which would have been avoided by running at a higher isolation level. Many of these bugs were simple to exploit and had direct financial implications. For example, in five of the tested applications, adding an item to your cart while checking out in another browser tab could result in the item being added to the order for free. The researchers developed tools to identify these vulnerabilities in a semi-automated way, paving the way for similar attacks (which the researchers dubbed “ACIDRain”) to become more prevalent.</p>
<p>斯坦福大学最近的研究探讨了弱隔离导致现实世界错误的程度。 Todd Warszawski 和 Peter Bailis 检查了 12 个电子商务应用程序，发现了 22 个与事务相关的错误，其中 5 个错误可以通过在更高的隔离级别运行来避免。 其中许多错误很容易被利用，并且会产生直接的财务影响。 例如，在五个测试的应用程序中，在另一个浏览器选项卡中结帐时将商品添加到购物车可能会导致该商品免费添加到订单中。 研究人员开发了工具以半自动方式识别这些漏洞，为类似攻击（研究人员称之为“ACIDRain”）变得更加普遍铺平了道路。</p>
<p>Most databases that default to weak transactional isolation provide workarounds, such as the (non-standard) <code>FOR UPDATE</code> and <code>LOCK IN SHARE MODE</code> modifiers for <code>SELECT</code> statements. When used correctly, these modifiers can make transactions safe even in weaker isolation levels. However, this is easy to get wrong, and even when used consistently these extensions introduce most of the downsides of <code>SERIALIZABLE</code> mode (in fact, overuse of <code>SELECT FOR UPDATE</code> in a <code>READ COMMITTED</code> transaction can perform worse than a <code>SERIALIZABLE</code> transaction, because it uses exclusive locks where serializability may only require shared locks). The ACIDRain research demonstrates the limitations of this technique: only one in three of the applications that attempted to use <code>SELECT FOR UPDATE</code> feature did so correctly; the others remained vulnerable.</p>
<p>大多数默认为弱事务隔离的数据库都提供了解决方法，例如 SELECT 语句的（非标准）FOR UPDATE 和 LOCK IN SHARE MODE 修饰符。 如果正确使用，这些修饰符即使在较弱的隔离级别下也可以使事务安全。 然而，这很容易出错，即使一致使用，这些扩展也会引入 SERIALIZABLE 模式的大部分缺点（事实上，在 READ COMMITTED 事务中过度使用 SELECT FOR UPDATE 的性能可能比 SERIALIZABLE 事务更差，因为它使用独占模式） 可串行化可能只需要共享锁的锁）。 ACIDRain 研究表明了该技术的局限性：尝试使用 SELECT FOR UPDATE 功能的应用程序中只有三分之一正确执行了操作； 其他人仍然很脆弱。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Databases that encourage the use of weaker isolation levels have prioritized performance over the safety of your data, leaving you to study subtle interactions between your transactions and implement error-prone workarounds. CockroachDB provides <code>SERIALIZABLE</code> transactions by default to ensure that you always see the consistency that you expect from a transactional database.</p>
<p>鼓励使用较弱隔离级别的数据库将性能置于数据安全之上，让您可以研究事务之间的微妙交互并实施容易出错的解决方法。 CockroachDB 默认提供 SERIALIZABLE 事务，以确保您始终看到事务数据库所期望的一致性。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title>CockroachDB&#39;s consistency model</title>
    <url>/2023/10/25/2-%E6%95%B0%E6%8D%AE%E5%BA%93/1-cockroachdb/cockroach-blogs/CockroachDB&#39;s%20consistency%20model/</url>
    <content><![CDATA[<p>原文链接 <a href="https://www.cockroachlabs.com/blog/consistency-model/">https://www.cockroachlabs.com/blog/consistency-model/</a></p>
<p>A few days ago, prompted by a Hacker News post, my friend Ivo texted me saying “<em>Does your head ever explode when you’re thinking about databases and consistency semantics and whatever models? It just sounds like pointless taxonomy stuff. We are &lt;N, K&gt;-serializable whereas QuinoaDB is only ü-serializable</em>”. The answer is yes — my head does explode. I don’t think it’s pointless, though, although I agree that the discussions are generally unproductive.</p>
<p>几天前，在黑客新闻帖子的推动下，我的朋友 Ivo 给我发短信说：“当你思考数据库、一致性语义和任何模型时，你的头是否曾经爆炸过？ 这听起来像是毫无意义的分类学东西。 我们是&lt;N, K&gt;-可序列化的，而QuinoaDB仅是ü-可序列化的”。 答案是肯定的——我的头确实爆炸了。 不过，我不认为这是毫无意义的，尽管我同意讨论通常没有成果。</p>
<span id="more"></span>

<p>Separately, the other day a colleague told a user that “CockroachDB implements serializability, not linearizability”. While we say this statement often, and it is the best kind of correct, I don’t like it much because I think it doesn’t do us justice and it’s also not particularly helpful for the users — it doesn’t teach them very much about CockroachDB.</p>
<p>另外，有一天，一位同事告诉用户“CockroachDB 实现了可序列化，而不是线性化”。 虽然我们经常说这句话，而且它是最好的正确说法，但我不太喜欢它，因为我认为它对我们不公平，而且对用户也不是特别有帮助——它并没有教会他们太多 关于 CockroachDB 的更多信息。</p>
<p>In this post, I’m attempting to present the guarantees that CockroachDB gives and the ones it doesn’t, and offer my preferred marketing slogan summarizing it all.</p>
<p>The first section provides background and some terminology for consistency models to support the following, CockroachDB-specific section. It’s not formal, rigorous or exhaustive (I link to better sources, though) so readers who are familiar with these things might want to skip it and head straight to the section on CockroachDB’s consistency model.</p>
<p>在这篇文章中，我试图介绍 CockroachDB 提供的保证和它没有提供的保证，并提供我最喜欢的营销口号来总结这一切。</p>
<p>第一部分提供一致性模型的背景和一些术语，以支持以下特定于 CockroachDB 的部分。 它不是正式的、严格的或详尽的（不过，我链接到了更好的资源），因此熟悉这些内容的读者可能想跳过它，直接阅读 CockroachDB 一致性模型的部分。</p>
<h2 id="A-summary-of-database-consistency-models"><a href="#A-summary-of-database-consistency-models" class="headerlink" title="A summary of database consistency models"></a>A summary of database consistency models</h2><p>数据库一致性模型总结</p>
<p>First of all, a brief introduction to what we’re talking about. Databases let many “clients” access data concurrently, and so they need to define the semantics of these concurrent accesses: for example, what happens if two clients read and write the same data “at the same time”. Moreover, distributed and replicated databases generally store multiple copies of the data, usually over a network of machines, and so they need to define what complications can arise from the fact that different machines are involved in serving reads and writes to the same data: e.g. if I tell machine A to write a key, and then immediately after I ask machine B to read it, will machine B return the data that had been just written? Informally speaking, what we’d ideally want from our database is to hide the data distribution and replication from us and to behave as if all transactions were being run one at a time by a single machine. A database that provides this kind of execution is said to implement the “strict serializability” consistency model - that’s the holy grail.</p>
<p>首先，简单介绍一下我们正在谈论的内容。 数据库允许许多“客户端”并发访问数据，因此需要定义这些并发访问的语义：例如，如果两个客户端“同时”读取和写入相同的数据会发生什么。 此外，分布式和复制数据库通常通过机器网络存储数据的多个副本，因此它们需要定义不同机器参与对相同数据的读取和写入服务这一事实可能会产生哪些复杂性：例如 如果我告诉机器A写入一个密钥，然后我让机器B读取它后，机器B会立即返回刚刚写入的数据吗？ 通俗地说，我们理想的情况是对数据库隐藏数据分布和复制，并且表现得好像所有事务都由一台机器一次运行一个。 提供这种执行的数据库据说可以实现“严格可串行化”一致性模型 - 这是圣杯。</p>
<p>But, of course, we also want our database to be resilient to machine failure, and we want the transactions to execute fast, and we want many transactions to execute at the same time, and we want data for European customers to be served from European servers and not cross an ocean network link. All these requirements generally come in conflict with strict serializability. So then databases start relaxing the strict serializability guarantees, basically compromising on that front to get execution speed and other benefits. These compromises need precise language for explaining them. For example, consider a replicated database and a write operation executed by one of the replicas followed quickly by a read operation served by another one. What are admissible results for this read? Under strict serializability, the answer is clear — only the value of the preceding write is acceptable. Under more relaxed models, more values are allowed in addition to this one. But which values exactly? Is a random value coming out of thin air acceptable? Generally, no. Is the value of some other relatively recent write acceptable? Perhaps. To define things precisely, we need specialized vocabulary that’s used by well studied sets of rules (called “consistency models”).</p>
<p>但是，当然，我们也希望我们的数据库能够适应机器故障，我们希望事务能够快速执行，我们希望许多事务同时执行，我们希望欧洲客户的数据能够从欧洲提供 服务器而不是跨越海洋的网络链接。 所有这些要求通常与严格的可串行性相冲突。 因此，数据库开始放松严格的可串行性保证，基本上在这方面做出妥协以获得执行速度和其他好处。 这些妥协需要精确的语言来解释。 例如，考虑一个复制数据库，其中一个副本执行写入操作，然后很快由另一个副本执行读取操作。 这次阅读的可接受结果是什么？ 在严格的可串行性下，答案很明确——只有前面写入的值是可接受的。 在更宽松的模型下，除此之外还允许更多值。 但究竟是哪个值呢？ 凭空产生的随机值可以接受吗？ 一般来说，不会。 其他一些相对较新的写入的值是否可以接受？ 也许。 为了精确地定义事物，我们需要经过深入研究的规则集（称为“一致性模型”）使用的专门词汇。</p>
<p>Historically, both the distributed systems community and the databases community have evolved their own terminology and models for consistency. In more recent years, the communities have joined, driven by the advent of “distributed databases”, and the vocabularies have combined. Things are tricky though, plus different databases try to market themselves the best way they can, and so I think it’s fair to say that there’s a lot of confusion on the topic. I’ve been thinking about these things for a couple of years now in the context of CockroachDB, and I still always struggle to make unequivocal and clear statements on the subject. Additionally, I’ll argue that none of the standard lexicon describes CockroachDB very well. For a more systematic treaty on the different meanings of consistency, see <a href="https://pdfs.semanticscholar.org/8d67/a8f90586e3c074a60a871a210785ee61c43e.pdf">The many faces of consistency</a> and <a href="https://jepsen.io/consistency">Jepsen’s treatment of the topic</a>.</p>
<p>从历史上看，分布式系统社区和数据库社区都发展了自己的术语和模型以实现一致性。 近年来，在“分布式数据库”出现的推动下，社区加入了，词汇也合并了。 但事情很棘手，加上不同的数据库试图以最好的方式推销自己，所以我认为可以公平地说，这个话题存在很多混乱。 几年来，我一直在 CockroachDB 的背景下思考这些事情，但我仍然很难就这个主题做出明确而清晰的陈述。 此外，我认为没有一个标准词典能够很好地描述 CockroachDB。 有关一致性的不同含义的更系统的条约，请参阅一致性的许多方面和杰普森对该主题的处理。</p>
<h2 id="Transaction-isolation-levels-and-serializability"><a href="#Transaction-isolation-levels-and-serializability" class="headerlink" title="Transaction isolation levels and serializability"></a>Transaction isolation levels and serializability</h2><p>事务隔离级别和可串行性</p>
<p>The databases community has been describing behavior in terms of <em><em>transactions</em></em>, which are composite operations (made up of SQL queries). Transactions are subject to the ACID properties (<strong>A</strong>tomicity, <strong>C</strong>onsistency, <strong>I</strong>solation, <strong>D</strong>urability). This community was primarily interested in the behavior of concurrent transactions on a single server, not so much in the interactions with data replication — it was thus initially not concerned by the historical issues around distributed consistency. For our discussion, the <strong>I</strong>solation property is the relevant one: we have multiple transactions accessing the same data concurrently and we need them to be isolated from each other. Each one needs to behave, to the greatest extent possible, as if no other transaction was interfering with it. Ironically, the <strong>C</strong>onsistency in ACID refers to a concept that’s only tangentially related to what we’re talking about here — the fact that the database will keep indexes up to date automatically and will enforce foreign key constraints and such.</p>
<p>数据库社区一直用_事务_来描述行为，事务是复合操作（由 SQL 查询组成）。 事务受 ACID 属性（原子性、一致性、隔离性、持久性）的约束。 该社区主要对单个服务器上并发事务的行为感兴趣，而不是与数据复制的交互 - 因此它最初并不关心分布式一致性的历史问题。 对于我们的讨论，隔离属性是相关的：我们有多个事务同时访问相同的数据，并且我们需要它们彼此隔离。 每个交易都需要尽最大可能表现得好像没有其他交易干扰它一样。 讽刺的是，ACID 中的一致性指的是一个与我们这里讨论的内容无关的概念——数据库将自动保持索引最新并强制执行外键约束等事实。</p>
<p>To describe the possible degrees of transaction isolation, the literature and the ANSI standard enumerates a list of possible “anomalies” (examples of imperfect isolation), and, based on those, defines a couple of standard “isolation levels”: Read Uncommitted, Read Committed, Repeatable Read, Serializable. To give a flavor of what these are about, for example the Repeatable Read isolation level says that once a transaction has read some data, reading it again within the same transaction yields the same results. So, concurrent transactions modifying that data have to somehow not affect the execution of our reading transaction. However, this isolation level allows the Phantom Read anomaly. Basically, if a transaction performs a query asking for rows matching a condition twice, the second execution might return more rows than the first. For example, something like <code>select * from orders where value &gt; 1000</code> might return orders (a, b, c) the first time and (a, b, c, d) the second time (which is ironic given Repeatable Read’s name since one might call what just happened a non-repeatable read).</p>
<p>为了描述事务隔离的可能程度，文献和 ANSI 标准列举了一系列可能的“异常”（不完美隔离的示例），并在此基础上定义了几个标准“隔离级别”：读未提交、读 提交、可重复读取、可序列化。 为了说明这些内容的含义，例如可重复读取隔离级别表示，一旦事务读取了某些数据，在同一事务中再次读取它会产生相同的结果。 因此，修改该数据的并发事务必须以某种方式不影响我们读取事务的执行。 然而，此隔离级别允许幻读异常。 基本上，如果事务执行两次查询，要求匹配条件的行，则第二次执行可能会返回比第一次更多的行。 例如，像 select * from orders where value &gt; 1000 这样的东西可能会第一次返回订单 (a, b, c) ，第二次返回 (a, b, c, d) （鉴于可重复读取的名称，这很讽刺，因为可能会 将刚刚发生的事情称为不可重复读取）。</p>
<p>Frankly, the definitions of the ANSI isolation levels are terrible (also see <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf">A Critique of ANSI SQL Isolation Levels</a>), arguably with the exception of the Serializable one. They have been defined narrow-mindedly with a couple of database implementations in mind and have not stood the test of time.</p>
<p>坦率地说，ANSI 隔离级别的定义非常糟糕（另请参阅《ANSI SQL 隔离级别批判》），可以说除了 Serialized 隔离级别之外。 它们的定义是狭隘的，只考虑了几种数据库实现，并且没有经受住时间的考验。</p>
<p>The <a href="https://www.cockroachlabs.com/blog/acid-rain/">Serializable isolation</a> level, which, as far as the SQL standard is concerned, is the gold standard, doesn’t allow any of the defined anomalies. In plain terms, it states that the database needs to ensure that transactions need to behave <em>as if</em> the transactions executed sequentially, one by one. The definition allows that database to choose the order of transactions in an equivalent sequential execution. This is less than ideal because it allows for the following scenario:</p>
<p>就 SQL 标准而言，可序列化隔离级别是黄金标准，不允许任何已定义的异常。 简单来说，它指出数据库需要确保事务的行为就像事务逐一按顺序执行一样。 该定义允许数据库选择等效顺序执行中的事务顺序。 这不太理想，因为它允许出现以下情况：</p>
<h3 id="HN1"><a href="#HN1" class="headerlink" title="HN1:"></a>HN1:</h3><p>We consider three transactions. The first one is <code>insert into hacker_news_comments (id, parent_id, text) values (1, NULL, &#39;a root comment&#39;)</code>. The second one is <code>insert into hacker_news_comments (id, parent_id, text) values (2, 1, &#39;OP is wrong&#39;)</code>. The third one is <code>select id, text from comments</code>.</p>
<p>我们考虑三个事务。 </p>
<p>第一个是 <code>insert into hacker_news_comments (id, parent_id, text) values (1, NULL, &#39;a root comment&#39;)</code>. </p>
<p>第二个是 <code>insert into hacker_news_comments (id, parent_id, text) values (2, 1, &#39;OP is wrong&#39;)</code>. </p>
<p>第三个是 <code>select id, text from comments</code>.</p>
<ul>
<li>I run transaction one.  我运行第一个</li>
<li>I yell across the room to my friend Tobi who’s just waiting to reply to my threads. 我在房间的lingg</li>
<li>Tobi runs transaction 2. Tobi 运行第二个</li>
<li>We then tell our friend Nathan to stop what he’s doing and read our thread.</li>
<li>He runs transaction 3 and gets a single result: <code>(2, &#39;OP is wrong&#39;)</code>.</li>
</ul>
<p>So, Nathan is seeing the response, but not the original post. That’s not good. And yet, it is allowed by the Serializable isolation level and, in fact, likely to occur in many distributed databases (spoiler alert: not in CRDB), assuming the actors were quick to yell at each other and run their transactions. The serial order in which the transactions appear to have executed is 2, 3, 1.</p>
<p>因此，Nathan 看到的是回复，而不是原始帖子。 这不好。 然而，它是可序列化隔离级别所允许的，并且事实上，它很可能发生在许多分布式数据库中（剧透警报：不在 CRDB 中），假设参与者很快就会互相大喊大叫并运行他们的事务。 事务执行的顺序是 2、3、1。</p>
<p>What has happened here is that the actors synchronized with each other outside of the database and expected the database’s ordering of transactions to respect “real time”, but the isolation levels don’t talk about “real time” at all. This seems to not have been a concern for the SQL standardization committee at the time, probably since this kind of thing simply wouldn’t happen if the database software runs entirely on one machine (however many database researchers were thinking about the issues of distributed databases as early as the 70s–for example, see <a href="https://www.cs.purdue.edu/homes/bb/cs542-06Spr-bb/SCDU-Papa-79.pdf">Papadimitriou paper on serializability</a>).</p>
<p>这里发生的情况是，参与者在数据库外部相互同步，并期望数据库的事务排序尊重“实时”，但隔离级别根本不谈论“实时”。 这似乎并不是当时 SQL 标准化委员会所关心的问题，可能是因为如果数据库软件完全运行在一台机器上，这种事情根本就不会发生（然而许多数据库研究人员正在考虑分布式数据库的问题） 早在 70 年代，例如，请参阅 Papadimitriou 关于可序列化性的论文）。</p>
<h2 id="Distributed-systems-and-linearizability"><a href="#Distributed-systems-and-linearizability" class="headerlink" title="Distributed systems and linearizability"></a>Distributed systems and linearizability</h2><p>分布式系统和线性化</p>
<p>While database people were concerned with transaction isolation, researchers in distributed and parallel systems were concerned with the effects of having multiple copies of data on the system’s operations. In particular, they were concerned with the semantics of “read” and “write” operations on this replicated data. So, the literature evolved a set of operation “consistency levels”, with names like “read your own writes”, “monotonic reads”, “bounded staleness”, “causal consistency”, and “linearizable” which all give guidance about what values a read operation can return under different circumstances. The original two problems in need of solutions were how to resolve concurrent writes to the same logical address from two writers at separate physical locations using local replicas (CPUs on their local cache, NFS clients on their local copy), and when&#x2F;how a stale copy should be updated (cache invalidation). The spectrum of possible solutions has been explored in different ways by the original communities: designers of memory caches were constrained by much tighter demands of programmers on consistency, whereas networked filesystems were constrained by unreliable networks to err on the side of more availability.</p>
<p>数据库人员关心事务隔离，而分布式并行系统的研究人员则关心拥有多个数据副本对系统操作的影响。 特别是，他们关心对此复制数据的“读”和“写”操作的语义。 因此，文献发展了一套操作“一致性级别”，其名称包括“读取自己的写入”、“单调读取”、“有界陈旧性”、“因果一致性”和“线性化”，这些名称都为什么值提供了指导 读操作可以在不同情况下返回。 最初需要解决的两个问题是如何使用本地副本（本地缓存上的 CPU、本地副本上的 NFS 客户端）解决来自不同物理位置的两个写入器对同一逻辑地址的并发写入，以及何时&#x2F;如何处理过时的问题。 应更新副本（缓存失效）。 最初的社区已经以不同的方式探索了一系列可能的解决方案：内存缓存的设计者受到程序员对一致性的更严格要求的限制，而网络文件系统则受到不可靠网络的限制，从而在更高的可用性方面犯了错误。</p>
<p>Generally speaking, this evolutionary branch of consistency models doesn’t talk about transactions. Instead, systems are modeled as collections of objects, with each object defining a set of operations it supports. For example, assuming we have a key-value store that provides the operations read(k) and write(k,v), the system obeys the “monotonic reads” model if, once a process reads the value of a key k, any successive read operation on k by that process will always return that same value or a more recent value. In other words, reads by any one process don’t “go backwards”.</p>
<p>一般来说，一致性模型的这一演化分支不涉及事务。 相反，系统被建模为对象的集合，每个对象定义它支持的一组操作。 例如，假设我们有一个提供 read(k) 和 write(k,v) 操作的键值存储，则系统遵循“单调读取”模型，如果进程读取键 k 的值，则任何 该进程对 k 的连续读取操作将始终返回相同的值或更新的值。 换句话说，任何一个进程的读取都不会“倒退”。</p>
<p>There’s two things to note about this model’s definition: first of all, it talks about a “process”, so the system has a notion of different threads of control. Understanding this is a burden; the serializable isolation level we discussed in the databases context did not need such a concept<a href="https://www.cockroachlabs.com/blog/consistency-model/#fn:1">1</a> — the user of a system did not need to think about what process is performing what operations. Second, this model is quite relaxed in comparison to others. If one process performs a write(“a”, 1) and later another process performs read(“a”) (and there’s no intervening writes to “a”), then the read might not return 1. The monotonic reads model describes various distributed systems where data is replicated asynchronously and multiple replicas can all serve reads.</p>
<p>这个模型的定义有两点需要注意：首先，它讨论的是“进程”，因此系统有不同控制线程的概念。 理解这一点是一种负担； 我们在数据库上下文中讨论的可序列化隔离级别不需要这样的概念1——系统的用户不需要考虑哪个进程正在执行什么操作。 其次，与其他模型相比，该模型相当宽松。 如果一个进程执行 write(“a”, 1)，然后另一个进程执行 read(“a”)（并且没有中间写入“a”），则读取可能不会返回 1。单调读取模型描述了各种 分布式系统，其中数据异步复制并且多个副本都可以提供读取服务。</p>
<p>The gold standard among these models is linearizability. It was <a href="https://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf">formalized by Herlihy and Wing in a delightful paper</a>.</p>
<p>这些模型的黄金标准是线性化。 Herlihy 和 Wing 在一篇令人愉快的论文中将其正式化。</p>
<p>This model aims to describe systems with properties pretty similar to the ones guaranteed for database transactions by the Serializable isolation level. Informally, it says that operations will behave as if they were executed one at a time, and an operation that finished before another one began (according to “real time”) has to execute before the second one. This model, assuming systems can actually implement it efficiently, sounds really good. Let’s definite it more formally.</p>
<p>该模型旨在描述具有与可序列化隔离级别保证数据库事务的属性非常相似的系统。 非正式地，它表示操作的行为就像一次执行一个操作，并且在另一个操作开始之前完成的操作（根据“实时”）必须在第二个操作之前执行。 这个模型，假设系统实际上可以有效地实现它，听起来确实不错。 让我们更正式地确定它。</p>
<p>Usually, linearizability is defined at the level of a single, relatively simple “object” and then expanded to the level of a system comprised of many such objects. So, we have an object that affords a couple of operations, and we want to devise a set of rules for how these operations behave. An operation is modeled as an “invocation” (from a client to the object) followed by a “response” (from the object to the client). We’re talking in a concurrent setting, where many clients are interacting with a single object concurrently. We define a “history” to be a set of invocations and responses.</p>
<p>通常，线性化是在单个相对简单的“对象”级别上定义的，然后扩展到由许多此类对象组成的系统级别。 因此，我们有一个提供几个操作的对象，并且我们希望为这些操作的行为方式设计一组规则。 操作被建模为“调用”（从客户端到对象），然后是“响应”（从对象到客户端）。 我们正在讨论并发环境，其中许多客户端同时与单个对象交互。 我们将“历史”定义为一组调用和响应。</p>
<p>For example, say our object is a FIFO queue (providing the enqueue&#x2F;dequeue operations). Then a history might be something like:</p>
<p>例如，假设我们的对象是一个 FIFO 队列（提供入队&#x2F;出队操作）。 那么历史可能是这样的：</p>
<p><strong>H1:</strong></p>
<p>client 1: enqueue “foo”<br>client 1: ok<br>client 1: dequeue<br>client 1: ok (“foo”)<br>client 1: enqueue “bar”<br>client 2: enqueue “baz”<br>client 1: ok<br>client 2: ok<br>client 1: dequeue<br>client 1: ok (“baz”)</p>
<p>The first event in this history is an invocation by client 1, the second one is the corresponding response from the queue object. Responses for dequeue operations are annotated with the element they return.</p>
<p>该历史记录中的第一个事件是客户端 1 的调用，第二个事件是来自队列对象的相应响应。 出队操作的响应用它们返回的元素进行注释。</p>
<p>We say that a given history is “sequential” if every invocation is immediately followed by a response. H1 is not sequential since it contains, for example, this interleaving of operations:</p>
<p>如果每次调用后都立即有响应，我们就说给定的历史是“顺序的”。 H1 不是连续的，因为它包含例如以下操作的交错：</p>
<p>client 1: enqueue “bar”<br>client 2: enqueue “baz”</p>
<p>Sequential histories are easy to reason about and check for validity (e.g. whether or not our FIFO queue is indeed FIFO). Since H1 is not sequential, it’s a bit hard to say whether the last response client 1 got is copacetic. Here’s where we use linearizability: we say that a history H is linearizable if it is <em>equivalent</em> to some valid sequential history H’, where H’ contains the same events, possibly reorderdered under the constraint that, if a response op1 appears before an invocation op2 in H, then this order is preserved in H’. In other words, a history is linearizable if all the responses are valid according to a sequential reordering that preserves the order of non-overlapping responses.</p>
<p>顺序历史很容易推理和检查有效性（例如，我们的 FIFO 队列是否确实是 FIFO）。 由于 H1 不是连续的，所以很难说客户端 1 最后得到的响应是否一致。 这里是我们使用线性化的地方：我们说历史 H 是线性化的，如果它“等价”于某个有效的顺序历史 H’，其中 H’ 包含相同的事件，可能在以下约束下重新排序：如果响应 op1 出现在 H 中的调用 op2 之前，则 该顺序保留在 H’ 中。 换句话说，如果所有响应根据保留非重叠响应顺序的顺序重新排序都是有效的，则历史是可线性化的。</p>
<p>For example, H1 is in fact linearizable because it’s equivalent to the following sequential history:</p>
<p>例如，H1 实际上是可线性化的，因为它相当于以下顺序历史：</p>
<p>client 1: enqueue “foo”<br>client 1: ok<br>client 1: dequeue<br>client 1: ok (“foo”)<br>client 2: enqueue “baz”<br>client 2: ok<br>client 1: enqueue “bar”<br>client 1: ok<br>client 1: dequeue<br>client 1: ok (“baz”)</p>
<p>Now, an object is said to be linearizable if all the histories it produces are linearizable. In other words, no matter how the clients bombard our queue with requests concurrently, the results need to look as if the requests came one by one. If the queue is to claim linearizability, the implementation should use internal locking, or whatever it needs to do, to make this guarantee. Note that this model does not explicitly talk about replication, but the cases where it is of value are primarily systems with replicated state. If our queue is replicated across many machines, and clients talk to all of them for performing operations, “using internal locking” is not trivial but has to somehow be done if we want linearizability.</p>
<p>现在，如果一个对象产生的所有历史都是可线性化的，则称该对象是可线性化的。 换句话说，无论客户端如何并发地用请求轰炸我们的队列，结果都需要看起来像是请求是一个接一个地到来的。 如果队列要求线性化，则实现应使用内部锁定或任何需要执行的操作来保证这一点。 请注意，该模型没有明确讨论复制，但它有价值的情况主要是具有复制状态的系统。 如果我们的队列在许多机器上复制，并且客户端与所有机器通信以执行操作，那么“使用内部锁定”并不是微不足道的，但如果我们想要线性化，就必须以某种方式完成。</p>
<p>To raise the level of abstraction, a whole system is said to be linearizable if it can be modeled as a set of linearizable objects. Linearizability has this nice “local” property: it can be composed like that. So, for example, a key-value store that offers point reads and point writes can be modeled as a collection of registers, with each register offering a read and write operation. If the registers individually provide linearizability, then the store as a whole also does.</p>
<p>为了提高抽象级别，如果整个系统可以建模为一组可线性化对象，则称其为可线性化的。 线性化具有这个很好的“局部”属性：它可以这样组合。 因此，例如，提供点读取和点写入的键值存储可以建模为寄存器的集合，每个寄存器提供读取和写入操作。 如果寄存器单独提供线性化能力，那么存储作为一个整体也能提供线性化能力。</p>
<p>Two things are of note about the linearizable consistency model:</p>
<p>关于线性化一致性模型有两点值得注意：</p>
<p>First, there is a notion of “real time” used implicitly. Everybody is able to look at one clock on the wall so that it can be judged which operation finishes before another operation begins. The order of operations in our linearizable histories has a relation with the time indicated by this mythical clock.</p>
<p>首先，隐含地使用了“实时”的概念。 每个人都可以看着墙上的一个时钟，从而可以判断哪一个操作在另一操作开始之前完成。 我们线性化历史中的运算顺序与这个神话时钟所指示的时间有关。</p>
<p>Second, concurrent operations are allowed to execute in any order. For example, in our history H1, the last event might have been</p>
<p>其次，允许并发操作以任何顺序执行。 例如，在我们的历史 H1 中，最后一个事件可能是</p>
<p>client 1: ok (“bar”) because a serial history where enqueuing baz finishes before enqueuing baz begins would also have been acceptable.</p>
<p>client 1: ok (“bar”)，因为在 enqueuing baz 开始之前 enqueuing baz 完成的串行历史也是可以接受的。</p>
<p>It’s worth reminding ourselves that linearizability does not talk about transactions, so this model by itself is not well suited to be used by SQL databases. I guess one could shoehorn it by saying that the whole database is one object which provides one transaction operation, but then a definition needs to be provided for the functional specifications of this operation. We’re getting back to the ACID properties and the transaction isolation levels, and I’m not sure how the formalism would work exactly.</p>
<p>值得提醒我们的是，线性化不涉及事务，因此该模型本身不太适合 SQL 数据库使用。 我想人们可以通过说整个数据库是一个提供一个事务操作的对象来硬塞它，但随后需要为该操作的功能规范提供一个定义。 我们回到 ACID 属性和事务隔离级别，我不确定形式主义将如何准确地发挥作用。</p>
<p>What the literature does for advancing a database model to incorporate this relationship that linearizability has with time is to incorporate its ideas into the serializable transaction isolation level.</p>
<p>为了推进数据库模型以纳入线性化与时间的这种关系，文献所做的就是将其思想纳入可序列化事务隔离级别。</p>
<h3 id="A-note-on-clocks"><a href="#A-note-on-clocks" class="headerlink" title="A note on clocks"></a><em>A note on clocks</em></h3><p>关于时钟的注意事项</p>
<p>The mentioning of “real time” and the use of a global clock governing a distributed system are fighting words for some of my colleagues. It’s understandable since, on the one hand, Einstein realized that time itself is relative (different observers can perceive events to take place in different orders relative to each other) and, on the other hand, even if we are to ignore relativistic effects for practical purposes, this one true, shared clock doesn’t quite exist in the context of a distributed system. I’m not qualified to discuss relativistic effects beyond acknowledging that there is such a thing as <em><a href="https://link.springer.com/chapter/10.1007/978-3-662-45174-8_25"><em>relativistic linearizability</em></a></em>. I believe the casual database user can ignore them, but I’ll start blabbering if you ask me exactly why.</p>
<p>对于我的一些同事来说，提到“实时”和使用全局时钟来管理分布式系统都是争论不休的。 这是可以理解的，因为一方面，爱因斯坦意识到时间本身是相对的（不同的观察者可以感知事件以相对于彼此不同的顺序发生），另一方面，即使我们在实际中忽略相对论效应 出于目的，这个真正的共享时钟在分布式系统的上下文中并不完全存在。 除了承认存在“相对论线性化”这样的东西之外，我没有资格讨论相对论效应。 我相信普通的数据库用户可以忽略它们，但如果你问我到底为什么，我会开始喋喋不休。</p>
<p>The fact that there is no shared clock according to which we can decide ordering is a problem all too real for implementers of distributed systems like CockroachDB. The closest we’ve come is <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45855.pdf">a system called TrueTime built by Google</a>, which provides tightly synchronized clocks and bounded errors brought front and center.</p>
<p>事实上，对于像 CockroachDB 这样的分布式系统的实现者来说，没有共享时钟来决定排序是一个非常现实的问题。 我们最接近的是一个由 Google 构建的名为 TrueTime 的系统，它提供了紧密同步的时钟和有限的误差。</p>
<p>As far as the linearizability model is concerned (which assumes that a shared clock exists), the way I think about it is that the model tells us what to expect if such a clock were to exist. Given that it doesn’t quite exist, then clients of the system can’t actually use it to record their histories perfectly: one can’t simply ask all the clients, or all the CockroachDB replicas, to log their operation invocations and responses and timestamp them using the local clocks, and then centralize all the logs and construct a history out of that. This means that verifying a system that claims to be linearizable isn’t trivial. In other words, Herlihy talks about histories but doesn’t describe how one might actually produce these histories in practice. But that doesn’t mean the model is not useful.</p>
<p>就线性化模型而言（假设存在共享时钟），我的想法是该模型告诉我们如果存在这样的时钟会发生什么。 鉴于它并不完全存在，那么系统的客户端实际上无法使用它来完美地记录其历史记录：不能简单地要求所有客户端或所有 CockroachDB 副本记录其操作调用和响应， 使用本地时钟为它们添加时间戳，然后集中所有日志并从中构建历史记录。 这意味着验证一个声称可线性化的系统并非易事。 换句话说，赫利希谈论历史，但没有描述人们如何在实践中真正产生这些历史。 但这并不意味着该模型没有用。</p>
<p>What a verifier can do is record certain facts like “I know that this invocation happened after this other invocation, because there was a causal relationship between them”. For certain operations for which there was not a causal relationship, the client might not have accurate enough timestamps to put in the history and so such pairs of events can’t be used to verify whether a history is linearlizable or not. Alternatively, another thing a verifier might do is relay all its operations through a singular “timestamp oracle”, whose recording would then be used to produce and validate a history. Whether such a construct is practical is debatable, though, since the mere act of sequencing all operations would probably introduce enough latency in them as to hide imperfections of the system under test.</p>
<p>验证者可以做的是记录某些事实，例如“我知道这次调用发生在另一次调用之后，因为它们之间存在因果关系”。 对于某些不存在因果关系的操作，客户端可能没有足够准确的时间戳来放入历史记录中，因此此类事件对不能用于验证历史记录是否可线性化。 或者，验证者可能做的另一件事是通过单个“时间戳预言机”中继其所有操作，然后使用其记录来生成和验证历史记录。 然而，这样的构造是否实用是有争议的，因为仅仅对所有操作进行排序的行为就可能会在其中引入足够的延迟，从而隐藏被测系统的缺陷。</p>
<h2 id="Bringing-the-worlds-together-strict-serializability"><a href="#Bringing-the-worlds-together-strict-serializability" class="headerlink" title="Bringing the worlds together: strict serializability"></a>Bringing the worlds together: strict serializability</h2><p>将世界结合在一起：严格的可串行性</p>
<p>As I was saying, the ANSI SQL standard defines the serializable transaction isolation as the highest level, but its definition doesn’t consider phenomena present in distributed databases. It admits transaction behavior that is surprising and undesirable because it doesn’t say anything about how some transactions need to be ordered with respect to the time at which the client executed them.</p>
<p>正如我所说，ANSI SQL 标准将可序列化事务隔离定义为最高级别，但其定义并未考虑分布式数据库中存在的现象。 它承认令人惊讶且不受欢迎的事务行为，因为它没有说明某些事务需要如何根据客户端执行它们的时间进行排序。</p>
<p>To cover these gaps, the term “strict serializability” has been introduced for describing (distributed) databases that don’t suffer from these undesirable behaviors.</p>
<p>为了弥补这些差距，引入了术语“严格可串行化”来描述不受这些不良行为影响的（分布式）数据库。</p>
<p>Strict serializability says that transaction behavior is equivalent to some serial execution, and the serial order of transactions corresponds to real time (i.e. a transaction started after another one finished will be ordered after it). Note that strict serializability (like linearizability) still doesn’t say anything about the relative ordering of concurrent transactions (but, of course, those transaction still need to appear to be “isolated” from each other). We’ll come back to this point in the next sections.</p>
<p>严格的可串行性表示事务行为相当于某种串行执行，并且事务的串行顺序对应于实时（即，在另一个事务完成之后开始的事务将在它之后排序）。 请注意，严格的可串行性（如线性化）仍然没有说明并发事务的相对顺序（但是，当然，这些事务仍然需要看起来彼此“隔离”）。 我们将在下一节中回到这一点。</p>
<p>Under strict serializability, the system behavior outlined in the Hacker News posts example from the Serializability section is not permitted. Databases described by the strict serializability model must ensure that the final read, Nathan’s, must return both the root comment and the response. Additionally, the system must ensure that a query like <code>select * from hacker_news_comments</code> never returns the child comment without the parent, regardless of the the time when the query is executed (i.e. depending on the time when it’s executed, it can return an empty set, the root, or both the root and the child). We’ll come back to this point when discussing CRDB’s guarantees.</p>
<p>在严格的可序列化性下，不允许出现“可序列化性”部分中的黑客新闻帖子示例中概述的系统行为。 严格的可序列化模型描述的数据库必须确保 Nathan 的最终读取必须返回根注释和响应。 此外，系统必须确保像 <code>select * from hacker_news_comments </code> 这样的查询永远不会返回没有父评论的子评论，无论查询执行的时间如何（即，根据执行的时间，它可以返回一个空集， 根，或根和孩子）。 当我们讨论 CRDB 的保证时，我们会回到这一点。</p>
<p><a href="https://cloud.google.com/spanner/docs/true-time-external-consistency#2">Google’s Spanner uses the term “external consistency”</a> instead of “strict serializability”. I like that term because it emphasizes the difference between a system that provides “consistency” for transactions known to the database to be causally related and systems that don’t try to infer causality and offer stronger guarantees (or, at least, that’s how me and my buddies interpret the term). For example, remembering the Hacker News example, there are systems that allow Tobi to explicitly tell the database that his transaction has been “caused” by my transaction, and then the system guarantees that the ordering of the two transaction will respect this. Usually this is done through some sort of “causality tokens” that the actors pass around between them. In contrast, Spanner doesn’t require such cooperation from the client in order to prevent the bad outcome previously described: even if the clients coordinated “externally” to the database (e.g, by yelling across the room), they’ll still get the consistency level they expect.</p>
<p>谷歌的 Spanner 使用术语“外部一致性”而不是“严格的可序列化性”。 我喜欢这个术语，因为它强调了为数据库已知的因果关系事务提供“一致性”的系统与不尝试推断因果关系并提供更强保证的系统之间的区别（或者，至少，这就是我的方式） 我的朋友解释了这个词）。 例如，记住 Hacker News 的例子，有些系统允许 Tobi 明确地告诉数据库他的交易是由我的交易“引起”的，然后系统保证两个交易的顺序将尊重这一点。 通常这是通过演员之间传递的某种“因果关系令牌”来完成的。 相比之下，Spanner 不需要客户端的这种合作来防止前面描述的不良结果：即使客户端在数据库“外部”进行协调（例如，通过在房间里大喊大叫），他们仍然会得到 他们期望的一致性水平。</p>
<p>Peter Bailis has more words on <a href="http://www.bailis.org/blog/linearizability-versus-serializability/">Linearizability, Serializability and Strict Serializability</a>.</p>
<p>Peter Bailis 对线性化、可串行化和严格可串行化有更多的论述。</p>
<h2 id="CockroachDB’s-consistency-model-more-than-serializable-less-than-strict-serializability"><a href="#CockroachDB’s-consistency-model-more-than-serializable-less-than-strict-serializability" class="headerlink" title="CockroachDB’s consistency model: more than serializable, less than strict serializability"></a>CockroachDB’s consistency model: more than serializable, less than strict serializability</h2><p>Now that we’ve discussed some general concepts, let’s talk about how they apply to CockroachDB. CockroachDB is an open-source, transactional, SQL database and it’s also a distributed system. In my opinion, it comes pretty close to being the Holy Grail of databases: it offers a high degree of “consistency”, it’s very resilient to machine and network failures, it scales well and it performs well. This combination of features already makes it unique enough; the system goes beyond that and brings new concepts that are quite game-changing — good, principled control over data placement and read and write latency versus availability tradeoffs in geographically-distributed clusters. All without ever sacrificing things we informally refer to as “consistency” and “correctness” in common parlance. Also it’s improving every day at a remarkable pace. I’m telling you — <a href="https://www.cockroachlabs.com/get-started-cockroachdb/">you need to try this thing</a>!</p>
<p>现在我们已经讨论了一些一般概念，接下来我们来谈谈它们如何应用于 CockroachDB。 CockroachDB 是一个开源的事务性 SQL 数据库，也是一个分布式系统。 在我看来，它非常接近数据库的圣杯：它提供了高度的“一致性”，它对机器和网络故障具有很强的弹性，它具有良好的扩展性并且性能良好。 这种功能组合已经使其足够独特； 该系统超越了这一点，并带来了完全改变游戏规则的新概念——对数据放置、读写延迟与地理分布式集群中的可用性权衡进行良好的、有原则的控制。 所有这一切都没有牺牲我们非正式地称为“一致性”和“正确性”的东西。 而且它每天都在以惊人的速度进步。 我告诉你——你需要尝试一下这个东西！</p>
<p>But back to the subject at hand — the consistency story. CockroachDB is a complex piece of software; understanding how it all works in detail is not tractable for most users, and indeed it will not even be a good proposition for all the engineers working on it. We therefore need to model it and present a simplified version of reality. The model needs to be as simple as possible and as useful as possible to users, without being misleading (e.g. suggesting that outcomes that one might think are undesirable are not possible when in fact they are). Luckily, because CockroachDB was always developed under a “correctness first” mantra, coming up with such a model is not too hard, as I’ll argue.</p>
<p>但回到我们手头的主题——一致性的故事。 CockroachDB 是一个复杂的软件； 对于大多数用户来说，理解它的详细工作原理并不容易，事实上，对于所有致力于它的工程师来说，这甚至不是一个好建议。 因此，我们需要对其进行建模并呈现现实的简化版本。 该模型需要尽可能简单并且对用户尽可能有用，而不会产生误导（例如，暗示人们可能认为不期望的结果是不可能的，而实际上它们是不可能的）。 幸运的是，因为 CockroachDB 始终是在“正确性第一”的口号下开发的，所以正如我所说，提出这样一个模型并不难。</p>
<p>There’s a standard disclosure that comes with our software: the system assumes that the clocks on the Cockroach nodes are somewhat synchronized with each other. The clocks are allowed to drift away from each other up to a configured “maximum clock offset” (by default 500ms). Operators need to run NTP or other clock synchronization mechanism on their machines. The system detects when the drift approaches the maximum allowed limit and shuts down some nodes, alerting an operator[^2]. Theoretically, I think more arbitrary failures modes are possible if clocks get unsynchronized quickly. More on the topic in Spencer’s post <a href="https://www.cockroachlabs.com/blog/living-without-atomic-clocks">“Living Without Atomic Clocks.”</a></p>
<p>我们的软件附带了一个标准披露：系统假设 Cockroach 节点上的时钟在某种程度上彼此同步。 允许时钟彼此漂移，最多可达配置的“最大时钟偏移”（默认为 500ms）。 运营商需要在他们的机器上运行NTP或其他时钟同步机制。 系统会检测漂移何时接近最大允许限制并关闭一些节点，从而向操作员发出警报[^2]。 从理论上讲，我认为如果时钟快速不同步，则可能会出现更多任意故障模式。 有关该主题的更多信息，请参阅斯宾塞的文章“没有原子钟的生活”。</p>
<p>Back to the consistency. For one, CockroachDB implements the serializable isolation level for transactions, as specified by the SQL standard. In contrast to most other databases which don’t offer this level of isolation as the default (<a href="https://blog.dbi-services.com/oracle-serializable-is-not-serializable/">or at all, for crying out loud!</a>), this is the only isolation level we offer; users can’t opt for a lesser one. We, the CockroachDB authors, collectively think that any lower level is just asking for pain. It’s fair to say that it’s generally extremely hard to reason about the other levels and the consequences of using them in an application (see the <a href="http://www.bailis.org/papers/acidrain-sigmod2017.pdf">ACIDRain paper</a> for what can go wrong when using lower isolation levels). I’m not trying to be condescending; up until the 2.1 version we used to offer another relatively high level of isolation as an option (Snapshot Isolation), but it turned out that it (or, at least, our implementation of it) had complex, subtle consequences that even we hadn’t fully realized for the longest time. Thus, we ripped it out and instead improved the performance of the our implementation ensuring serializability as much as possible. Below serializability be dragons.</p>
<p>回到一致性。 其一，CockroachDB 实现了 SQL 标准指定的事务的可序列化隔离级别。 与大多数其他不提供这种默认隔离级别（或者根本不提供这种隔离级别）的数据库相比，这是我们提供的唯一隔离级别； 用户不能选择较小的。 我们，CockroachDB 作者，集体认为任何较低的级别都是自找痛苦。 公平地说，通常很难推理其他级别以及在应用程序中使用它们的后果（请参阅 ACIDRain 论文，了解使用较低隔离级别时可能会出现的问题）。 我并不是想表现出居高临下的态度。 在 2.1 版本之前，我们曾经提供另一个相对较高级别的隔离作为选项（快照隔离），但事实证明它（或者至少是我们对它的实现）产生了复杂而微妙的后果，甚至我们也没有意识到” 最长的时间没有完全实现。 因此，我们将其删除，并提高了实现的性能，尽可能确保可序列化。 下面的可序列化是龙。</p>
<p>But simply saying that we’re serializable is selling our system short. We offer more than that. We do not allow the bad outcome in the Hacker News commenting scenario.</p>
<p>但仅仅说我们是可序列化的就低估了我们的系统。 我们提供的远不止这些。 我们不允许黑客新闻评论场景出现不良结果。</p>
<p>CockroachDB doesn’t quite offer strict serializability, but we’re fairly close to it. I’ll spend the rest of the section explaining how exactly we fail strict serializability, what our guarantees actually are, and some gotchas.</p>
<p>CockroachDB 并没有完全提供严格的可序列化性，但我们已经相当接近了。 我将用本节的其余部分来解释我们到底是如何失败的严格的可序列化，我们的保证实际上是什么，以及一些陷阱。</p>
<h3 id="No-stale-reads"><a href="#No-stale-reads" class="headerlink" title="No stale reads"></a>No stale reads</h3><p>If there’s one canned response I wish we’d give users that pop into our chat channels asking about the consistency model, I think it should be “CockroachDB doesn’t allow stale reads”. This should be the start of all further conversations, and in fact I think it will probably preempt many conversations. Stating this addresses a large swath of anomalies that people wonder about (in relation to distributed systems). “No stale reads” means that, once a write transaction committed, every read transaction starting afterwards[^3] will see it.</p>
<p>如果我希望我们能给那些突然进入我们的聊天频道询问一致性模型的用户一个预设的回复，我认为它应该是“CockroachDB 不允许过时的读取”。 这应该是所有进一步对话的开始，事实上我认为它可能会抢占许多对话。 声明这一点解决了人们想知道的大量异常现象（与分布式系统有关）。 “无陈旧读取”意味着，一旦提交写入事务，随后开始的每个读取事务[^3]都会看到它。</p>
<p>Internalizing this is important and useful. It does not come by chance; the system works hard for it and so have we, the builders. In the Hacker News comments example, once I have committed my root comment, a new transaction by Nathan is guaranteed to see it. Yes, our system is distributed and data is replicated. Yes, Nathan might be talking to a different node than I was, maybe a node with a clock that’s trailing behind. In fact, the node I was talking to might have even crashed in the meantime. Doesn’t matter. If Nathan is able to read the respective table, he will be able to read my write.</p>
<p>内化这一点很重要而且有用。 它不是偶然出现的；它是偶然发生的。 系统为此努力工作，我们建设者也是如此。 在黑客新闻评论示例中，一旦我提交了我的根评论，Nathan 的新交易就一定会看到它。 是的，我们的系统是分布式的，数据是复制的。 是的，Nathan 可能正在与一个与我不同的节点通信，也许是一个时钟落后的节点。 事实上，我正在交谈的节点甚至可能在此期间崩溃了。 没关系。 如果Nathan能够读取相应的表，他将能够读取我的写入。</p>
<p>Beyond serializability, saying “no stale reads” smells like linearizability (and, thus, strict serializability) since “staleness” is related to the passing of time. In fact, when people come around asking for linearizability, I conjecture that most will be satisfied by this answer. I think this is what I’d be asking for if I hadn’t educated myself specifically on the topic. Relatedly, this is also what the C(onsistency) in the famous <a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP theorem</a> is asking for. And we have it.</p>
<p>除了可序列化性之外，说“没有过时的读取”闻起来像线性化（因此也是严格的可序列化），因为“过时性”与时间的流逝有关。 事实上，当人们询问线性化时，我猜大多数人都会对这个答案感到满意。 我想如果我没有专门针对这个主题进行自我教育的话，这就是我所要求的。 与此相关，这也是著名的 CAP 定理中的 C（一致性）所要求的。 我们有它。</p>
<p>So why exactly don’t we claim strict serializability?</p>
<p>那么我们为什么不要求严格的可序列化呢？</p>
<h3 id="CockroachDB-does-not-offer-strict-serializability"><a href="#CockroachDB-does-not-offer-strict-serializability" class="headerlink" title="CockroachDB does not offer strict serializability"></a>CockroachDB does not offer strict serializability</h3><p>Even though CRDB guarantees (say it with me) “no stale reads”, it still can produce transaction histories that are not linearizable.</p>
<p>尽管 CRDB 保证（跟我说）“没有过时的读取”，但它仍然会产生不可线性化的事务历史记录。</p>
<p>Consider the history HN2 (assume every statement is its own transaction, for simplicity):</p>
<p>考虑历史 HN2（为简单起见，假设每个语句都是它自己的事务）：</p>
<ul>
<li>Nathan runs <code>select * from hacker_news_comments</code>. Doesn’t get a response yet.</li>
<li>I run <code>insert into hacker_news_comments (id, parent_id, text) values (1, NULL, &#39;a root comment&#39;)</code> and commit.</li>
<li>Tobi runs <code>insert into hacker_news_comments (id, parent_id, text) values (2, 1, &#39;OP is wrong&#39;)</code> and commits.</li>
<li>Nathan’s query returns and he gets Tobi’s row but not mine.</li>
</ul>
<p>This is the “anomaly” described in Section 2.5 of <a href="https://jepsen.io/analyses/cockroachdb-beta-20160829">Jepsen’s analysis of CRDB</a> from back in the day.</p>
<p>这就是 Jepsen 当年对 CRDB 的分析第 2.5 节中描述的“异常”。</p>
<p>So what happened? From Nathan’s perspective, Tobi’s transaction appears to have executed before mine. That contradicts strict serializability since, according to “real time”, Tobi ran his transaction after me. This is how CRDB fails strict serializability; we call this anomaly “causal reverse”.</p>
<p>所以发生了什么事？ 从 Nathan 的角度来看，Tobi 的交易似乎是在我的之前执行的。 这与严格的序列化相矛盾，因为根据“实时”，托比在我之后运行他的交易。 这就是 CRDB 无法严格串行化的原因； 我们称这种异常为“因果逆转”。</p>
<p>Before freaking out, let’s analyze the circumstances of the anomaly a bit. Then I’ll explain more technically, for the curious, how such a thing can happen in CRDB.</p>
<p>在惊慌失措之前，我们先来分析一下异常情况。 然后，为了满足好奇心，我将从技术上更详细地解释一下 CRDB 中如何发生这样的事情。</p>
<p>First of all, let’s restate our motto: if Nathan had have started his transaction after Tobi committed (in particular, if Nathan would have started his transaction <em>because</em> Tobi committed his), he would have seen both rows and things would have been good. An element that’s at play, and in fact is key here, is that Nathan’s transaction was concurrent with <strong>both</strong> mine and Tobi’s. According to the definition of strict serializability, Nathan’s transaction can be ordered in a bunch of ways with respect to the other two: it can be ordered before both of them, after both of them, or after mine but before Tobi’s. The only thing that’s required is that my transaction is ordered before Tobi’s. The violation of strict serializability that we detected here is not that Nathan’s transaction was mis-ordered, but that mine and Tobi’s (which are not concurrent) appear to have been reordered. Non-strict serializability allows this just fine.</p>
<p>首先，让我们重申一下我们的座右铭：如果 Nathan 在 Tobi 提交后开始他的事务（特别是，如果 Nathan 因为 Tobi 提交了他的事务而开始他的事务），他就会看到这两行，事情就会很好。 一个起作用的因素，实际上是这里的关键，是Nathan的事务与我和Tobi的事务同时发生。 根据严格可序列化的定义，Nathan 的事务相对于其他两个事务可以通过多种方式排序：它可以排序在它们之前、之后，或者在我的事务之后但在 Tobi 之前。 唯一需要做的是我的事务在 Tobi 的事务之前订购。 我们在这里检测到的违反严格序列化的行为并不是 Nathan 的事务顺序错误，而是我的事务和 Tobi 的事务（不并发）似乎已重新排序。 非严格的可串行性允许这很好。</p>
<p>My opinion is that this anomaly is not particularly bad because Nathan was not particularly expecting to see either of the two writes. But if this was my only argument, I’d probably stay silent.</p>
<p>我的观点是，这种异常现象并不是特别糟糕，因为 Nathan 并没有特别期望看到这两个写入中的任何一个。 但如果这是我唯一的论点，我可能会保持沉默。</p>
<p>There’s another important thing to explain: both my and Tobi’s transactions are, apart from their timing, unrelated: the sets of data they read and write do not overlap. If they were overlapping (e.g. if Tobi read my comment from the DB before inserting his), then serializability would not allow them to be reordered at all (and so CockroachDB wouldn’t do it and the anomaly goes away). In this particular example, if the schema of the hacker<em>news</em>comments table would contain a self-referencing foreign key constraint (asking the database to ensure that child comments reference an existing parent), then the “reading” part would have been ensured by the system.</p>
<p>还有一件重要的事情需要解释：我和 Tobi 的事务除了时间之外都是无关的：它们读取和写入的数据集不重叠。 如果它们重叠（例如，如果 Tobi 在插入他的评论之前从数据库中读取了我的评论），那么可序列化性根本不允许它们重新排序（因此 CockroachDB 不会这样做，异常就会消失）。 在这个特定的示例中，如果 hackernewscomments 表的模式包含自引用外键约束（要求数据库确保子评论引用现有的父评论），那么系统将确保“阅读”部分。</p>
<p>So, for this anomaly to occur, you need three transactions to play. Two of them need to appear to be independent of each other (but not really be, or otherwise we probably wouldn’t have noticed the anomaly) and the third needs to overlap both of them. I’ll let everybody judge for themselves how big of a deal this is. For what it’s worth, I don’t remember hearing a CRDB user complaining about it.</p>
<p>因此，要发生这种异常，您需要进行三笔交易。 其中两个需要看起来彼此独立（但实际上并非如此，否则我们可能不会注意到异常），第三个需要将它们重叠。 我会让每个人自己判断这件事有多大。 无论如何，我不记得听到过 CRDB 用户抱怨过它。</p>
<p>Beyond the theory, there are technical considerations that make producing this anomaly even more unlikely: given CockroachDB’s implementation, the anomaly is avoided not only if the read&#x2F;write sets of my and Tobi’s transactions overlap, but also if the leadership of any of the ranges of data containing hacker<em>news</em>comments rows 1 and 2 happens to be on the same node when these transactions occur, or if Nathan’s database client is talking to the same CockroachDB node as Tobi’s, and also in various other situations. Also, the more synchronized the clocks on the three nodes are, the less likely it is. Overall, this anomaly is pretty hard to produce even if you try explicitly.</p>
<p>除了理论之外，还有一些技术考虑因素使得产生这种异常的可能性更小：考虑到 CockroachDB 的实现，不仅当 my 和 Tobi 的事务的读&#x2F;写集重叠时，而且当任何范围的领导层重叠时，也可以避免异常。 当这些事务发生时，或者 Nathan 的数据库客户端与 Tobi 的数据库客户端与同一个 CockroachDB 节点通信时，以及在各种其他情况下，包含 hackernewscomments 行 1 和 2 的数据恰好位于同一节点上。 此外，三个节点上的时钟越同步，这种情况的可能性就越小。 总的来说，即使你明确地尝试，这种异常也很难产生。</p>
<p>As you might have guessed, I personally am not particularly concerned about this anomaly. Besides everything I’ve said, I’ll add a whataboutist argument and take the discussion back to friendly territory: consider this anomaly in contrast to the “stale reads” family of anomalies present in many other competing products. All these things are commonly bucketed under strict serializability &#x2F; linearizability violations, but don’t be fooled into thinking that they’re all just as bad. Our anomaly needs three transactions doing a specific dance resulting in an outcome that, frankly, is not even that bad. A stale read anomaly can be seen much easier in a product that allows it. Examples are many; a colleague gave a compelling one recently: if your bank was using a database that allows stale reads, someone might deposit a check for you, at which point your bank would text you about it, and you’d go online to see your balance. You might see the non-updated balance and freak out. Banks should be using CockroachDB.</p>
<p>正如您可能已经猜到的那样，我个人并不特别担心这种异常现象。 除了我所说的一切之外，我还将添加一个关于什么的论点，并将讨论带回到友好的领域：将此异常与许多其他竞争产品中存在的“陈旧读取”异常系列进行对比。 所有这些事情通常都受到严格的可序列化&#x2F;线性化违规的影响，但不要误以为它们都一样糟糕。 我们的异常需要三笔交易进行特定的舞蹈，坦率地说，结果并没有那么糟糕。 在允许这种情况的产品中，可以更容易地看到陈旧的读取异常。 例子有很多； 一位同事最近给出了一个令人信服的说法：如果您的银行使用的数据库允许过时读取，有人可能会为您存入一张支票，此时您的银行会向您发送短信，然后您可以上网查看余额。 您可能会看到未更新的余额并感到害怕。 银行应该使用 CockroachDB。</p>
<h3 id="Other-CockroachDB-gotchas"><a href="#Other-CockroachDB-gotchas" class="headerlink" title="Other CockroachDB gotchas"></a>Other CockroachDB gotchas</h3><p>其他 CockroachDB 问题</p>
<p>I’ve discussed the CockroachDB guarantees and violations of strict serializability. Our discussion used, laxly, the SQL language to illustrate things but the discussion used language and concepts from more theoretical literature. We bridged the gap by implying that SQL statements are really reads and writes used by some models. This section discusses some uses of CockroachDB&#x2F;SQL that fall a bit outside the models we’ve used, but are surprising nevertheless. I think these examples will not fall nicely into the models used for the strict serializability definition, at least not without some effort into expanding the model.</p>
<p>我已经讨论了 CockroachDB 的保证和对严格序列化的违反。 我们的讨论宽松地使用了 SQL 语言来说明问题，但讨论使用了更多理论文献中的语言和概念。 我们通过暗示 SQL 语句实际上是某些模型使用的读取和写入来弥补这一差距。 本节讨论 CockroachDB&#x2F;SQL 的一些用法，这些用法有点超出我们使用的模型，但仍然令人惊讶。 我认为这些示例不会很好地落入用于严格可串行性定义的模型中，至少在不努力扩展模型的情况下是这样。</p>
<h4 id="The-SQL-now-function"><a href="#The-SQL-now-function" class="headerlink" title="The SQL now() function"></a><strong>The SQL now() function</strong></h4><p>Consider the following two transactions:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> <span class="keyword">insert</span> <span class="keyword">into</span> foo (id, <span class="type">time</span>) <span class="keyword">values</span> (<span class="number">1</span>, now())</span><br><span class="line"><span class="number">2.</span> <span class="keyword">insert</span> <span class="keyword">into</span> foo (id, <span class="type">time</span>) <span class="keyword">values</span> (<span class="number">2</span>, now())</span><br></pre></td></tr></table></figure>

<p>Assuming these two transactions execute in this order, it is possible (and surprising) to read the rows back and see that the time value for row 2 is lower that the one for row one.</p>
<p>假设这两个事务按此顺序执行，则有可能（并且令人惊讶）读回行并看到第 2 行的时间值低于第 1 行的时间值。</p>
<p>Perhaps it’s realistic to think that this happens in other systems too, even single-node systems, if the system clock jumps backwards (as it sometimes does), so perhaps there’s nothing new here.</p>
<p>也许现实的是，如果系统时钟向后跳（有时会发生），这种情况也会发生在其他系统中，甚至是单节点系统中，所以也许这里没有什么新东西。</p>
<h3 id="as-of-system-time-queries-and-backups"><a href="#as-of-system-time-queries-and-backups" class="headerlink" title="as of system time queries and backups"></a><code>as of system time</code> queries and backups</h3><p>CockroachDB supports the (newer) standard SQL system-versioned tables; CockroachDB lets one “time travel” and query the old state of the database with a query like <code>select * from foo as of system time now()-10s</code>. This is a fantastic, really powerful feature. But it also provides another way to observe a “causal reverse” anomaly. Say one ran these two distinct transactions, in this order:</p>
<p>CockroachDB 支持（较新的）标准 SQL 系统版本表； CockroachDB 允许“时间旅行”，并使用 select * from foo 之类的查询来查询截至系统时间 now()-10s 的数据库的旧状态。 这是一个非常棒的、非常强大的功能。 但它也提供了另一种观察“因果逆转”异常的方法。 假设有人按以下顺序运行这两个不同的事务：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> <span class="keyword">insert</span> <span class="keyword">into</span>  hacker_news_comments (id, parent_id, text) <span class="keyword">values</span> (<span class="number">1</span>, <span class="keyword">NULL</span>, <span class="string">&#x27;a root comment&#x27;</span>)</span><br><span class="line"><span class="number">2.</span> <span class="keyword">insert</span> <span class="keyword">into</span> hacker_news_comments (id, parent_id, text) <span class="keyword">values</span> (<span class="number">2</span>, <span class="number">1</span>, <span class="string">&#x27;OP is wrong&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>It’s possible for an <code>as of system time</code> query to be executed later and, if it’s unlucky in its choice of a “system time”, to see the second row and not the first.</p>
<p>稍后执行<code>as of system time</code>查询是可能的，如果不幸选择了“系统时间”，则可能会看到第二行而不是第一行。</p>
<p>Again, if the second transaction were to read the data written by the first (e.g. implicitly through a foreign key check), the anomaly would not be possible.</p>
<p>同样，如果第二个事务要读取第一个事务写入的数据（例如，通过外键检查隐式地进行），则不会出现异常。</p>
<p>Relatedly, a backup, taken through the <code>backup database</code> command, is using <code>as of system time</code> queries under the hood, and so a particular backup might contain row 2 but not row 1.</p>
<p>相关地，通过备份数据库命令进行的备份在幕后使用系统时间查询，因此特定备份可能包含第 2 行，但不包含第 1 行。</p>
<h2 id="CockroachDB-implementation-details"><a href="#CockroachDB-implementation-details" class="headerlink" title="CockroachDB implementation details"></a>CockroachDB implementation details</h2><p>The <a href="https://www.cockroachlabs.com/docs/stable/architecture/overview">architecture of CockroachDB</a> is based on a separation between multiple layers (a SQL layer on top down to a storage layer at the bottom). For the subject at hand, the interesting layer is the <a href="https://www.cockroachlabs.com/docs/stable/architecture/transaction-layer">Transaction Layer</a>, which is in charge of making sure that a transaction doesn’t miss writes that it’s supposed to be seeing. Each transaction has a timestamp, assigned by the “gateway node” — the node that a client happens to be talking to — when the transaction starts (through a SQL BEGIN statement). As the transaction talks to different other nodes that might be responsible for <em><em>ranges</em></em> of data it wants to read, this timestamp is used to decide what values are visible (because they’ve been written by transactions “in the past”) and which values aren’t visible because they’ve been written “in the future”.</p>
<p>CockroachDB的架构基于多层之间的分离（顶部的SQL层到底部的存储层）。 对于当前的主题，有趣的层是事务层，它负责确保事务不会错过它应该看到的写入。 每个事务都有一个时间戳，由事务开始时（通过 SQL BEGIN 语句）由“网关节点”（客户端恰好与之通信的节点）分配。 当事务与可能负责其想要读取的数据范围的不同其他节点进行通信时，此时间戳用于决定哪些值是可见的（因为它们是由“过去”的事务写入的）以及哪些值是可见的。 不可见，因为它们已被写为“未来”。</p>
<p>CockroachDB uses multi-version concurrency control (MVCC), which means that the history of each row is available for transactions to look through. The difficulties, with respect to consistency guarantees, stem from the fact that the timestamp recording into MVCC are taken from the clock of the gateway node that wrote it, which generally is not the same one as the gateways assigning transaction timestamp for a reader, and we assume that the clock can be desynchronized up to a limit (we call the phenomenon “clock skew”). So, given transaction timestamp <em>t</em> and value timestamp <em>t’</em>, how does one decide whether the value in question should be visible or not?</p>
<p>CockroachDB使用多版本并发控制（MVCC），这意味着每一行的历史记录都可供事务查看。 一致性保证方面的困难源于以下事实：MVCC 中的时间戳记录取自写入它的网关节点的时钟，该时钟通常与为读取器分配事务时间戳的网关不同，并且 我们假设时钟可以去同步到一定限度（我们将这种现象称为“时钟偏差”）。 那么，给定交易时间戳 t 和值时间戳 t’，如何决定所讨论的值是否应该可见？</p>
<p>The rules are that, if <em>t’ &lt;&#x3D; t</em>, then the transaction will see the respective value (and so we’ll essentially order our transaction after that writer). The reasoning is that either our transaction really started after the other one committed, or, if not, the two were concurrent and so we can order things either way.</p>
<p>规则是，如果 t’ &lt;&#x3D; t，那么交易将看到相应的值（因此我们基本上会在该编写者之后对交易进行排序）。 原因是，要么我们的事务在另一个事务提交后才真正开始，要么如果不是，则两个事务是并发的，因此我们可以以任何一种方式排序。</p>
<p>If <em>t’ &gt; t</em>, then it gets tricky. Did the writer really start and commit before the reader began its transaction, or did it commit earlier than that but t’ was assigned by a clock that’s ahead of ours? What CRDB does is define an “uncertainty interval”: if the values are close enough so that <em>t’</em> could be explained by a trailing clock, we say that we’re unsure about whether the value needs to be visible or not, and our transaction needs to change its timestamp (which, unless we can avoid it, means the transaction might have to restart. Which, unless we can further avoid it, means the client might get a retriable error). This is what allows CockroachDB to guarantee no stale reads. In the Hacker News example, if Nathan starts his transaction after me and Tobi committed ours, the worst that could happen is that he gets a timestamp that’s slightly in the past and has to consider some of our other writes uncertain, at which point he’ll restart at a higher timestamp.</p>
<p>如果 t’ &gt; t，那么事情就会变得棘手。 写入器是否真的在读取器开始其事务之前开始并提交，或者它是否早于该时间提交，但 t’ 是由比我们早的时钟分配的？ CRDB 所做的是定义一个“不确定性区间”：如果这些值足够接近以至于 t’ 可以用尾随时钟来解释，我们就说我们不确定该值是否需要可见，并且我们的交易 需要更改其时间戳（除非我们可以避免它，否则意味着事务可能必须重新启动。除非我们可以进一步避免它，否则意味着客户端可能会遇到可重试的错误）。 这就是 CockroachDB 能够保证没有过时读取的原因。 在 Hacker News 的例子中，如果 Nathan 在我和 Tobi 提交我们的交易之后开始他的交易，最糟糕的情况是他得到的时间戳稍微有点过去，并且必须考虑我们的其他一些写入不确定，此时他’ 将以更高的时间戳重新启动。</p>
<p>We work quite hard to minimize the effects of this uncertainty interval. For one, transactions keep track of what timestamps they’ve observed at each node and uncertainty is tracked between nodes pair-wise. This, coupled with the fact that a node’s clock is bumped up when someone tries to write on it with a higher timestamp, allows a transaction to not have to restart more than once because of an uncertain value seen on a particular node. Also, overall, once the maximum admissible clock skew elapses since a transaction started, a transaction no longer has any uncertainty.</p>
<p>我们非常努力地工作以尽量减少这种不确定性区间的影响。 首先，交易会跟踪它们在每个节点观察到的时间戳，并且成对地跟踪节点之间的不确定性。 再加上当有人试图用更高的时间戳在节点上写入时，节点的时钟会被调高，使得事务不必因为在特定节点上看到的不确定值而多次重新启动。 此外，总体而言，一旦自事务开始以来最大允许时钟偏差过去，事务就不再具有任何不确定性。</p>
<p>Separately, when a transaction’s timestamp does need to be bumped, we try to be smart about it. If either the transaction hasn’t read anything before encountering the uncertain value, or if we can verify that there’s been no writes on the data its already read before encountering the uncertainty, then the transaction can be bumped with no fuss. If we can’t verify that, then the transaction needs to restart so it can perform its writes again. If it does have to restart, we don’t necessarily tell the client about it. If we haven’t yet returned any results for the transaction to the client (which is common if the client can send parts of a transaction’s statements as a batch), then we can re-execute all the transaction’s statements on the server-side and the client is none the wiser.</p>
<p>另外，当交易的时间戳确实需要改变时，我们会尽量聪明地处理它。 如果事务在遇到不确定值之前没有读取任何内容，或者如果我们可以验证在遇到不确定值之前已经读取的数据没有被写入，那么事务就可以毫不费力地被碰撞。 如果我们无法验证这一点，则事务需要重新启动，以便它可以再次执行写入操作。 如果确实需要重新启动，我们不一定会告诉客户。 如果我们尚未将事务的任何结果返回给客户端（如果客户端可以批量发送事务的部分语句，则这是常见的），那么我们可以在服务器端重新执行所有事务的语句，并 客户却一无所知。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>CockroachDB provides a high level of “consistency”, second only to Spanner among distributed databases as far as I know (but then CockroachDB is a more flexible and easy to migrate to database — think <a href="https://www.cockroachlabs.com/docs/stable/install-client-drivers">ORM support</a> — so I’ll<a href="https://www.cockroachlabs.com/blog/spanner-vs-cockroachdb/"> take it over Spanner any day</a>). We offer a relatively easy to understand programming model, although the literature doesn’t give us a good name for it. It stronger than serializability, but somewhat weaker than strict serializability (and than linearizability, although using that term in the context of a transactional system is an abuse of the language). It’s probably easiest to qualify it by understanding the anomaly that it allows — “causal reverse” — and the limited set of circumstances under which it can occur. In the majority of cases where one might be wondering about semantics of reads and writes in CockroachDB, the slogan “no stale reads” should settle most discussions.</p>
<p>据我所知，CockroachDB 提供了高水平的“一致性”，在分布式数据库中仅次于 Spanner（但 CockroachDB 是一个更灵活、更容易迁移到的数据库——想想 ORM 支持——所以我会用它来取代 Spanner） 天）。 我们提供了一个相对容易理解的编程模型，尽管文献没有给我们一个好名字。 它比可序列化性更强，但比严格的可序列化性稍弱（并且比线性化更弱，尽管在事务系统的上下文中使用该术语是对该语言的滥用）。 通过理解它所允许的异常——“因果逆转”——以及它可能发生的有限情况，来限定它可能是最简单的。 在大多数情况下，人们可能想知道 CockroachDB 中读写的语义，“无陈旧读取”这一口号应该可以解决大多数讨论。</p>
<p>Although I think the definition of the Serializable isolation level would have benefitted from introducing some notion of different clients. As phrased by the SQL standard, I believe it technically allows empty results to be produced for any read-only transaction with the justification that those transactions are simply ordered before any other transaction. Implementing that would be egregious, though.[^2]: We’re thinking of ways to make CRDB resilient to more arbitrarily unsynchronized clocks.[^3]: As discussed in the “A note on clocks” section, figuring out what “afterwards” means is not always trivial when the clients involved are not on the same machine. But still, sometimes (in the cases that matter most), a transaction is known to happen after another one, usually through a causal relationship between the two. </p>
<p>尽管我认为可串行化隔离级别的定义会受益于引入不同客户端的一些概念。 正如 SQL 标准所述，我相信它在技术上允许为任何只读事务生成空结果，理由是这些事务只是在任何其他事务之前排序。 然而，实现这一点将是令人震惊的。[^2]：我们正在考虑如何使 CRDB 能够适应更多任意不同步的时钟。[^3]：正如“时钟注释”部分中所讨论的，弄清楚“ 当涉及的客户端不在同一台机器上时，“之后”的意思并不总是微不足道的。 但有时（在最重要的情况下），一笔交易会在另一笔交易之后发生，通常是通过两者之间的因果关系。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
</search>
